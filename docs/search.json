[
  {
    "objectID": "index.html#preface",
    "href": "index.html#preface",
    "title": "The Practice R Tutorials",
    "section": "Preface",
    "text": "Preface\nThis website gives access to all tutorials of Practice R (Treischl 2023). Practice R is a text book for the social sciences which provides several tutorials supporting students to learn R. Feel free to inspect the tutorials even if you are not familiar with the book, but keep in mind the tutorials are supposed to complement the Practice R book."
  },
  {
    "objectID": "index.html#the-book",
    "href": "index.html#the-book",
    "title": "The Practice R Tutorials",
    "section": "The book",
    "text": "The book\nMany students learn to analyze data using commercial packages, even though there is an open-source software with cutting-edge possibilities: R, a programming language with countless cool features for applied empirical research.\nPractice R introduces R to social science students, inspiring them to consider R as an excellent choice. In a non-technical pragmatic way, this book covers all typical steps of applied empirical research.\nLearn how to prepare, analyze, and visualize data in R. Discover how to collect data, generate reports, or automate error-prone tasks.\nThe book is accompanied by an R package. This provides further learning materials that include interactive tutorials, challenging you with typical problems of applied research. This way, you can immediately practice the knowledge you have learned. The package also includes the source code of each chapter and templates that help to create reports.\nPractice R has social science students in mind, nonetheless a broader audience may use Practice R to become a proficient R user.\n\nIntroduces R in a non-technical fashion\nCovers typical steps of applied empirical research\nComplemented by interactive tutorials\nWith access to all materials via the Practice R Package\n\n\n\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg."
  },
  {
    "objectID": "chapter_02.html#typical-error-messages",
    "href": "chapter_02.html#typical-error-messages",
    "title": "1  Base R",
    "section": "1.1 Typical error messages",
    "text": "1.1 Typical error messages\nWhat kind of errors do we need to talk about? Sometimes we introduce errors when we are not cautious enough about the code. Spelling mistakes (e.g., typos, missing and wrong characters, etc.) are easy to fix yet hard to find. For example, I tried to use the assignment operator, but something went wrong. Do you know what might be the problem?\n\n#Assigning the values the wrong way\na -&lt; 5\nb -&lt; 3\n\na + b\n\n#&gt; Error: &lt;text&gt;:2:4: unexpected '&lt;'\n#&gt; 1: #Assigning the values the wrong way\n#&gt; 2: a -&lt;\n#&gt;       ^\n\n\n\n# Keep the short cut for the assignment operator in mind:\n#&lt;Alt/Option&gt; + &lt;-&gt;\n\n# Solution:\na &lt;- 5\nb &lt;- 3\n\na + b\n\n#&gt; [1] 8\n\n\nFinding spelling mistakes in your own code can be hard. There are certainly several reasons, but our human nature to complete text certainly is part of it. This ability gives us the possibility to read fast, but it makes it difficult to see our own mistakes. Don’t get frustrated, it happens even if you have a lot of experience working with R. Thus, check if there are no simple orthographically mistakes - such as typos, missing (extra) parentheses, and commas - which prevents the code from running.\nI highlighted in Chapter 2 that RStudio inserts opening and closing parentheses, which reduces the chance that missing (or wrong) characters create an error, but there is no guarantee that we insert or delete one by chance. Suppose you try to estimate a mean in combination with the round() function. I put a parenthesis at a wrong place, which is why R throws an error. Can you see which parenthesis is causing the problem?\n\n#Check parenthesis\nround(mean(c(1, 4, 6))), digits = 2)\n\n#&gt; Error: &lt;text&gt;:2:24: unexpected ','\n#&gt; 1: #Check parenthesis\n#&gt; 2: round(mean(c(1, 4, 6))),\n#&gt;                           ^\n\n\n\n# Solution:\nround(mean(c(1, 4, 6)), digits = 2)\n\n#&gt; [1] 3.67\n\n\nThis error is hard to spot, but it illustrates that we need to be careful not to introduce mistakes. Moreover, RStudio gives parentheses that belong together the same color which help us to keep overview. Go to the RStudio menu (via the &lt;Code&gt; tab) and select rainbow parentheses if they are not displayed in color in the Code pane.\nUnfortunately, RStudio cannot help us all the time because some R errors messages (and warnings) are cryptic. There are even typical errors messages that are quite obscure for beginners. For example, R tells me all the time that it can’t find an object, functions, and data. There are several explanations why R throws such an error. If R cannot find an object, check if the object is listed in the environment. If so, you know for sure that the object exists and that other reasons cause the error. R cannot find an object even in the case of a simple typo.\n\n# R cannot find an object due to typos\nmean_a &lt;- mean(1, 2, 3)\nmaen_a\n\n#&gt; Error in eval(expr, envir, enclos): object 'maen_a' not found\n\n\n\n# Solution:\nmean_a &lt;- mean(1, 2, 3)\nmean_a\n\n#&gt; [1] 1\n\n\nR tells us that a function (an object) cannot be found if different notations are used. Keep in mind that R is case-sensitive (r vs. R) and cannot apply a function (or find an object) that does not exist, as the next console illustrates. Of course, the same applies if you forgot to execute the function before using it or if the function itself includes an error and cannot be executed. In all these examples R cannot find the function (or object).\n\n# R is case-sensitive\nreturn_fun &lt;- function(x) {\n  return(x)\n}\n\nReturn_fun(c(1, 2, 3))\n\n#&gt; Error in Return_fun(c(1, 2, 3)): could not find function \"Return_fun\"\n\n\n\n# Solution:\nreturn_fun(c(1, 2, 3))\n\n#&gt; [1] 1 2 3\n\n\nWhat is the typical reason why a function from an R package cannot be found? I started to introduce the dplyr package in Chapter 2 (Wickham et al. 2022). Suppose we want to use the select function from the package. To use anything from an R package, we need to load the package with the library() function each time we start (over). Otherwise, R cannot find the function.\n\n# Load the package to use a function from a package\nlibrary(palmerpenguins)\nselect(penguins, species)\n\n#&gt; Error in select(penguins, species): could not find function \"select\"\n\n\n\n# Solution:\ndplyr::select(penguins, species)\n\n#&gt; # A tibble: 344 × 1\n#&gt;    species\n#&gt;    &lt;fct&gt;  \n#&gt;  1 Adelie \n#&gt;  2 Adelie \n#&gt;  3 Adelie \n#&gt;  4 Adelie \n#&gt;  5 Adelie \n#&gt;  6 Adelie \n#&gt;  7 Adelie \n#&gt;  8 Adelie \n#&gt;  9 Adelie \n#&gt; 10 Adelie \n#&gt; # ℹ 334 more rows\n\n\nThe same applies to objects from a package (e.g., data). The .packages() function returns all loaded (attached) packages, but there is no need to keep that in mind. Go to the packages pane and check if a package is installed and loaded. R tells us only that the function cannot be found if we forget to load it first.\n\n# Inspect the loaded packages via the Packages pane\nloaded_packages &lt;- .packages()\nloaded_packages\n\n#&gt; [1] \"palmerpenguins\" \"stats\"          \"graphics\"       \"grDevices\"     \n#&gt; [5] \"utils\"          \"datasets\"       \"methods\"        \"base\"\n\n\nUltimately, suppose we try to import data. Never mind about the code, we focus on this step in Chapter 5 in detail, but R tells us that it cannot open the connection if the file cannot be found in the current working directory.\n\n# Load my mydata\nread.csv(\"mydata.csv\")\n\n#&gt; Warning in file(file, \"rt\"): cannot open file 'mydata.csv': No such file or\n#&gt; directory\n\n\n#&gt; Error in file(file, \"rt\"): cannot open the connection\n\n\nR tells that data, or other files cannot be found because we provided the wrong path to the file. We will learn how to import data later, but keep in mind that R cannot open a file if we search in the wrong place. In Chapter 2, I outlined many possibilities to change the work directory for which RStudio supplies convenient ways. In addition, the getwd() function returns the current work directory in case of any doubts.\n\n# Do we search for files in the right place\ngetwd()\n#&gt; [1] \"C:/Users/Edgar/R/Practice_R/Tutorial/02\"\n\nLoading the right packages and searching in the right place does not imply that we cannot inadvertently introduce mistakes. Suppose you want to apply the filter function from the dplyr package. You copy and adjust the code from an old script, but R returns an error. Can you see where I made the mistake? I tried to create a subset with Adelie penguins only, but dplyr seems to know what the problem might be.\n\n# Mistakes happen all the time ...\nlibrary(dplyr)\nfilter(penguins, species = \"Adelie\")\n\n#&gt; Error in `filter()`:\n#&gt; ! We detected a named input.\n#&gt; ℹ This usually means that you've used `=` instead of `==`.\n#&gt; ℹ Did you mean `species == \"Adelie\"`?\n\n\n\n# Solution:\nlibrary(dplyr)\nfilter(penguins, species == \"Adelie\")\n\n#&gt; # A tibble: 152 × 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           NA            NA                  NA          NA\n#&gt;  5 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  6 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  7 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  8 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  9 Adelie  Torgersen           34.1          18.1               193        3475\n#&gt; 10 Adelie  Torgersen           42            20.2               190        4250\n#&gt; # ℹ 142 more rows\n#&gt; # ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nTypos, missing functions (objects), and confusion about operators are typical mistakes and some packages return suggestions to fix the problem. Unfortunately, R can also return cryptic error messages, which are often harder to understand."
  },
  {
    "objectID": "chapter_02.html#cryptic-errors",
    "href": "chapter_02.html#cryptic-errors",
    "title": "1  Base R",
    "section": "1.2 Cryptic errors",
    "text": "1.2 Cryptic errors\nNot all error R messages and warnings are cryptic. Suppose you wanted to estimate a mean of an income variable. The variable is not measured numerically which implies that the mean cannot be estimated. Consequently, R warns us about wrong and inconsistent data types.\n\n# Warning: argument is not numeric or logical\nincome &lt;- c(\"More than 10000\", \"0 - 999\", \"2000 - 2999\")\nmean(income)\n\n#&gt; Warning in mean.default(income): argument is not numeric or logical: returning\n#&gt; NA\n\n\nUnfortunately, some errors and warnings seem more like an enigma than useful feedback. Imagine, R tells you that a non-numeric argument has been applied to a binary operator. The next console reproduces the error with two example vectors. The last value of the vector y is a character (e.g., a missing value indicator: NA) and for obvious reasons we cannot multiply x with y as long as we do clean the latter.\n\n# Cryptic error: A non-numeric argument to binary operator\nx &lt;- c(3, 5, 3)\ny &lt;- c(1, 4, \"NA\")\n\nresult &lt;- x * y\n\n#&gt; Error in x * y: non-numeric argument to binary operator\n\nresult\n\n#&gt; Error in eval(expr, envir, enclos): object 'result' not found\n\n\nWe will learn how to fix such problem in a systematic manner later, for now just keep in mind that such an error message might be due to messy, not yet prepared data. Or suppose you tried to estimate the sum but R tells you that the code includes an unexpected numeric constant. Any idea what that means and how to fix the example code of the next console?\n\n#Cryptic error: Unexpected numeric constant\nsum(c(3, 2 1))\n\n#&gt; Error: &lt;text&gt;:2:12: unexpected numeric constant\n#&gt; 1: #Cryptic error: Unexpected numeric constant\n#&gt; 2: sum(c(3, 2 1\n#&gt;               ^\n\n\n\n# Solution:\nsum(c(3, 2, 1))\n\n#&gt; [1] 6\n\n\nR finds an unexpected numeric constant (here 1) because I forgot the last comma inside the c() function. The same applies to strings and characters. R tells us that there is an unexpected string constant. Can you see where?\n\n#Cryptic error: Unexpected string constant\nnames &lt;- c(\"Tom\", \"Diana\"___\"Pete\")\nnames\n\n#&gt; Error: &lt;text&gt;:2:26: unexpected input\n#&gt; 1: #Cryptic error: Unexpected string constant\n#&gt; 2: names &lt;- c(\"Tom\", \"Diana\"_\n#&gt;                             ^\n\n\n\n# Solution:\nnames &lt;- c(\"Tom\", \"Diana\", \"Pete\")\nnames\n\n#&gt; [1] \"Tom\"   \"Diana\" \"Pete\"\n\n\nOr consider unexpected symbols. Can you find the problem of the next console. I used to round function but something went wrong with the digits option.\n\n#Cryptic error: Unexpected symbol\nx &lt;- mean(c(1:3))\nround(x digits = 2)\n\n#&gt; Error: &lt;text&gt;:3:9: unexpected symbol\n#&gt; 2: x &lt;- mean(c(1:3))\n#&gt; 3: round(x digits\n#&gt;            ^\n\n\n\n# Solution:\nx &lt;- mean(c(1:3))\nround(x, digits = 2)\n\n#&gt; [1] 2\n\n\nThus, we introduce a mistake with a function argument because the comma is missing. A similar mistake happens if we forget to provide a necessary argument or provide a wrong one. For example, there is no numbers option of the round function as the next console (and the help files ?round) outline.\n\n# Cryptic error: Unused argument\nx &lt;- mean(c(1:3))\nround(x, numbers = 2)\n\n#&gt; Error in round(x, numbers = 2): unused argument (numbers = 2)\n\n\n\n# Solution:\nx &lt;- mean(c(1:3))\nround(x, digits = 2)\n\n#&gt; [1] 2\n\n\nTry to be patient and be kind to yourself should you run into such an error. You will become better to solve errors, but they will happen all the time. Let me give you one more for the road. Consider the error message: object of type ‘closure’ is not subsettable. R returns this error message if we try to slice a variable that does not exist or if we try to slice a function instead of providing a column vector. Can you fix the next console and provide a column vectors instead of slicing the mean() function?\n\n# Cryptic error: Object of type 'closure' is not subsettable\nmean[1:5]\n\n#&gt; Error in mean[1:5]: object of type 'closure' is not subsettable\n\n\n\n# Solution:\nmean(1:5)\n\n#&gt; [1] 3"
  },
  {
    "objectID": "chapter_02.html#further-sources-of-errors",
    "href": "chapter_02.html#further-sources-of-errors",
    "title": "1  Base R",
    "section": "1.3 Further sources of errors",
    "text": "1.3 Further sources of errors\nThere are further errors and mistakes and this tutorial cannot capture them all. As a minimum, I try to give you a heads-up that it takes time and experience to overcome such problems. For example, consider one more time the small data that we used to slice data in Practice R.\n\n# Save data as df\ndf &lt;- tibble::tribble(\n  ~names, ~year, ~sex,\n  \"Bruno\", 1985, \"male\",\n  \"Justin\", 1994, \"male\",\n  \"Miley\", 1992, \"female\",\n  \"Ariana\", 1993, \"female\"\n)\n\nDo you still remember how to slice the data? Give it a try with the following examples:\n\n# Slice the first column (variable)\ndf[1]\n\n#&gt; # A tibble: 4 × 1\n#&gt;   names \n#&gt;   &lt;chr&gt; \n#&gt; 1 Bruno \n#&gt; 2 Justin\n#&gt; 3 Miley \n#&gt; 4 Ariana\n\n\n\n# First row\ndf[1, ]\n\n#&gt; # A tibble: 1 × 3\n#&gt;   names  year sex  \n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1 Bruno  1985 male\n\n\nSuppose that you have not worked with R for a few weeks, would you still be able to remember how slicing works? We all face the same problems when we start to learn something new: you need several attempts before you understand how to get the desired information. Later, after slicing data many times, you will no longer think about how it works. Thus, be patient and kind to yourself, because some concepts need time and experience to internalize them.\nMoreover, there are often several approaches to reach the same goal and - depending on your preferred style - some are harder or easier to apply. Say you need the names of the stars as a column vector. Can you slice the data or use the $ operator to get the names variable from the data frame?\n\n# Slice or use the $ operator\nnames &lt;- df$names\nnames &lt;- df[1]\nnames\n\n#&gt; # A tibble: 4 × 1\n#&gt;   names \n#&gt;   &lt;chr&gt; \n#&gt; 1 Bruno \n#&gt; 2 Justin\n#&gt; 3 Miley \n#&gt; 4 Ariana\n\n\nUnfortunately, some mistakes are logical in nature and pure practice cannot help us to overcome such problems. Consider the next console. I created a slice function (slice_function) which is supposed to return an element of a vector x, but so far it only returns non-sense. Why does it not return the second element of the input data?\n\n# A pretty messed up slice_function\ndata &lt;- c(3, 9, 1, 5, 8, \"999\", 1)\n\nslice_function &lt;- function(data, x) {\n  data[x]\n}\n\nslice_function(2)\n\n#&gt; [1] 2\n\n\n\n# Solution:\ndata &lt;- c(3, 9, 1, 5, 8, 1)\n\nslice_function &lt;- function(data, x) {\n  data[x]\n}\n\nslice_function(data, x = 2)\n\n#&gt; [1] 9\n\n\nSoon, your code will encompass several steps, try to break it into its separate elements and then examine each step carefully. For example, inspect the vector x to see if error was introduced in the first step. Use the class() function to examine if the input of a variable is as expected (e.g. numerical). If we are sure about the input, we would go on to the next step and so on. Certainly, the last example is not complicated but the complexity of code (and the tasks) will increase from the chapter to chapter. By breaking down all steps into elements, you may realize where the error occurs and how you can fix it."
  },
  {
    "objectID": "chapter_02.html#summary",
    "href": "chapter_02.html#summary",
    "title": "1  Base R",
    "section": "1.4 Summary",
    "text": "1.4 Summary\nAll tutorials of Practice R will end with a short code summary of the corresponding book chapter. The summary only contains the function name from the R help file and code example of the most important functions and packages. In connection with Chapter 2, keep the following functions in mind:\n\nInstall packages from repositories or local files (install.packages)\nLoading/attaching and listing of packages(library)\nInspect the help file (?function)\nCombine Values into a vector or list (c)\nCompare objects (&lt;=, &gt;=, ==, !=)\nReplicate elements of vectors and lists (rep)\nSequence generation (seq)\nSum of vector elements (sum)\nLength of an object (length)\nObject classes (class)\nData frames (data.frame)\nBuild a data frame (tibble::tibble, Müller and Wickham 2022)\nRow-wise tibble creation (tibble::tribble)\nThe number of rows/columns of an array (nrow/ncol)\n\nBase R and many R packages have cheat sheets that summarize the most important features. You can inspect them directly from RStudio (via the &lt;help&gt; tab) and I included the link to the base R cheat sheet in the PracticeR package.\n\n# Cheat sheets summarize the most important features\n# The base R cheat sheet\nPracticeR::show_link(\"base_r\")\n\n\n\n\n\nMüller, Kirill, and Hadley Wickham. 2022. tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "chapter_03.html#categorical-variables",
    "href": "chapter_03.html#categorical-variables",
    "title": "2  Data Exploration",
    "section": "2.1 Categorical variables",
    "text": "2.1 Categorical variables\nWe started to explore categorical variables in Chapter 3 and I outlined a few basics about factor variables. Suppose we want to explore the factor variable island, which indicates where the penguins live. How can you examine unique group levels?\n\n# Inspect the levels() of the penguin's home island\nlevels(df$island)\n\n#&gt; [1] \"Biscoe\"    \"Dream\"     \"Torgersen\"\n\n\nWe will deepen our knowledge about factor variables in Chapter 5, but keep in mind that we can (re-) create and adjust factor() variables. For example, suppose the data looks like a messy character vector for penguin’s sex that I have created in the next console. In such a case it is good to remember that we can give the variable proper text labels (e.g., female for f) and examine the results.\n\n# Example of a messy factor variable\nsex &lt;- c(\"m\", \"f\", \"f\")\n\n# Give clearer labels\nsex &lt;- factor(sex,\n  levels = c(\"f\", \"m\"),\n  labels = c(\"female\", \"male\"),\n)\nhead(sex)\n\n#&gt; [1] male   female female\n#&gt; Levels: female male\n\n\nTables help us to explore data and we used the summarytools package to make frequency and cross tables (Comtois 2022). Keep in mind that we will learn how to create text documents with tables and graphs in Chapter 8. For the moment it is enough to remember that we can create different sort of tables with the summarytools package. For example, create a frequency (freq) table to find out on which island most of the penguins live.\n\n# Create a frequency table\nfreq(df$island)\n\n#&gt; Frequencies  \n#&gt; df$island  \n#&gt; Type: Factor  \n#&gt; \n#&gt;                   Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n#&gt; --------------- ------ --------- -------------- --------- --------------\n#&gt;          Biscoe    168     48.84          48.84     48.84          48.84\n#&gt;           Dream    124     36.05          84.88     36.05          84.88\n#&gt;       Torgersen     52     15.12         100.00     15.12         100.00\n#&gt;            &lt;NA&gt;      0                               0.00         100.00\n#&gt;           Total    344    100.00         100.00    100.00         100.00\n\n\nAs outlined in the book, we can use the table() function to count categorical variables and plot the result as a bar graph. I introduced the latter approach because it is very easy to apply, but our code becomes clearer if we make the necessary steps visible. First, we need to count the levels before we can plot the results. The count() function from the dplyr package does this job (Wickham et al. 2022). It needs only the data frame and the factor variable.\n\n# Count islands with dplyr\ncount_island &lt;- dplyr::count(df, island)\ncount_island\n\n#&gt; # A tibble: 3 × 2\n#&gt;   island        n\n#&gt;   &lt;fct&gt;     &lt;int&gt;\n#&gt; 1 Biscoe      168\n#&gt; 2 Dream       124\n#&gt; 3 Torgersen    52\n\n\nNext, use the assigned results (count_island) and insert the variables into the barplot() function (with the formula y ~ x).\n\n# Create a barplot\nbarplot(n ~ island, data = count_island)\n\n\n\n\n\nIn a similar vein, I introduced functions from the DataExplorer package that help us to get a quick overview (Cui 2020). For example, use the plot_bar() function to depict several or all discrete variables of a data frame.\n\n# Inspect all or several plots at once\nDataExplorer::plot_bar(df[1:2])"
  },
  {
    "objectID": "chapter_03.html#continuous-variables",
    "href": "chapter_03.html#continuous-variables",
    "title": "2  Data Exploration",
    "section": "2.2 Continuous variables",
    "text": "2.2 Continuous variables\nTo explore continuous variables, estimate the summary statistics with the summary() function. Pick one variable such as penguin’s body mass in gram (body_mass_g) or use the entire data frame.\n\n# Get a summary\nsummary(df[1:4])\n\n#&gt;       species          island    bill_length_mm  bill_depth_mm  \n#&gt;  Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n#&gt;  Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n#&gt;  Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n#&gt;                                  Mean   :43.92   Mean   :17.15  \n#&gt;                                  3rd Qu.:48.50   3rd Qu.:18.70  \n#&gt;                                  Max.   :59.60   Max.   :21.50  \n#&gt;                                  NA's   :2       NA's   :2\n\n\nThe classic approach to visualize the distribution of a continuous variable is a histogram. Use the hist() function to display the distribution of the penguins body mass.\n\n# Create a histogram\nhist(df$body_mass_g)\n\n\n\n\nKeep in mind that we only explored the data for the first time. We did not clean the data nor did we prepare the variables. We have to be explicit about missing values when we want to apply functions such as the mean. The function returns NA, but only because of a missing values problem. Can you remember how to fix this problem and estimate, for example, the mean?\n\n# Calculate the mean, but what about missing values (na.rm)?\nmean(df$body_mass_g, na.rm = TRUE)\n\n#&gt; [1] 4201.754\n\n\nI picked data that was more or less prepared to be explored, because data preparation needs more time and effort especially in the beginning. For this reason we will learn how to manipulate data in Chapter 4; and Chapter 5 tries to prepare you for own journey. For example, we use packages such as visdat and naniar to identify missing values, as the next console illustrates with two examples (Tierney et al. 2021). The vis_dat() function from the corresponding packages shows us which type of data we have with missing values in gray; while vis_miss() visualizes missing values in general terms. Keep in mind that Chapter 3 did not introduce data preparation steps which are often necessary to explore data and effects between variables.\n\nlibrary(visdat)\n\n# Left plot: vis_dat()\nvis_dat(df)\n\n# Right plot: vis_miss()\nvis_miss(df)"
  },
  {
    "objectID": "chapter_03.html#explore-effects",
    "href": "chapter_03.html#explore-effects",
    "title": "2  Data Exploration",
    "section": "2.3 Explore effects",
    "text": "2.3 Explore effects\nLet’s start with an effect between two categorical variables. There are different packages that provides functions to create (cross) tables, but we used the summarytools package. It even provides a simulated data set which we will use the repeat the steps to create a cross table. The package comes with the tobacco data, which illustrates that smoking is harmful. As the next console shows, it indicates if a person is a smoker and if the person is diseased.\n\nhead(tobacco)[1:8]\n\n#&gt;   gender age age.gr      BMI smoker cigs.per.day diseased      disease\n#&gt; 1      M  75   71 + 29.50225     No            0       No         &lt;NA&gt;\n#&gt; 2      F  35  35-50 26.14989     No            0      Yes Neurological\n#&gt; 3      F  70  51-70 27.53183     No            0       No         &lt;NA&gt;\n#&gt; 4      F  40  35-50 24.05832     No            0       No         &lt;NA&gt;\n#&gt; 5      F  75   71 + 22.77486     No            0      Yes      Hearing\n#&gt; 6      M  38  35-50 21.46412     No            0       No         &lt;NA&gt;\n\n\nUse the ctable function from the summarytools package to make a cross table for these variables. See also what happens if you adjust the prop option. Insert c or t. Furthermore, explore what happens if you set the chisq, OR, or RR option to TRUE.\n\n# Create a cross table with summarytools\nsummarytools::ctable(\n  x = tobacco$smoker,\n  y = tobacco$diseased,\n  prop = \"r\",\n  chisq = TRUE,\n  OR = TRUE\n)\n\n#&gt; Cross-Tabulation, Row Proportions  \n#&gt; smoker * diseased  \n#&gt; Data Frame: tobacco  \n#&gt; \n#&gt; \n#&gt; -------- ---------- ------------- ------------- ---------------\n#&gt;            diseased           Yes            No           Total\n#&gt;   smoker                                                       \n#&gt;      Yes              125 (41.9%)   173 (58.1%)    298 (100.0%)\n#&gt;       No               99 (14.1%)   603 (85.9%)    702 (100.0%)\n#&gt;    Total              224 (22.4%)   776 (77.6%)   1000 (100.0%)\n#&gt; -------- ---------- ------------- ------------- ---------------\n#&gt; \n#&gt; ----------------------------\n#&gt;  Chi.squared   df   p.value \n#&gt; ------------- ---- ---------\n#&gt;    91.7088     1       0    \n#&gt; ----------------------------\n#&gt; \n#&gt; ----------------------------------\n#&gt;  Odds Ratio   Lo - 95%   Hi - 95% \n#&gt; ------------ ---------- ----------\n#&gt;     4.40        3.22       6.02   \n#&gt; ----------------------------------\n\n\nThe prop option lets you determine the proportions: rows (r), columns (c), total (t), or none (n). Furthermore, the function even adds the chi-square statistic (chisq); the odds ratio (OR) or the relative risk (RR) if we set them to TRUE. Never mind if you are not familiar with the latter, the discussed options only illustrated how the summarytools package helps us to explore data and effects.\nIn the social sciences we are often interested in comparing numerical outcomes between categorical variables (groups). For example, one of the penguin’s species has a higher body mass and we can examine which penguins species differ in terms of their body mass (body_mass_g). With base R, the aggregate() function lets us split the data and we are able to estimate the mean for each species.\n\n# Aggregate splits the data into subsets and computes summary statistics\naggregate(df$body_mass_g, list(df$species), FUN = mean, na.rm = TRUE)\n\n#&gt;     Group.1        x\n#&gt; 1    Adelie 3700.662\n#&gt; 2 Chinstrap 3733.088\n#&gt; 3    Gentoo 5076.016\n\n\nTo calculate a group-mean looks quite complicated and I did not introduce the latter since we will systematically work on our skills to manipulate data in the next Chapter. Instead, we used a box plot to explore a continuous outcome between groups. As outlined in the book, box plots can be very helpful to compare groups even though they have graphical limitations since they do not display the data. Keep the boxplot() function in mind and practice one more time how it works. Inspect how penguin’s body mass differs between the species.\n\n# Inspect group differences with a box plot\nboxplot(body_mass_g ~ species, data = df)\n\n\n\n\nIf we examine an effect between two continuous outcomes, we have to keep in mind that the plot function returns a scatter plot and we may insert a regression line with the abline and the lm function. Do you still know how it works? Create a scatter plot to examine the association between the body mass (body_mass_g) and the flipper length (flipper_length_mm) of the penguins.\n\n# Create a scatter plot\nplot(y = df$body_mass_g, x = df$flipper_length_mm)\n\n# And a red regression line\nabline(lm(body_mass_g ~ flipper_length_mm, data = df),\n  col = \"red\"\n)\n\n\n\n\nFurthermore, we learned how to calculate the correlation coefficient. The code of the next console does not work if I apply the cor() with the penguins data. Do you have any idea how to fix the problem?\n\n# Calculate the correlation between x and y\ncor_penguins &lt;- cor(df$body_mass_g, df$flipper_length_mm,\n  use = \"complete\"\n)\ncor_penguins\n\n#&gt; [1] 0.8712018\n\n\nBy the way, the cor() also returns Kendall’s or Spearman’s if you adjust the method option:\n\n# estimate a rank-based measure of association\ncor(x,\n  y = NULL, use = \"complete\",\n  method = c(\"pearson\", \"kendall\", \"spearman\")\n)\n\n\nFinally, the effectsize package helped us with the interpretation of Pearson’s r (and other stats, see Chapter 6). I copied the code from the book; can you adjust it to interpret the effect of the examined variables with the effectsize package (Ben-Shachar et al. 2022)?\n\n\n#&gt; [1] 0.8712018\n\n\n\n# Use effectsize to interpret R\neffectsize::interpret_r(cor_penguins, rules = \"cohen1988\")\n\n#&gt; [1] \"large\"\n#&gt; (Rules: cohen1988)\n\n\n\nThere are more R packages to explore data than I could possibly outline. For example, consider the skimr package (Waring et al. 2022). It skims a data set and returns, for example, a short summary, summary statistics, and missing values. Inspect the vignette and skim() the data frame.\n\n# Inspect skimr package (and vignette)\n# vignette(\"skimr\")\nskimr::skim(df)\n\nOr examine the ggpairs() function from the GGally package (Schloerke et al. 2021). It provides many extensions to create graphs (with ggplot2 see Chapter 7); and it also has functions to explore data and effects. The ggpairs() function returns a graph for a pairwise comparison of all variables. Depending on the data type, it returns bar plots, density plot, or the correlation between variables and combines all plots in one graph.\n\n# GGally: https://ggobi.github.io/ggally/\nGGally::ggpairs(df[2:5])"
  },
  {
    "objectID": "chapter_03.html#summary",
    "href": "chapter_03.html#summary",
    "title": "2  Data Exploration",
    "section": "2.4 Summary",
    "text": "2.4 Summary\nData exploration can be exciting since we explore something new. Unfortunately, it can be painful if the data is complex or messy. For this reason we used a simple and clean data, but we will start to manipulate complex(er) data and prepare messy data soon. Keep the following functions from Chapter 3 in mind:\n\nGet a glimpse of your data (dplyr::glimpse); display the structure of an object (str); and inspect the first or last parts of an object (head/tail)\nCreate a factor variable (factor); levels attributes (levels); object labels (labels)\nSimple cross table (table)\nGet a summary (summary)\nSummary statistics (min, mean, max, sd)\nCorrelation, variance and covariance (matrices) via (cor); or with the correlation package (Makowski et al. 2022)\nGraphs: Bar plots (barplot); histograms (hist), spine plot (spineplot), box plot (boxplot), scatter plot (plot), correlation matrix (corrplot::corrplot)\nPackages:\n\nThe summarytools package provides many tables: (e.g., freq, ctable)\nThe DataExplorer to visualize several variable at once: (e.g., plot_bar)\nThe effectsize package to interpret results: (e.g., interpret_r)\n\n\n\n\n\n\nBen-Shachar, Mattan S., Dominique Makowski, Daniel Lüdecke, Indrajeet Patil, and Brenton M. Wiernik. 2022. effectsize: Indices of Effect Size. https://CRAN.R-project.org/package=effectsize.\n\n\nComtois, Dominic. 2022. summarytools: Tools to Quickly and Neatly Summarize Data. https://CRAN.R-project.org/package=summarytools.\n\n\nCui, Boxuan. 2020. DataExplorer: Automate Data Exploration and Treatment. https://CRAN.R-project.org/package=DataExplorer.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nMakowski, Dominique, Brenton M. Wiernik, Indrajeet Patil, Daniel Lüdecke, and Mattan S. Ben-Shachar. 2022. Correlation: Methods for Correlation Analysis. https://CRAN.R-project.org/package=correlation.\n\n\nMüller, Kirill, and Hadley Wickham. 2022. pillar: Coloured Formatting for Columns. https://CRAN.R-project.org/package=pillar.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nTierney, Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021. naniar: Data Structures, Summaries, and Visualisations for Missing Data. https://CRAN.R-project.org/package=naniar.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu, and Shannon Ellis. 2022. skimr: Compact and Flexible Summaries of Data. https://CRAN.R-project.org/package=skimr.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "chapter_04.html#select",
    "href": "chapter_04.html#select",
    "title": "3  Data manipulation with dplyr",
    "section": "3.1 Select",
    "text": "3.1 Select\nEspecially in case of large and cluttered data, we use select() to specify which variables we work with. For example, pick only one variable such as school degree from the gss2016 data.\n\n# Select a variable\nselect(gss2016, degree)\n\n#&gt; # A tibble: 2,867 × 1\n#&gt;   degree     \n#&gt;   &lt;fct&gt;      \n#&gt; 1 Bachelor   \n#&gt; 2 High School\n#&gt; 3 Bachelor   \n#&gt; 4 High School\n#&gt; 5 Graduate   \n#&gt; # ℹ 2,862 more rows\n\n\nSelect comes with handy functions and applies the same logic as base R. For example, select several columns by providing a start (e.g., id) and endpoint (e.g., degree).\n\n# Select all variables from x to y\nselect(gss2016, id:degree) |&gt; head()\n\n#&gt; # A tibble: 6 × 6\n#&gt;      id ballot       age childs sibs       degree     \n#&gt;   &lt;dbl&gt; &lt;labelled&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;labelled&gt; &lt;fct&gt;      \n#&gt; 1     1 1             47      3 2          Bachelor   \n#&gt; 2     2 2             61      0 3          High School\n#&gt; 3     3 3             72      2 3          Bachelor   \n#&gt; 4     4 1             43      4 3          High School\n#&gt; 5     5 3             55      2 2          Graduate   \n#&gt; # ℹ 1 more row\n\n\nMaybe we need all columns except the variables shown in the last output. Ask for the opposite and insert parentheses and a minus signs to turn the selection around.\n\n# Turn around the selection\nselect(gss2016, -(id:degree)) |&gt; head()\n\n#&gt; # A tibble: 6 × 27\n#&gt;    year race  sex    region     income16 relig marital padeg\n#&gt;   &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;      &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;fct&gt;\n#&gt; 1  2016 White Male   New Engla… $170000… None  Married Grad…\n#&gt; 2  2016 White Male   New Engla… $50000 … None  Never … Lt H…\n#&gt; 3  2016 White Male   New Engla… $75000 … Cath… Married High…\n#&gt; 4  2016 White Female New Engla… $170000… Cath… Married &lt;NA&gt; \n#&gt; 5  2016 White Female New Engla… $170000… None  Married Bach…\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 19 more variables: madeg &lt;fct&gt;, partyid &lt;fct&gt;,\n#&gt; #   polviews &lt;fct&gt;, happy &lt;fct&gt;, partners &lt;fct&gt;,\n#&gt; #   grass &lt;fct&gt;, zodiac &lt;fct&gt;, pres12 &lt;labelled&gt;,\n#&gt; #   wtssall &lt;dbl&gt;, income_rc &lt;fct&gt;, agegrp &lt;fct&gt;,\n#&gt; #   ageq &lt;fct&gt;, siblings &lt;fct&gt;, kids &lt;fct&gt;, religion &lt;fct&gt;,\n#&gt; #   bigregion &lt;fct&gt;, partners_rc &lt;fct&gt;, obama &lt;dbl&gt;, …\n\n\nThe gss2016 data does not contain variables with a running number nor other systematic variable names. However, dplyr helps to select such variables without much effort. Consider toy data with several measurements and running numbers to illustrate how we can select such variables efficiently.\n\n# A new df to illustrate\ndf &lt;- tibble(\n  measurement_1 = 1:3,\n  x1 = 1:3,\n  measurement_2 = 1:3,\n  x2 = 1:3,\n  x3 = 1:3,\n  other_variables = 1\n)\n\nSuppose we measured a variables several times and all start with an identical name (e.g., measurement_). Select all variables which start (or end) with a certain string. Thus, insert the starts_with() function and select all measurement variables.\n\n# Select variables that start with a string\nselect(df, starts_with(\"measurement\"))\n\n#&gt; # A tibble: 3 × 2\n#&gt;   measurement_1 measurement_2\n#&gt;           &lt;int&gt;         &lt;int&gt;\n#&gt; 1             1             1\n#&gt; 2             2             2\n#&gt; 3             3             3\n\n\nOr pick variables with the running number. The num_range functions needs the name (x) and the running number.\n\n# Select based on a running number\nselect(df, num_range(\"x\", 1:3))\n\n#&gt; # A tibble: 3 × 3\n#&gt;      x1    x2    x3\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n#&gt; 1     1     1     1\n#&gt; 2     2     2     2\n#&gt; 3     3     3     3\n\n\nThe package offers more helpers to select variables than I can possibly outline. For example, contains() checks if a variable includes a certain word; matches() let us specify search patterns (regular expression, see Chapter 10); and we can also include other functions to select variables. For example, the is.numeric function checks if an input is numeric and we can combine it with where() to select columns only where the content is numeric.\n\n# Insert a function to select variables\ngss2016 |&gt; select(where(is.numeric))\n\n#&gt; # A tibble: 2,867 × 10\n#&gt;    year    id ballot   age childs sibs  pres12 wtssall obama\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;labe&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lab&gt; &lt;labe&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2016     1 1         47      3 2     3        0.957     0\n#&gt; 2  2016     2 2         61      0 3     1        0.478     1\n#&gt; 3  2016     3 3         72      2 3     2        0.957     0\n#&gt; 4  2016     4 1         43      4 3     2        1.91      0\n#&gt; 5  2016     5 3         55      2 2     1        1.44      1\n#&gt; # ℹ 2,862 more rows\n#&gt; # ℹ 1 more variable: income &lt;dbl&gt;\n\n\nNext, we filter data but since all R outputs are large due to the gss2016 data, let us first create a smaller subset to reduce the size of the output and the length of this document.\n\n# Select a smaller subset for the rest of this tutorial\ngss2016 &lt;- select(PracticeR::gss2016, year:sex, income)"
  },
  {
    "objectID": "chapter_04.html#filter",
    "href": "chapter_04.html#filter",
    "title": "3  Data manipulation with dplyr",
    "section": "3.2 Filter",
    "text": "3.2 Filter\nUse filter() to subset the data. The dplyr filters the data and returns a new data frame depending on the specified conditions. Use one or several relational or logical operators to select observations. For example, suppose you want to analyze persons who have a bachelor’s degree only.\n\n# Apply a filter\ngss2016 |&gt;\n  filter(degree == \"Bachelor\") |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 10\n#&gt;    year    id ballot     age childs sibs  degree race  sex  \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;labell&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lab&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;\n#&gt; 1  2016     1 1           47      3 2     Bache… White Male \n#&gt; 2  2016     3 3           72      2 3     Bache… White Male \n#&gt; 3  2016    37 2           59      2 2     Bache… White Male \n#&gt; 4  2016    38 1           43      2 6     Bache… White Fema…\n#&gt; 5  2016    39 3           58      0 1     Bache… White Fema…\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: income &lt;dbl&gt;\n\n\nCan you adjust the code so that two conditions have to be fulfilled simultaneously. For example, keep only observations from adults (18 years and older) with a bachelor’s degree.\n\n# Combine several conditions\ngss2016 |&gt;\n  filter(degree == \"Bachelor\" & age &gt; 17) |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 10\n#&gt;    year    id ballot     age childs sibs  degree race  sex  \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;labell&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lab&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;\n#&gt; 1  2016     1 1           47      3 2     Bache… White Male \n#&gt; 2  2016     3 3           72      2 3     Bache… White Male \n#&gt; 3  2016    37 2           59      2 2     Bache… White Male \n#&gt; 4  2016    38 1           43      2 6     Bache… White Fema…\n#&gt; 5  2016    39 3           58      0 1     Bache… White Fema…\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: income &lt;dbl&gt;\n\n\nAs outlined, keep your base R skills in mind when selecting or filtering data. For example, keep all degrees but exclude persons who have a Bachelor.\n\n# All degrees, but not! Bachelors\ngss2016 |&gt;\n  filter(degree != \"Bachelor\") |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 10\n#&gt;    year    id ballot     age childs sibs  degree race  sex  \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;labell&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lab&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;\n#&gt; 1  2016     2 2           61      0 3     High … White Male \n#&gt; 2  2016     4 1           43      4 3     High … White Fema…\n#&gt; 3  2016     5 3           55      2 2     Gradu… White Fema…\n#&gt; 4  2016     6 2           53      2 2     Junio… White Fema…\n#&gt; 5  2016     7 1           50      2 2     High … White Male \n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: income &lt;dbl&gt;\n\n\nUse the operators() function from the PracticeR package when you have trouble to remember how logical and relational operators are implemented. The function inserts and runs examples via the console.\n\nPracticeR::operators(\"logical\")\n# ── Logical Operators\n# &gt; x &lt;- TRUE\n# &gt; y &lt;- FALSE\n# &gt; #Elementwise logical AND\n# &gt; x & y == TRUE\n# [1] FALSE\n# &gt; #Elementwise logical OR\n# &gt; x | y == TRUE\n# [1] TRUE\n# &gt; #Elementwise OR\n# &gt; xor(x, y)\n# [1] TRUE\n# &gt; #Logical NOT\n# &gt; !x\n# [1] FALSE\n# &gt; #In operator\n# &gt; 1:3 %in% rep(1:2)\n# [1]  TRUE  TRUE FALSE"
  },
  {
    "objectID": "chapter_04.html#mutate",
    "href": "chapter_04.html#mutate",
    "title": "3  Data manipulation with dplyr",
    "section": "3.3 Mutate",
    "text": "3.3 Mutate\nIn Chapter 4 I outline several ways to generate new variables based on observed ones. For example, raw data often contains a person’s year of birth but not their age. With mutate() we can extend the data frame and estimate such a variable. Unfortunately, the gss2016 has an age variable, but the variable does only reveal their age when the survey was conducted. To recap how mutate() works, recreate their birth year and a recent age variable, say for the year 2023.\n\n# Create birth_year and a recent (year: 2023) age variable\ngss2016 |&gt;\n  select(id, year, age) |&gt;\n  mutate(\n    birth_year = year - age,\n    age_2023 = 2023 - birth_year\n  ) |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 5\n#&gt;      id  year   age birth_year age_2023\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1     1  2016    47       1969       54\n#&gt; 2     2  2016    61       1955       68\n#&gt; 3     3  2016    72       1944       79\n#&gt; 4     4  2016    43       1973       50\n#&gt; 5     5  2016    55       1961       62\n#&gt; # ℹ 1 more row\n\n\nKeep in mind that you can use relational and logical operators, as well other functions (e.g., log, rankings, etc.) to generate new variables. For example, generate a logical variable that indicates whether a person was an adult (older than 17) in the year 2016. The if_else() function helps you with this job.\n\n# In theory: if_else(condition, true, false, missing = NULL)\ngss2016 |&gt;\n  select(id, year, age) |&gt;\n  mutate(adult = if_else(age &gt; 17, TRUE, FALSE)) |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 4\n#&gt;      id  year   age adult\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1     1  2016    47 TRUE \n#&gt; 2     2  2016    61 TRUE \n#&gt; 3     3  2016    72 TRUE \n#&gt; 4     4  2016    43 TRUE \n#&gt; 5     5  2016    55 TRUE \n#&gt; # ℹ 1 more row\n\n\nIn terms of generating new variables, also keep the case_when() function in mind, which provides a very flexible approach. Suppose we need to identify parents with a academic background. Parents educational background has many levels or attributes in the gss2016 data, which makes a first attempt harder to apply (and we learn more about factor variables in Chapter 5). For this reason I created a smaller toy data set and I started to prepare the code. Can you complete it? The variable academic_parents is supposed to identify persons with a high educational background (education) with one or more kids. All other conditions are set to FALSE.\n\n# Data to illustrate\ndf &lt;- data.frame(\n  kids = c(0, 1, 3, 0, NA),\n  educ = c(\"high\", \"low\", \"high\", \"low\", NA)\n)\n\n# In theory: case_when(condition ~ value)\ndf |&gt;\n  mutate(academic_parents = case_when(\n    kids &gt;= 1 & educ == \"high\" ~ \"TRUE\",\n    TRUE ~ \"FALSE\"\n  ))\n\n#&gt;   kids educ academic_parents\n#&gt; 1    0 high            FALSE\n#&gt; 2    1  low            FALSE\n#&gt; 3    3 high             TRUE\n#&gt; 4    0  low            FALSE\n#&gt; 5   NA &lt;NA&gt;            FALSE"
  },
  {
    "objectID": "chapter_04.html#summarize",
    "href": "chapter_04.html#summarize",
    "title": "3  Data manipulation with dplyr",
    "section": "3.4 Summarize",
    "text": "3.4 Summarize\nThe summarize() function collapses several columns into a single row. By the way, the dplyr package understands both, British (e.g., summarise) and American English (e.g. summarize) and it’s up to you to decide which one you prefer.\nLet’s calculate the mean age of the survey participants. As outlined in Practice R, the variable has missing values which is why we need to drop them first. In Chapter 5 we will focus on this problem and we learn more about the consequences of such decisions. I already excluded missing values, can you summarize() the age?\n\n# Exclude missing values but consider the consequences (see Chapter 5)\ngss2016 &lt;- gss2016 |&gt;\n  tidyr::drop_na(age, sex)\n\n# Summarize age\ngss2016 |&gt; summarize(mean_age = mean(age))\n\n#&gt; # A tibble: 1 × 1\n#&gt;   mean_age\n#&gt;      &lt;dbl&gt;\n#&gt; 1     49.2\n\n\nThe dplyr package comes with several help functions to summarize data. For example, to count the number of observation per group (e.g., for sex), split the data by groups (group_by) and apply the n() function.\n\n# County by (sex)\ngss2016 |&gt;\n  group_by(sex) %&gt;%\n  summarize(count = n())\n\n#&gt; # A tibble: 2 × 2\n#&gt;   sex    count\n#&gt;   &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 Male    1272\n#&gt; 2 Female  1585\n\n\nMoreover, compare the groups by calculating the median age instead of the mean; add the standard deviation (sd); and count the number of distinct values (n_distinct) of the degree variable.\n\n# Dplyr has more summary functions\ngss2016 |&gt;\n  group_by(sex) |&gt;\n  summarise(\n    median_age = median(age),\n    sd_age = sd(age),\n    distinct_degree = n_distinct(degree)\n  )\n\n#&gt; # A tibble: 2 × 4\n#&gt;   sex    median_age sd_age distinct_degree\n#&gt;   &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;           &lt;int&gt;\n#&gt; 1 Male           48   17.4               6\n#&gt; 2 Female         50   17.9               6\n\n\nIn the last examples we grouped the data and then collapsed it. The counterpart to group is ungroup() which we may add as a last step to disperse the data again. For example, we can estimate how old men or women are on average and add this information to the original data frame. Use mutate() instead of summarise() to see the logic behind ungroup.\n\n# Mutate ungroups the data again\ngss2016 |&gt;\n  select(id, sex, age) |&gt;\n  group_by(sex) |&gt;\n  mutate(count = round(mean(age), 2))\n\n#&gt; # A tibble: 2,857 × 4\n#&gt; # Groups:   sex [2]\n#&gt;      id sex      age count\n#&gt;   &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1 Male      47  48.3\n#&gt; 2     2 Male      61  48.3\n#&gt; 3     3 Male      72  48.3\n#&gt; 4     4 Female    43  49.8\n#&gt; 5     5 Female    55  49.8\n#&gt; # ℹ 2,852 more rows"
  },
  {
    "objectID": "chapter_04.html#arrange",
    "href": "chapter_04.html#arrange",
    "title": "3  Data manipulation with dplyr",
    "section": "3.5 Arrange",
    "text": "3.5 Arrange\nLast but not least, keep the arrange() function in mind. It is easy to apply and I don’t believe there is much to practice. However, it gives us the chance to repeat how transmute() and the between() function works.\nConsider the steps to build a restricted age sample to examine adults only. Use mutate to create a logical variable (age_filter) that indicates if a person is between 18 and 65. Furthermore, explore the difference between mutate() and transmute() if you can’t remember it.\n\n# Create a restricted analysis sample\n# between: x &gt;= left & x &lt;= right\ngss2016 |&gt;\n  transmute(age,\n    age_filter = between(age, 18, 65)\n  )\n\n#&gt; # A tibble: 2,857 × 2\n#&gt;     age age_filter\n#&gt;   &lt;dbl&gt; &lt;lgl&gt;     \n#&gt; 1    47 TRUE      \n#&gt; 2    61 TRUE      \n#&gt; 3    72 FALSE     \n#&gt; 4    43 TRUE      \n#&gt; 5    55 TRUE      \n#&gt; # ℹ 2,852 more rows\n\n\nNext, we need a filter() to restrict the sample, but how can we know that code worked? We can inspect the entire data frame with View, but we can also use arrange() to inspect if the filter was correctly applied. Sort in ascending and descending (desc) order.\n\n# Filter and arrange the data\ngss2016 |&gt;\n  transmute(age,\n    age_filter = between(age, 18, 65)\n  ) |&gt;\n  filter(age_filter == \"TRUE\") |&gt;\n  arrange(desc(age)) |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 2\n#&gt;     age age_filter\n#&gt;   &lt;dbl&gt; &lt;lgl&gt;     \n#&gt; 1    65 TRUE      \n#&gt; 2    65 TRUE      \n#&gt; 3    65 TRUE      \n#&gt; 4    65 TRUE      \n#&gt; 5    65 TRUE      \n#&gt; # ℹ 1 more row\n\n\nThe dplyr package offers many functions to manipulate data and this tutorial only summarizes the main functions. Consider the cheat sheet and the package website for more information.\n\n# The dplyr website\nPracticeR::show_link(\"dplyr\", browse = FALSE)\n#&gt; [1] \"https://dplyr.tidyverse.org/\"\n\nKeep in mind that data preparation steps may appear simple, but only as long as we are not supposed to prepare data on our own. In the latter case we will often need several attempts to come up with a solution that works. Thus, be patient with yourself when your first attempts will not work. Most of the time we all need more than one shot to come up with a workable solution. In addition, we will use the package one more time to combine data in Chapter 5 and other dplyr functions will appear through the Practice R book. Thus, there will be plenty of opportunities to apply and develop your dplyr skills.\nThere are often different approaches that lead to the same result. As the artwork by Jake Clark illustrates and the Practice R info box about data manipulation approaches underlines, the subset() function from base R does essentially the same as dplyr::filter. Base R provides the most stable solution, while dplyr is more verbose and often easier to learn. Don’t perceive them as two different dialects that forces us to stick to one approach. Instead, embrace them both because you will come across different approaches if you use Google to solve a problem. Fortunately, many roads lead to Rome.\n\n\n\nArtwork by Jake Clark"
  },
  {
    "objectID": "chapter_04.html#summary",
    "href": "chapter_04.html#summary",
    "title": "3  Data manipulation with dplyr",
    "section": "3.6 Summary",
    "text": "3.6 Summary\nKeep the main dplyr functions in mind, among them:\n\nKeep rows that match a condition (filter)\nOrder rows using column values (arrange)\nKeep or drop columns using their names and types (select)\nCreate, modify, and delete columns (mutate, transmute)\nSummarize each group down to one row (summarize)\nChange column order (relocate)\nVectorized if-else (if_else)\nA general vectorized if-else (case_when)\nApply a function (or functions) across multiple columns (across)\nSelect all variables or the last variable (e.g., everything)\n\nAnd the following base functions:\n\nThe names of an object (names)\nSub-setting vectors, matrices and data frames (subset)\nApply a function over a list or vector (lapply, sapply)\nRead R code from a file, a connection or expressions (source)\n\n\n\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley. 2022. forcats: Tools for Working with Categorical Variables (Factors). https://CRAN.R-project.org/package=forcats.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "chapter_05.html#inspect-factors",
    "href": "chapter_05.html#inspect-factors",
    "title": "4  Prepare categorical variables",
    "section": "4.1 Inspect factors",
    "text": "4.1 Inspect factors\nSuppose we need to prepare several categorical variables, such as religion (relig) or marital status (marital), for an analysis. To inspect factors, count them with fct_count().\n\n# Count factor variable\nfct_count(df$marital)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                 n\n#&gt;   &lt;fct&gt;         &lt;int&gt;\n#&gt; 1 Married        1212\n#&gt; 2 Widowed         251\n#&gt; 3 Divorced        495\n#&gt; 4 Separated       102\n#&gt; 5 Never Married   806\n#&gt; 6 &lt;NA&gt;              1\n\n\nOr examine the unique levels of a variable with the fct_unique() function:\n\n# How many unique levels do we observe\nfct_unique(df$marital)\n\n#&gt; [1] Married       Widowed       Divorced      Separated     Never Married\n#&gt; [6] &lt;NA&gt;         \n#&gt; Levels: Married Widowed Divorced Separated Never Married"
  },
  {
    "objectID": "chapter_05.html#change-the-order-of-levels",
    "href": "chapter_05.html#change-the-order-of-levels",
    "title": "4  Prepare categorical variables",
    "section": "4.2 Change the order of levels",
    "text": "4.2 Change the order of levels\nThe variable religion (relig) has 13 different levels. Let’s assume we want to control for the largest religious groups only in the analysis. Use the fct_infreq() function to identify how often each level appears.\n\n# fct_infreq: Reorder factor levels by frequency\nf &lt;- fct_infreq(df$relig)\nfct_count(f)\n\n#&gt; # A tibble: 14 × 2\n#&gt;    f                           n\n#&gt;    &lt;fct&gt;                   &lt;int&gt;\n#&gt;  1 Protestant               1371\n#&gt;  2 Catholic                  649\n#&gt;  3 None                      619\n#&gt;  4 Jewish                     51\n#&gt;  5 Other                      44\n#&gt;  6 Christian                  40\n#&gt;  7 Buddhism                   21\n#&gt;  8 Moslem/Islam               19\n#&gt;  9 Hinduism                   13\n#&gt; 10 Orthodox-Christian          7\n#&gt; 11 Inter-Nondenominational     7\n#&gt; 12 Other Eastern               4\n#&gt; 13 Native American             4\n#&gt; 14 &lt;NA&gt;                       18\n\n\nThe fct_infreq() sorts them in order of their frequency, but note we can also order the levels by first appearance (fct_inorder) or in a numeric order (fct_inseq). As the next console illustrates, R sorts levels alphabetically, which is clearly not always a desirable default behavior. Use the fct_inorder() to sort them by appearance.\n\n# Example factor\nf &lt;- factor(c(\"b\", \"a\", \"c\"))\nlevels(f)\n\n#&gt; [1] \"a\" \"b\" \"c\"\n\n# fct_inorder: Reorder factor levels by first appearance\nfct_inorder(f)\n\n#&gt; [1] b a c\n#&gt; Levels: b a c\n\n\nCan you still remember how to manually relevel? Use the fct_relevel() and sort the level Never Married at the second position. You can provide a vector with level names or use the after option to change the position of the level.\n\n# Relevel manually\n# f &lt;- fct_relevel(df$marital, c(\"Married\", \"Never Married\"))\nf &lt;- fct_relevel(df$marital, \"Never Married\", after = 1)\nfct_count(f)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                 n\n#&gt;   &lt;fct&gt;         &lt;int&gt;\n#&gt; 1 Married        1212\n#&gt; 2 Never Married   806\n#&gt; 3 Widowed         251\n#&gt; 4 Divorced        495\n#&gt; 5 Separated       102\n#&gt; 6 &lt;NA&gt;              1\n\n\nSometimes we need to turn the order around. Reverse the order of the levels with fct_rev().\n\n# fct_rev: Reverse order of factor levels\nf &lt;- fct_rev(df$marital)\nfct_count(f)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                 n\n#&gt;   &lt;fct&gt;         &lt;int&gt;\n#&gt; 1 Never Married   806\n#&gt; 2 Separated       102\n#&gt; 3 Divorced        495\n#&gt; 4 Widowed         251\n#&gt; 5 Married        1212\n#&gt; 6 &lt;NA&gt;              1"
  },
  {
    "objectID": "chapter_05.html#change-the-value-of-levels",
    "href": "chapter_05.html#change-the-value-of-levels",
    "title": "4  Prepare categorical variables",
    "section": "4.3 Change the value of levels",
    "text": "4.3 Change the value of levels\nThe relig variable has many levels and even has a category named other, since there are so many religious groups. The same logic applies the fct_other() function which collapses all levels but the one we actually need. Create a variable that includes the five largest groups only. Use the fct_other() function and tell R which variables to keep.\n\n# Create a variable with the five largest, rest are others\ndf$relig5 &lt;- fct_other(df$relig,\n  keep = c(\"Protestant\", \"Catholic\", \"None\", \"Jewish\")\n)\n\nfct_count(df$relig5)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f              n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant  1371\n#&gt; 2 Catholic     649\n#&gt; 3 Jewish        51\n#&gt; 4 None         619\n#&gt; 5 Other        159\n#&gt; 6 &lt;NA&gt;          18\n\n\nThe fct_other() function includes in the code the used levels. If we are unconcerned about this information, you can use one of the fct_lump() functions. The function picks between different methods to lump together factor levels. Nowadays the authors recommend to use one of the specific fct_lump_* functions (fct_lump_min, fct_lump_prop, fct_lump_lowfreq) as outlined in the help file. In our case, use the fct_lump_n() function to lump together the most frequent (n) ones.\n\n# Lump uncommon factor together levels into \"other\"\nf &lt;- fct_lump_n(df$relig, n = 5, other_level = \"Further groups\")\nfct_count(f)\n\n#&gt; # A tibble: 7 × 2\n#&gt;   f                  n\n#&gt;   &lt;fct&gt;          &lt;int&gt;\n#&gt; 1 Protestant      1371\n#&gt; 2 Catholic         649\n#&gt; 3 Jewish            51\n#&gt; 4 None             619\n#&gt; 5 Other             44\n#&gt; 6 Further groups   115\n#&gt; 7 &lt;NA&gt;              18\n\n\nNext, we are going to prepare the educational background. The variable degree includes several levels, as the console shows.\n\n# Count degrees\nfct_count(df$degree)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                  n\n#&gt;   &lt;fct&gt;          &lt;int&gt;\n#&gt; 1 Lt High School   328\n#&gt; 2 High School     1461\n#&gt; 3 Junior College   216\n#&gt; 4 Bachelor         536\n#&gt; 5 Graduate         318\n#&gt; 6 &lt;NA&gt;               8\n\n\nWe already used the fct_recode() function to change factor levels by hand. The lowest category of degree is called less than high school but the text label is confusing. Recode the variable, insert the new label in back ticks to replace the old label (Lt High School).\n\n# fct_recode: Change factor levels by hand\nf &lt;- fct_recode(df$degree, `Less than high school` = \"Lt High School\")\nfct_count(f)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                         n\n#&gt;   &lt;fct&gt;                 &lt;int&gt;\n#&gt; 1 Less than high school   328\n#&gt; 2 High School            1461\n#&gt; 3 Junior College          216\n#&gt; 4 Bachelor                536\n#&gt; 5 Graduate                318\n#&gt; 6 &lt;NA&gt;                      8\n\n\nSuppose we want to control only if participants have a high educational background. Use the fct_collapse() function to create a binary dummy variable. The variable should indicate if a person’s educational background is low (Lt High School; High School, and Junior College) or high (Bachelor and Graduate).\n\n# Collapse factor variable\ndf$edu_dummy &lt;- fct_collapse(df$degree,\n  low = c(\n    \"Lt High School\",\n    \"High School\",\n    \"Junior College\"\n  ),\n  high = c(\"Bachelor\", \"Graduate\")\n)\n\nfct_count(df$edu_dummy)\n\n#&gt; # A tibble: 3 × 2\n#&gt;   f         n\n#&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1 low    2005\n#&gt; 2 high    854\n#&gt; 3 &lt;NA&gt;      8"
  },
  {
    "objectID": "chapter_05.html#add-or-drop-levels",
    "href": "chapter_05.html#add-or-drop-levels",
    "title": "4  Prepare categorical variables",
    "section": "4.4 Add or drop levels",
    "text": "4.4 Add or drop levels\nAs always, the forcats package has more to offer than I can outline. For example, suppose we observed the following religion variable.\n\n# New religion variable\nreligion &lt;- factor(\n  x = c(\"Protestant\", \"Jewish\", NA, NA),\n  levels = c(\"Protestant\", \"Jewish\", \"Catholic\")\n)\n\nreligion\n\n#&gt; [1] Protestant Jewish     &lt;NA&gt;       &lt;NA&gt;      \n#&gt; Levels: Protestant Jewish Catholic\n\n\nDid you notice that the variable has a level for Catholic even though we do not observe it. The fct_expand() can be used to expand levels, while the fct_drop() function helps us to get rid of unused levels.\n\n# Drop unused levels\nfct_drop(religion)\n\n#&gt; [1] Protestant Jewish     &lt;NA&gt;       &lt;NA&gt;      \n#&gt; Levels: Protestant Jewish\n\n\nFurthermore, I included missing values on purpose and the latter may have an impact on our analysis. We can make them explicit and include them as a level with fct_na_value_to_level().\n\n# Make NAs explicit\nfct_na_value_to_level(religion, level = \"Missing\")\n\n#&gt; [1] Protestant Jewish     Missing    Missing   \n#&gt; Levels: Protestant Jewish Catholic Missing"
  },
  {
    "objectID": "chapter_05.html#further-steps",
    "href": "chapter_05.html#further-steps",
    "title": "4  Prepare categorical variables",
    "section": "4.5 Further steps",
    "text": "4.5 Further steps\nChapter 5 discussed many steps to prepare data, but of course this was not an all-encompassing list. I introduced data formats and we learned how to combine data given that many official data sets are split into several files. Unfortunately, transforming and combining data can be tricky and we may introduce mistakes if we neglected to prepare and clean the data properly. Thus, it is up to you to assure that the data can be transformed (combined) and further cleaning steps might be necessary.\nInstead of re-running these steps with the gss2016 data, let us explore how the tidyr package can help with the task (Wickham and Girlich 2022). As other packages, tidyr has a cheat sheet and provides a tiny data set that lets us repeat how the functions work. For example, the table4a data is a wide data set with observations of three countries and two years.\n\n# Example wide table\nhead(table4a)\n\n#&gt; # A tibble: 3 × 3\n#&gt;   country     `1999` `2000`\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Afghanistan    745   2666\n#&gt; 2 Brazil       37737  80488\n#&gt; 3 China       212258 213766\n\n\nUse the pivot_longer() function to transform the data. The long data should have a new variable for the year (via names_to) and you can give the values (values_to) to a variable named cases.\n\n# Make em longer\npivot_longer(table4a,\n  cols = 2:3, names_to = \"year\",\n  values_to = \"cases\"\n)\n\n#&gt; # A tibble: 6 × 3\n#&gt;   country     year   cases\n#&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 Afghanistan 1999     745\n#&gt; 2 Afghanistan 2000    2666\n#&gt; 3 Brazil      1999   37737\n#&gt; 4 Brazil      2000   80488\n#&gt; 5 China       1999  212258\n#&gt; 6 China       2000  213766\n\n\nOr consider the table2 data, the variable type has two outcome types (cases and population) which underline why we should transform the data into the wide format.\n\n# Example long table\nhead(table2)\n\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year type           count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999 cases            745\n#&gt; 2 Afghanistan  1999 population  19987071\n#&gt; 3 Afghanistan  2000 cases           2666\n#&gt; 4 Afghanistan  2000 population  20595360\n#&gt; 5 Brazil       1999 cases          37737\n#&gt; 6 Brazil       1999 population 172006362\n\n\nKeep in mind that we need to provide where the names (names_from) and the values (values_from) are coming from to transform the data.\n\n# Make it wider\npivot_wider(table2,\n  names_from = type,\n  values_from = count\n)\n\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year  cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071\n#&gt; 2 Afghanistan  2000   2666   20595360\n#&gt; 3 Brazil       1999  37737  172006362\n#&gt; 4 Brazil       2000  80488  174504898\n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\n\n\nI introduced these data sets because tidyr offers such simple examples in the cheat sheet that demonstrates how we can transform data. In addition, the copycat package has the code snippets from the tidyverse cheat sheets included. As the animation shows, it only takes a few seconds to insert these examples via the add-in. Start with such a simple example if you do not transform and combine data on a regular basis. After you made sure that the code works, adjust it for your purpose, but be careful how the data is transformed.\n\nThe same applies if you need to combine data. The dplyr also offers a small data set to practice mutating joins (Wickham et al. 2022). The band_members data includes names from members of two different music bands; and the band_instruments data includes their instruments.\n\n# Small data to recapture the join_* functions\nband_members\n\n#&gt; # A tibble: 3 × 2\n#&gt;   name  band   \n#&gt;   &lt;chr&gt; &lt;chr&gt;  \n#&gt; 1 Mick  Stones \n#&gt; 2 John  Beatles\n#&gt; 3 Paul  Beatles\n\nband_instruments\n\n#&gt; # A tibble: 3 × 2\n#&gt;   name  plays \n#&gt;   &lt;chr&gt; &lt;chr&gt; \n#&gt; 1 John  guitar\n#&gt; 2 Paul  bass  \n#&gt; 3 Keith guitar\n\n\nUse one of the join function (e.g., inner_join, full_join) to combine the data.\n\n# Mutating joins\nband_members |&gt; inner_join(band_instruments, by = \"name\")\n\n#&gt; # A tibble: 2 × 3\n#&gt;   name  band    plays \n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1 John  Beatles guitar\n#&gt; 2 Paul  Beatles bass\n\nband_members |&gt; full_join(band_instruments, by = \"name\")\n\n#&gt; # A tibble: 4 × 3\n#&gt;   name  band    plays \n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1 Mick  Stones  &lt;NA&gt;  \n#&gt; 2 John  Beatles guitar\n#&gt; 3 Paul  Beatles bass  \n#&gt; 4 Keith &lt;NA&gt;    guitar\n\n# Further joins:\n# band_members |&gt; left_join(band_instruments)\n# band_members |&gt; right_join(band_instruments)\n\n\nFinally, one last word about missing values: make sure you explore the data before you run an analysis, but don’t neglect to inspect missing and implausible values as well. The naniar package has a lot to offer for this task and of course I did not introduce everything it is capable of in Chapter 5. For example, we used the vis_miss() function to visualize missing values, but not the amount of missing values. Give the gg_miss_var() function a try. It returns a lollipop chart to visualize the amount of missing values. To display percentages, set the show_pct option to TRUE.\n\n# Visualize the amount of missing values\nlibrary(naniar)\ngg_miss_var(df, show_pct = TRUE)"
  },
  {
    "objectID": "chapter_05.html#summary",
    "href": "chapter_05.html#summary",
    "title": "4  Prepare categorical variables",
    "section": "4.6 Summary",
    "text": "4.6 Summary\nIn addition to the discussed content, keep the following R functions and packages in mind:\n\nImport data with different packages. For example:\n\nCSV with the readr package (Wickham, Hester, and Bryan 2022)\nExcel with the readxl package (Wickham and Bryan 2022)\nSPSS or Stata with the haven package (Wickham, Miller, and Smith 2022)\n\nConvert objects into numeric (character) vectors (as.numeric, as.character)\nRename columns (dplyr::rename)\nCleans names of an object (janitor::clean_names: Firke 2021)\nCombine data:\n\nPivot data from long to wide (tidyr::pivot_wider)\nPivot data from wide to long (tidyr::pivot_longer)\nMutating joins (dplyr::inner_join, left_join, right_join, full_join)\nFiltering joins (dplyr::semi_join, anti_join)\nSet pperations (base::union, intersect, setdiff, setequal)\n\nMissing (and implausible) values:\n\nThe naniar package and its function to explore missing values (e.g., n_miss, n_complete, vis_miss)\nCheck if something is not available (e.g., base::is.na)\nConvert values to NA (dplyr::na_if)\nDrop rows containing missing values (tidyr::drop_na)\nReplace NAs with specified values (tidyr::replace_na)\n\n\n\n\n\n\nFirke, Sam. 2021. janitor: Simple Tools for Examining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor.\n\n\nTierney, Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021. naniar: Data Structures, Summaries, and Visualisations for Missing Data. https://CRAN.R-project.org/package=naniar.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley. 2022. forcats: Tools for Working with Categorical Variables (Factors). https://CRAN.R-project.org/package=forcats.\n\n\nWickham, Hadley, and Jennifer Bryan. 2022. readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Maximilian Girlich. 2022. tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2022. haven: Import and Export SPSS, Stata and SAS Files. https://CRAN.R-project.org/package=haven."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ben-Shachar, Mattan S., Dominique Makowski, Daniel Lüdecke, Indrajeet\nPatil, and Brenton M. Wiernik. 2022. effectsize: Indices of Effect Size. https://CRAN.R-project.org/package=effectsize.\n\n\nComtois, Dominic. 2022. summarytools: Tools to\nQuickly and Neatly Summarize Data. https://CRAN.R-project.org/package=summarytools.\n\n\nCui, Boxuan. 2020. DataExplorer: Automate Data\nExploration and Treatment. https://CRAN.R-project.org/package=DataExplorer.\n\n\nFirke, Sam. 2021. janitor: Simple Tools for\nExamining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. palmerpenguins: Palmer Archipelago (Antarctica) Penguin\nData. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nMakowski, Dominique, Brenton M. Wiernik, Indrajeet Patil, Daniel\nLüdecke, and Mattan S. Ben-Shachar. 2022. Correlation:\nMethods for Correlation Analysis. https://CRAN.R-project.org/package=correlation.\n\n\nMüller, Kirill, and Hadley Wickham. 2022a. pillar: Coloured Formatting for Columns. https://CRAN.R-project.org/package=pillar.\n\n\n———. 2022b. tibble: Simple Data\nFrames. https://CRAN.R-project.org/package=tibble.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz\nMarbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nTierney, Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021. naniar: Data Structures, Summaries, and Visualisations\nfor Missing Data. https://CRAN.R-project.org/package=naniar.\n\n\nTreischl, Edgar J. 2023. Practice R: An\nInteractive Textbook. De Gruyter Oldenbourg.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia,\nHao Zhu, and Shannon Ellis. 2022. skimr:\nCompact and Flexible Summaries of Data. https://CRAN.R-project.org/package=skimr.\n\n\nWickham, Hadley. 2022. forcats: Tools for\nWorking with Categorical Variables (Factors). https://CRAN.R-project.org/package=forcats.\n\n\nWickham, Hadley, and Jennifer Bryan. 2022. readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022.\ndplyr: A Grammar of Data\nManipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Maximilian Girlich. 2022. tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2022. haven: Import and Export SPSS, Stata and SAS\nFiles. https://CRAN.R-project.org/package=haven."
  }
]