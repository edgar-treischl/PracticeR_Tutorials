[
  {
    "objectID": "index.html#preface",
    "href": "index.html#preface",
    "title": "The Practice R Tutorials",
    "section": "Preface",
    "text": "Preface\nThis website gives access to all tutorials of Practice R (Treischl 2023). Practice R is a text book for the social sciences which provides several tutorials supporting students to learn R. Feel free to inspect the tutorials even if you are not familiar with the book, but keep in mind the tutorials are supposed to complement the Practice R book."
  },
  {
    "objectID": "index.html#the-book",
    "href": "index.html#the-book",
    "title": "The Practice R Tutorials",
    "section": "The book",
    "text": "The book\nMany students learn to analyze data using commercial packages, even though there is an open-source software with cutting-edge possibilities: R, a programming language with countless cool features for applied empirical research.\nPractice R introduces R to social science students, inspiring them to consider R as an excellent choice. In a non-technical pragmatic way, this book covers all typical steps of applied empirical research.\nLearn how to prepare, analyze, and visualize data in R. Discover how to collect data, generate reports, or automate error-prone tasks.\nThe book is accompanied by an R package. This provides further learning materials that include interactive tutorials, challenging you with typical problems of applied research. This way, you can immediately practice the knowledge you have learned. The package also includes the source code of each chapter and templates that help to create reports.\nPractice R has social science students in mind, nonetheless a broader audience may use Practice R to become a proficient R user.\n\nIntroduces R in a non-technical fashion\nCovers typical steps of applied empirical research\nComplemented by interactive tutorials\nWith access to all materials via the Practice R Package\n\n\n\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg."
  },
  {
    "objectID": "chapter_02.html#typical-error-messages",
    "href": "chapter_02.html#typical-error-messages",
    "title": "1  Base R",
    "section": "1.1 Typical error messages",
    "text": "1.1 Typical error messages\nWhat kind of errors do we need to talk about? Sometimes we introduce errors when we are not cautious enough about the code. Spelling mistakes (e.g., typos, missing and wrong characters, etc.) are easy to fix yet hard to find. For example, I tried to use the assignment operator, but something went wrong. Do you know what might be the problem?\n\n#Assigning the values the wrong way\na -&lt; 5\nb -&lt; 3\n\na + b\n\n#&gt; Error in parse(text = input): &lt;text&gt;:2:4: unexpected '&lt;'\n#&gt; 1: #Assigning the values the wrong way\n#&gt; 2: a -&lt;\n#&gt;       ^\n\n\n\n# Keep the short cut for the assignment operator in mind:\n#&lt;Alt/Option&gt; + &lt;-&gt;\n\n# Solution:\na &lt;- 5\nb &lt;- 3\n\na + b\n\n#&gt; [1] 8\n\n\nFinding spelling mistakes in your own code can be hard. There are certainly several reasons, but our human nature to complete text certainly is part of it. This ability gives us the possibility to read fast, but it makes it difficult to see our own mistakes. Don’t get frustrated, it happens even if you have a lot of experience working with R. Thus, check if there are no simple orthographically mistakes - such as typos, missing (extra) parentheses, and commas - which prevents the code from running.\nI highlighted in Chapter 2 that RStudio inserts opening and closing parentheses, which reduces the chance that missing (or wrong) characters create an error, but there is no guarantee that we insert or delete one by chance. Suppose you try to estimate a mean in combination with the round() function. I put a parenthesis at a wrong place, which is why R throws an error. Can you see which parenthesis is causing the problem?\n\n#Check parenthesis\nround(mean(c(1, 4, 6))), digits = 2)\n\n#&gt; Error in parse(text = input): &lt;text&gt;:2:24: unexpected ','\n#&gt; 1: #Check parenthesis\n#&gt; 2: round(mean(c(1, 4, 6))),\n#&gt;                           ^\n\n\n\n# Solution:\nround(mean(c(1, 4, 6)), digits = 2)\n\n#&gt; [1] 3.67\n\n\nThis error is hard to spot, but it illustrates that we need to be careful not to introduce mistakes. Moreover, RStudio gives parentheses that belong together the same color which help us to keep overview. Go to the RStudio menu (via the &lt;Code&gt; tab) and select rainbow parentheses if they are not displayed in color in the Code pane.\nUnfortunately, RStudio cannot help us all the time because some R errors messages (and warnings) are cryptic. There are even typical errors messages that are quite obscure for beginners. For example, R tells me all the time that it can’t find an object, functions, and data. There are several explanations why R throws such an error. If R cannot find an object, check if the object is listed in the environment. If so, you know for sure that the object exists and that other reasons cause the error. R cannot find an object even in the case of a simple typo.\n\n# R cannot find an object due to typos\nmean_a &lt;- mean(1, 2, 3)\nmaen_a\n\n#&gt; Error: object 'maen_a' not found\n\n\n\n# Solution:\nmean_a &lt;- mean(1, 2, 3)\nmean_a\n\n#&gt; [1] 1\n\n\nR tells us that a function (an object) cannot be found if different notations are used. Keep in mind that R is case-sensitive (r vs. R) and cannot apply a function (or find an object) that does not exist, as the next console illustrates. Of course, the same applies if you forgot to execute the function before using it or if the function itself includes an error and cannot be executed. In all these examples R cannot find the function (or object).\n\n# R is case-sensitive\nreturn_fun &lt;- function(x) {\n  return(x)\n}\n\nReturn_fun(c(1, 2, 3))\n\n#&gt; Error in Return_fun(c(1, 2, 3)): could not find function \"Return_fun\"\n\n\n\n# Solution:\nreturn_fun(c(1, 2, 3))\n\n#&gt; [1] 1 2 3\n\n\nWhat is the typical reason why a function from an R package cannot be found? I started to introduce the dplyr package in Chapter 2 (Wickham et al. 2022). Suppose we want to use the select function from the package. To use anything from an R package, we need to load the package with the library() function each time we start (over). Otherwise, R cannot find the function.\n\n# Load the package to use a function from a package\nlibrary(palmerpenguins)\nselect(penguins, species)\n\n#&gt; Error in select(penguins, species): could not find function \"select\"\n\n\n\n# Solution:\ndplyr::select(penguins, species)\n\n#&gt; # A tibble: 344 × 1\n#&gt;    species\n#&gt;    &lt;fct&gt;  \n#&gt;  1 Adelie \n#&gt;  2 Adelie \n#&gt;  3 Adelie \n#&gt;  4 Adelie \n#&gt;  5 Adelie \n#&gt;  6 Adelie \n#&gt;  7 Adelie \n#&gt;  8 Adelie \n#&gt;  9 Adelie \n#&gt; 10 Adelie \n#&gt; # ℹ 334 more rows\n\n\nThe same applies to objects from a package (e.g., data). The .packages() function returns all loaded (attached) packages, but there is no need to keep that in mind. Go to the packages pane and check if a package is installed and loaded. R tells us only that the function cannot be found if we forget to load it first.\n\n# Inspect the loaded packages via the Packages pane\nloaded_packages &lt;- .packages()\nloaded_packages\n\n#&gt; [1] \"palmerpenguins\" \"stats\"          \"graphics\"       \"grDevices\"     \n#&gt; [5] \"utils\"          \"datasets\"       \"methods\"        \"base\"\n\n\nUltimately, suppose we try to import data. Never mind about the code, we focus on this step in Chapter 5 in detail, but R tells us that it cannot open the connection if the file cannot be found in the current working directory.\n\n# Load my mydata\nread.csv(\"mydata.csv\")\n\n#&gt; Warning in file(file, \"rt\"): cannot open file 'mydata.csv': No such file or\n#&gt; directory\n\n\n#&gt; Error in file(file, \"rt\"): cannot open the connection\n\n\nR tells that data, or other files cannot be found because we provided the wrong path to the file. We will learn how to import data later, but keep in mind that R cannot open a file if we search in the wrong place. In Chapter 2, I outlined many possibilities to change the work directory for which RStudio supplies convenient ways. In addition, the getwd() function returns the current work directory in case of any doubts.\n\n# Do we search for files in the right place\ngetwd()\n#&gt; [1] \"C:/Users/Edgar/R/Practice_R/Tutorial/02\"\n\nLoading the right packages and searching in the right place does not imply that we cannot inadvertently introduce mistakes. Suppose you want to apply the filter function from the dplyr package. You copy and adjust the code from an old script, but R returns an error. Can you see where I made the mistake? I tried to create a subset with Adelie penguins only, but dplyr seems to know what the problem might be.\n\n# Mistakes happen all the time ...\nlibrary(dplyr)\nfilter(penguins, species = \"Adelie\")\n\n#&gt; Error in `filter()`:\n#&gt; ! We detected a named input.\n#&gt; ℹ This usually means that you've used `=` instead of `==`.\n#&gt; ℹ Did you mean `species == \"Adelie\"`?\n\n\n\n# Solution:\nlibrary(dplyr)\nfilter(penguins, species == \"Adelie\")\n\n#&gt; # A tibble: 152 × 8\n#&gt;    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#&gt;    &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n#&gt;  1 Adelie  Torgersen           39.1          18.7               181        3750\n#&gt;  2 Adelie  Torgersen           39.5          17.4               186        3800\n#&gt;  3 Adelie  Torgersen           40.3          18                 195        3250\n#&gt;  4 Adelie  Torgersen           NA            NA                  NA          NA\n#&gt;  5 Adelie  Torgersen           36.7          19.3               193        3450\n#&gt;  6 Adelie  Torgersen           39.3          20.6               190        3650\n#&gt;  7 Adelie  Torgersen           38.9          17.8               181        3625\n#&gt;  8 Adelie  Torgersen           39.2          19.6               195        4675\n#&gt;  9 Adelie  Torgersen           34.1          18.1               193        3475\n#&gt; 10 Adelie  Torgersen           42            20.2               190        4250\n#&gt; # ℹ 142 more rows\n#&gt; # ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nTypos, missing functions (objects), and confusion about operators are typical mistakes and some packages return suggestions to fix the problem. Unfortunately, R can also return cryptic error messages, which are often harder to understand."
  },
  {
    "objectID": "chapter_02.html#cryptic-errors",
    "href": "chapter_02.html#cryptic-errors",
    "title": "1  Base R",
    "section": "1.2 Cryptic errors",
    "text": "1.2 Cryptic errors\nNot all error R messages and warnings are cryptic. Suppose you wanted to estimate a mean of an income variable. The variable is not measured numerically which implies that the mean cannot be estimated. Consequently, R warns us about wrong and inconsistent data types.\n\n# Warning: argument is not numeric or logical\nincome &lt;- c(\"More than 10000\", \"0 - 999\", \"2000 - 2999\")\nmean(income)\n\n#&gt; Warning in mean.default(income): argument is not numeric or logical: returning\n#&gt; NA\n\n\nUnfortunately, some errors and warnings seem more like an enigma than useful feedback. Imagine, R tells you that a non-numeric argument has been applied to a binary operator. The next console reproduces the error with two example vectors. The last value of the vector y is a character (e.g., a missing value indicator: NA) and for obvious reasons we cannot multiply x with y as long as we do clean the latter.\n\n# Cryptic error: A non-numeric argument to binary operator\nx &lt;- c(3, 5, 3)\ny &lt;- c(1, 4, \"NA\")\n\nresult &lt;- x * y\n\n#&gt; Error in x * y: non-numeric argument to binary operator\n\nresult\n\n#&gt; Error: object 'result' not found\n\n\nWe will learn how to fix such problem in a systematic manner later, for now just keep in mind that such an error message might be due to messy, not yet prepared data. Or suppose you tried to estimate the sum but R tells you that the code includes an unexpected numeric constant. Any idea what that means and how to fix the example code of the next console?\n\n#Cryptic error: Unexpected numeric constant\nsum(c(3, 2 1))\n\n#&gt; Error in parse(text = input): &lt;text&gt;:2:12: unexpected numeric constant\n#&gt; 1: #Cryptic error: Unexpected numeric constant\n#&gt; 2: sum(c(3, 2 1\n#&gt;               ^\n\n\n\n# Solution:\nsum(c(3, 2, 1))\n\n#&gt; [1] 6\n\n\nR finds an unexpected numeric constant (here 1) because I forgot the last comma inside the c() function. The same applies to strings and characters. R tells us that there is an unexpected string constant. Can you see where?\n\n#Cryptic error: Unexpected string constant\nnames &lt;- c(\"Tom\", \"Diana\"___\"Pete\")\nnames\n\n#&gt; Error in parse(text = input): &lt;text&gt;:2:26: unexpected input\n#&gt; 1: #Cryptic error: Unexpected string constant\n#&gt; 2: names &lt;- c(\"Tom\", \"Diana\"_\n#&gt;                             ^\n\n\n\n# Solution:\nnames &lt;- c(\"Tom\", \"Diana\", \"Pete\")\nnames\n\n#&gt; [1] \"Tom\"   \"Diana\" \"Pete\"\n\n\nOr consider unexpected symbols. Can you find the problem of the next console. I used to round function but something went wrong with the digits option.\n\n#Cryptic error: Unexpected symbol\nx &lt;- mean(c(1:3))\nround(x digits = 2)\n\n#&gt; Error in parse(text = input): &lt;text&gt;:3:9: unexpected symbol\n#&gt; 2: x &lt;- mean(c(1:3))\n#&gt; 3: round(x digits\n#&gt;            ^\n\n\n\n# Solution:\nx &lt;- mean(c(1:3))\nround(x, digits = 2)\n\n#&gt; [1] 2\n\n\nThus, we introduce a mistake with a function argument because the comma is missing. A similar mistake happens if we forget to provide a necessary argument or provide a wrong one. For example, there is no numbers option of the round function as the next console (and the help files ?round) outline.\n\n# Cryptic error: Unused argument\nx &lt;- mean(c(1:3))\nround(x, numbers = 2)\n\n#&gt; Error in round(x, numbers = 2): unused argument (numbers = 2)\n\n\n\n# Solution:\nx &lt;- mean(c(1:3))\nround(x, digits = 2)\n\n#&gt; [1] 2\n\n\nTry to be patient and be kind to yourself should you run into such an error. You will become better to solve errors, but they will happen all the time. Let me give you one more for the road. Consider the error message: object of type ‘closure’ is not subsettable. R returns this error message if we try to slice a variable that does not exist or if we try to slice a function instead of providing a column vector. Can you fix the next console and provide a column vectors instead of slicing the mean() function?\n\n# Cryptic error: Object of type 'closure' is not subsettable\nmean[1:5]\n\n#&gt; Error in mean[1:5]: object of type 'closure' is not subsettable\n\n\n\n# Solution:\nmean(1:5)\n\n#&gt; [1] 3"
  },
  {
    "objectID": "chapter_02.html#further-sources-of-errors",
    "href": "chapter_02.html#further-sources-of-errors",
    "title": "1  Base R",
    "section": "1.3 Further sources of errors",
    "text": "1.3 Further sources of errors\nThere are further errors and mistakes and this tutorial cannot capture them all. As a minimum, I try to give you a heads-up that it takes time and experience to overcome such problems. For example, consider one more time the small data that we used to slice data in Practice R.\n\n# Save data as df\ndf &lt;- tibble::tribble(\n  ~names, ~year, ~sex,\n  \"Bruno\", 1985, \"male\",\n  \"Justin\", 1994, \"male\",\n  \"Miley\", 1992, \"female\",\n  \"Ariana\", 1993, \"female\"\n)\n\nDo you still remember how to slice the data? Give it a try with the following examples:\n\n# Slice the first column (variable)\ndf[1]\n\n#&gt; # A tibble: 4 × 1\n#&gt;   names \n#&gt;   &lt;chr&gt; \n#&gt; 1 Bruno \n#&gt; 2 Justin\n#&gt; 3 Miley \n#&gt; 4 Ariana\n\n\n\n# First row\ndf[1, ]\n\n#&gt; # A tibble: 1 × 3\n#&gt;   names  year sex  \n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1 Bruno  1985 male\n\n\nSuppose that you have not worked with R for a few weeks, would you still be able to remember how slicing works? We all face the same problems when we start to learn something new: you need several attempts before you understand how to get the desired information. Later, after slicing data many times, you will no longer think about how it works. Thus, be patient and kind to yourself, because some concepts need time and experience to internalize them.\nMoreover, there are often several approaches to reach the same goal and - depending on your preferred style - some are harder or easier to apply. Say you need the names of the stars as a column vector. Can you slice the data or use the $ operator to get the names variable from the data frame?\n\n# Slice or use the $ operator\nnames &lt;- df$names\nnames &lt;- df[1]\nnames\n\n#&gt; # A tibble: 4 × 1\n#&gt;   names \n#&gt;   &lt;chr&gt; \n#&gt; 1 Bruno \n#&gt; 2 Justin\n#&gt; 3 Miley \n#&gt; 4 Ariana\n\n\nUnfortunately, some mistakes are logical in nature and pure practice cannot help us to overcome such problems. Consider the next console. I created a slice function (slice_function) which is supposed to return an element of a vector x, but so far it only returns non-sense. Why does it not return the second element of the input data?\n\n# A pretty messed up slice_function\ndata &lt;- c(3, 9, 1, 5, 8, \"999\", 1)\n\nslice_function &lt;- function(data, x) {\n  data[x]\n}\n\nslice_function(2)\n\n#&gt; [1] 2\n\n\n\n# Solution:\ndata &lt;- c(3, 9, 1, 5, 8, 1)\n\nslice_function &lt;- function(data, x) {\n  data[x]\n}\n\nslice_function(data, x = 2)\n\n#&gt; [1] 9\n\n\nSoon, your code will encompass several steps, try to break it into its separate elements and then examine each step carefully. For example, inspect the vector x to see if error was introduced in the first step. Use the class() function to examine if the input of a variable is as expected (e.g. numerical). If we are sure about the input, we would go on to the next step and so on. Certainly, the last example is not complicated but the complexity of code (and the tasks) will increase from the chapter to chapter. By breaking down all steps into elements, you may realize where the error occurs and how you can fix it."
  },
  {
    "objectID": "chapter_02.html#summary",
    "href": "chapter_02.html#summary",
    "title": "1  Base R",
    "section": "1.4 Summary",
    "text": "1.4 Summary\nAll tutorials of Practice R will end with a short code summary of the corresponding book chapter. The summary only contains the function name from the R help file and code example of the most important functions and packages. In connection with Chapter 2, keep the following functions in mind:\n\nInstall packages from repositories or local files (install.packages)\nLoading/attaching and listing of packages(library)\nInspect the help file (?function)\nCombine Values into a vector or list (c)\nCompare objects (&lt;=, &gt;=, ==, !=)\nReplicate elements of vectors and lists (rep)\nSequence generation (seq)\nSum of vector elements (sum)\nLength of an object (length)\nObject classes (class)\nData frames (data.frame)\nBuild a data frame (tibble::tibble, Müller and Wickham 2022)\nRow-wise tibble creation (tibble::tribble)\nThe number of rows/columns of an array (nrow/ncol)\n\nBase R and many R packages have cheat sheets that summarize the most important features. You can inspect them directly from RStudio (via the &lt;help&gt; tab) and I included the link to the base R cheat sheet in the PracticeR package.\n\n# Cheat sheets summarize the most important features\n# The base R cheat sheet\nPracticeR::show_link(\"base_r\")\n\n\n\n\n\nMüller, Kirill, and Hadley Wickham. 2022. tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "chapter_03.html#categorical-variables",
    "href": "chapter_03.html#categorical-variables",
    "title": "2  Data Exploration",
    "section": "2.1 Categorical variables",
    "text": "2.1 Categorical variables\nWe started to explore categorical variables in Chapter 3 and I outlined a few basics about factor variables. Suppose we want to explore the factor variable island, which indicates where the penguins live. How can you examine unique group levels?\n\n# Inspect the levels() of the penguin's home island\nlevels(df$island)\n\n#&gt; [1] \"Biscoe\"    \"Dream\"     \"Torgersen\"\n\n\nWe will deepen our knowledge about factor variables in Chapter 5, but keep in mind that we can (re-) create and adjust factor() variables. For example, suppose the data looks like a messy character vector for penguin’s sex that I have created in the next console. In such a case it is good to remember that we can give the variable proper text labels (e.g., female for f) and examine the results.\n\n# Example of a messy factor variable\nsex &lt;- c(\"m\", \"f\", \"f\")\n\n# Give clearer labels\nsex &lt;- factor(sex,\n  levels = c(\"f\", \"m\"),\n  labels = c(\"female\", \"male\"),\n)\nhead(sex)\n\n#&gt; [1] male   female female\n#&gt; Levels: female male\n\n\nTables help us to explore data and we used the summarytools package to make frequency and cross tables (Comtois 2022). Keep in mind that we will learn how to create text documents with tables and graphs in Chapter 8. For the moment it is enough to remember that we can create different sort of tables with the summarytools package. For example, create a frequency (freq) table to find out on which island most of the penguins live.\n\n# Create a frequency table\nfreq(df$island)\n\n#&gt; Frequencies  \n#&gt; df$island  \n#&gt; Type: Factor  \n#&gt; \n#&gt;                   Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n#&gt; --------------- ------ --------- -------------- --------- --------------\n#&gt;          Biscoe    168     48.84          48.84     48.84          48.84\n#&gt;           Dream    124     36.05          84.88     36.05          84.88\n#&gt;       Torgersen     52     15.12         100.00     15.12         100.00\n#&gt;            &lt;NA&gt;      0                               0.00         100.00\n#&gt;           Total    344    100.00         100.00    100.00         100.00\n\n\nAs outlined in the book, we can use the table() function to count categorical variables and plot the result as a bar graph. I introduced the latter approach because it is very easy to apply, but our code becomes clearer if we make the necessary steps visible. First, we need to count the levels before we can plot the results. The count() function from the dplyr package does this job (Wickham et al. 2022). It needs only the data frame and the factor variable.\n\n# Count islands with dplyr\ncount_island &lt;- dplyr::count(df, island)\ncount_island\n\n#&gt; # A tibble: 3 × 2\n#&gt;   island        n\n#&gt;   &lt;fct&gt;     &lt;int&gt;\n#&gt; 1 Biscoe      168\n#&gt; 2 Dream       124\n#&gt; 3 Torgersen    52\n\n\nNext, use the assigned results (count_island) and insert the variables into the barplot() function (with the formula y ~ x).\n\n# Create a barplot\nbarplot(n ~ island, data = count_island)\n\n\n\n\n\nIn a similar vein, I introduced functions from the DataExplorer package that help us to get a quick overview (Cui 2020). For example, use the plot_bar() function to depict several or all discrete variables of a data frame.\n\n# Inspect all or several plots at once\nDataExplorer::plot_bar(df[1:2])"
  },
  {
    "objectID": "chapter_03.html#continuous-variables",
    "href": "chapter_03.html#continuous-variables",
    "title": "2  Data Exploration",
    "section": "2.2 Continuous variables",
    "text": "2.2 Continuous variables\nTo explore continuous variables, estimate the summary statistics with the summary() function. Pick one variable such as penguin’s body mass in gram (body_mass_g) or use the entire data frame.\n\n# Get a summary\nsummary(df[1:4])\n\n#&gt;       species          island    bill_length_mm  bill_depth_mm  \n#&gt;  Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n#&gt;  Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n#&gt;  Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n#&gt;                                  Mean   :43.92   Mean   :17.15  \n#&gt;                                  3rd Qu.:48.50   3rd Qu.:18.70  \n#&gt;                                  Max.   :59.60   Max.   :21.50  \n#&gt;                                  NA's   :2       NA's   :2\n\n\nThe classic approach to visualize the distribution of a continuous variable is a histogram. Use the hist() function to display the distribution of the penguins body mass.\n\n# Create a histogram\nhist(df$body_mass_g)\n\n\n\n\nKeep in mind that we only explored the data for the first time. We did not clean the data nor did we prepare the variables. We have to be explicit about missing values when we want to apply functions such as the mean. The function returns NA, but only because of a missing values problem. Can you remember how to fix this problem and estimate, for example, the mean?\n\n# Calculate the mean, but what about missing values (na.rm)?\nmean(df$body_mass_g, na.rm = TRUE)\n\n#&gt; [1] 4201.754\n\n\nI picked data that was more or less prepared to be explored, because data preparation needs more time and effort especially in the beginning. For this reason we will learn how to manipulate data in Chapter 4; and Chapter 5 tries to prepare you for own journey. For example, we use packages such as visdat and naniar to identify missing values, as the next console illustrates with two examples (Tierney et al. 2021). The vis_dat() function from the corresponding packages shows us which type of data we have with missing values in gray; while vis_miss() visualizes missing values in general terms. Keep in mind that Chapter 3 did not introduce data preparation steps which are often necessary to explore data and effects between variables.\n\nlibrary(visdat)\n\n# Left plot: vis_dat()\nvis_dat(df)\n\n# Right plot: vis_miss()\nvis_miss(df)"
  },
  {
    "objectID": "chapter_03.html#explore-effects",
    "href": "chapter_03.html#explore-effects",
    "title": "2  Data Exploration",
    "section": "2.3 Explore effects",
    "text": "2.3 Explore effects\nLet’s start with an effect between two categorical variables. There are different packages that provides functions to create (cross) tables, but we used the summarytools package. It even provides a simulated data set which we will use the repeat the steps to create a cross table. The package comes with the tobacco data, which illustrates that smoking is harmful. As the next console shows, it indicates if a person is a smoker and if the person is diseased.\n\nhead(tobacco)[1:8]\n\n#&gt;   gender age age.gr      BMI smoker cigs.per.day diseased      disease\n#&gt; 1      M  75   71 + 29.50225     No            0       No         &lt;NA&gt;\n#&gt; 2      F  35  35-50 26.14989     No            0      Yes Neurological\n#&gt; 3      F  70  51-70 27.53183     No            0       No         &lt;NA&gt;\n#&gt; 4      F  40  35-50 24.05832     No            0       No         &lt;NA&gt;\n#&gt; 5      F  75   71 + 22.77486     No            0      Yes      Hearing\n#&gt; 6      M  38  35-50 21.46412     No            0       No         &lt;NA&gt;\n\n\nUse the ctable function from the summarytools package to make a cross table for these variables. See also what happens if you adjust the prop option. Insert c or t. Furthermore, explore what happens if you set the chisq, OR, or RR option to TRUE.\n\n# Create a cross table with summarytools\nsummarytools::ctable(\n  x = tobacco$smoker,\n  y = tobacco$diseased,\n  prop = \"r\",\n  chisq = TRUE,\n  OR = TRUE\n)\n\n#&gt; Cross-Tabulation, Row Proportions  \n#&gt; smoker * diseased  \n#&gt; Data Frame: tobacco  \n#&gt; \n#&gt; \n#&gt; -------- ---------- ------------- ------------- ---------------\n#&gt;            diseased           Yes            No           Total\n#&gt;   smoker                                                       \n#&gt;      Yes              125 (41.9%)   173 (58.1%)    298 (100.0%)\n#&gt;       No               99 (14.1%)   603 (85.9%)    702 (100.0%)\n#&gt;    Total              224 (22.4%)   776 (77.6%)   1000 (100.0%)\n#&gt; -------- ---------- ------------- ------------- ---------------\n#&gt; \n#&gt; ----------------------------\n#&gt;  Chi.squared   df   p.value \n#&gt; ------------- ---- ---------\n#&gt;    91.7088     1       0    \n#&gt; ----------------------------\n#&gt; \n#&gt; ----------------------------------\n#&gt;  Odds Ratio   Lo - 95%   Hi - 95% \n#&gt; ------------ ---------- ----------\n#&gt;     4.40        3.22       6.02   \n#&gt; ----------------------------------\n\n\nThe prop option lets you determine the proportions: rows (r), columns (c), total (t), or none (n). Furthermore, the function even adds the chi-square statistic (chisq); the odds ratio (OR) or the relative risk (RR) if we set them to TRUE. Never mind if you are not familiar with the latter, the discussed options only illustrated how the summarytools package helps us to explore data and effects.\nIn the social sciences we are often interested in comparing numerical outcomes between categorical variables (groups). For example, one of the penguin’s species has a higher body mass and we can examine which penguins species differ in terms of their body mass (body_mass_g). With base R, the aggregate() function lets us split the data and we are able to estimate the mean for each species.\n\n# Aggregate splits the data into subsets and computes summary statistics\naggregate(df$body_mass_g, list(df$species), FUN = mean, na.rm = TRUE)\n\n#&gt;     Group.1        x\n#&gt; 1    Adelie 3700.662\n#&gt; 2 Chinstrap 3733.088\n#&gt; 3    Gentoo 5076.016\n\n\nTo calculate a group-mean looks quite complicated and I did not introduce the latter since we will systematically work on our skills to manipulate data in the next Chapter. Instead, we used a box plot to explore a continuous outcome between groups. As outlined in the book, box plots can be very helpful to compare groups even though they have graphical limitations since they do not display the data. Keep the boxplot() function in mind and practice one more time how it works. Inspect how penguin’s body mass differs between the species.\n\n# Inspect group differences with a box plot\nboxplot(body_mass_g ~ species, data = df)\n\n\n\n\nIf we examine an effect between two continuous outcomes, we have to keep in mind that the plot function returns a scatter plot and we may insert a regression line with the abline and the lm function. Do you still know how it works? Create a scatter plot to examine the association between the body mass (body_mass_g) and the flipper length (flipper_length_mm) of the penguins.\n\n# Create a scatter plot\nplot(y = df$body_mass_g, x = df$flipper_length_mm)\n\n# And a red regression line\nabline(lm(body_mass_g ~ flipper_length_mm, data = df),\n  col = \"red\"\n)\n\n\n\n\nFurthermore, we learned how to calculate the correlation coefficient. The code of the next console does not work if I apply the cor() with the penguins data. Do you have any idea how to fix the problem?\n\n# Calculate the correlation between x and y\ncor_penguins &lt;- cor(df$body_mass_g, df$flipper_length_mm,\n  use = \"complete\"\n)\ncor_penguins\n\n#&gt; [1] 0.8712018\n\n\nBy the way, the cor() also returns Kendall’s or Spearman’s if you adjust the method option:\n\n# estimate a rank-based measure of association\ncor(x,\n  y = NULL, use = \"complete\",\n  method = c(\"pearson\", \"kendall\", \"spearman\")\n)\n\n\nFinally, the effectsize package helped us with the interpretation of Pearson’s r (and other stats, see Chapter 6). I copied the code from the book; can you adjust it to interpret the effect of the examined variables with the effectsize package (Ben-Shachar et al. 2022)?\n\n\n#&gt; [1] 0.8712018\n\n\n\n# Use effectsize to interpret R\neffectsize::interpret_r(cor_penguins, rules = \"cohen1988\")\n\n#&gt; [1] \"large\"\n#&gt; (Rules: cohen1988)\n\n\n\nThere are more R packages to explore data than I could possibly outline. For example, consider the skimr package (Waring et al. 2022). It skims a data set and returns, for example, a short summary, summary statistics, and missing values. Inspect the vignette and skim() the data frame.\n\n# Inspect skimr package (and vignette)\n# vignette(\"skimr\")\nskimr::skim(df)\n\nOr examine the ggpairs() function from the GGally package (Schloerke et al. 2021). It provides many extensions to create graphs (with ggplot2 see Chapter 7); and it also has functions to explore data and effects. The ggpairs() function returns a graph for a pairwise comparison of all variables. Depending on the data type, it returns bar plots, density plot, or the correlation between variables and combines all plots in one graph.\n\n# GGally: https://ggobi.github.io/ggally/\nGGally::ggpairs(df[2:5])"
  },
  {
    "objectID": "chapter_03.html#summary",
    "href": "chapter_03.html#summary",
    "title": "2  Data Exploration",
    "section": "2.4 Summary",
    "text": "2.4 Summary\nData exploration can be exciting since we explore something new. Unfortunately, it can be painful if the data is complex or messy. For this reason we used a simple and clean data, but we will start to manipulate complex(er) data and prepare messy data soon. Keep the following functions from Chapter 3 in mind:\n\nGet a glimpse of your data (dplyr::glimpse); display the structure of an object (str); and inspect the first or last parts of an object (head/tail)\nCreate a factor variable (factor); levels attributes (levels); object labels (labels)\nSimple cross table (table)\nGet a summary (summary)\nSummary statistics (min, mean, max, sd)\nCorrelation, variance and covariance (matrices) via (cor); or with the correlation package (Makowski et al. 2022)\nGraphs: Bar plots (barplot); histograms (hist), spine plot (spineplot), box plot (boxplot), scatter plot (plot), correlation matrix (corrplot::corrplot)\nPackages:\n\nThe summarytools package provides many tables: (e.g., freq, ctable)\nThe DataExplorer to visualize several variable at once: (e.g., plot_bar)\nThe effectsize package to interpret results: (e.g., interpret_r)\n\n\n\n\n\n\nBen-Shachar, Mattan S., Dominique Makowski, Daniel Lüdecke, Indrajeet Patil, and Brenton M. Wiernik. 2022. effectsize: Indices of Effect Size. https://CRAN.R-project.org/package=effectsize.\n\n\nComtois, Dominic. 2022. summarytools: Tools to Quickly and Neatly Summarize Data. https://CRAN.R-project.org/package=summarytools.\n\n\nCui, Boxuan. 2020. DataExplorer: Automate Data Exploration and Treatment. https://CRAN.R-project.org/package=DataExplorer.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nMakowski, Dominique, Brenton M. Wiernik, Indrajeet Patil, Daniel Lüdecke, and Mattan S. Ben-Shachar. 2022. Correlation: Methods for Correlation Analysis. https://CRAN.R-project.org/package=correlation.\n\n\nMüller, Kirill, and Hadley Wickham. 2022. pillar: Coloured Formatting for Columns. https://CRAN.R-project.org/package=pillar.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz Marbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nTierney, Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021. naniar: Data Structures, Summaries, and Visualisations for Missing Data. https://CRAN.R-project.org/package=naniar.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu, and Shannon Ellis. 2022. skimr: Compact and Flexible Summaries of Data. https://CRAN.R-project.org/package=skimr.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "chapter_04.html#select",
    "href": "chapter_04.html#select",
    "title": "3  Data manipulation with dplyr",
    "section": "3.1 Select",
    "text": "3.1 Select\nEspecially in case of large and cluttered data, we use select() to specify which variables we work with. For example, pick only one variable such as school degree from the gss2016 data.\n\n# Select a variable\nselect(gss2016, degree)\n\n#&gt; # A tibble: 2,867 × 1\n#&gt;   degree     \n#&gt;   &lt;fct&gt;      \n#&gt; 1 Bachelor   \n#&gt; 2 High School\n#&gt; 3 Bachelor   \n#&gt; 4 High School\n#&gt; 5 Graduate   \n#&gt; # ℹ 2,862 more rows\n\n\nSelect comes with handy functions and applies the same logic as base R. For example, select several columns by providing a start (e.g., id) and endpoint (e.g., degree).\n\n# Select all variables from x to y\nselect(gss2016, id:degree) |&gt; head()\n\n#&gt; # A tibble: 6 × 6\n#&gt;      id ballot       age childs sibs       degree     \n#&gt;   &lt;dbl&gt; &lt;labelled&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;labelled&gt; &lt;fct&gt;      \n#&gt; 1     1 1             47      3 2          Bachelor   \n#&gt; 2     2 2             61      0 3          High School\n#&gt; 3     3 3             72      2 3          Bachelor   \n#&gt; 4     4 1             43      4 3          High School\n#&gt; 5     5 3             55      2 2          Graduate   \n#&gt; # ℹ 1 more row\n\n\nMaybe we need all columns except the variables shown in the last output. Ask for the opposite and insert parentheses and a minus signs to turn the selection around.\n\n# Turn around the selection\nselect(gss2016, -(id:degree)) |&gt; head()\n\n#&gt; # A tibble: 6 × 27\n#&gt;    year race  sex    region     income16 relig marital padeg\n#&gt;   &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;      &lt;fct&gt;    &lt;fct&gt; &lt;fct&gt;   &lt;fct&gt;\n#&gt; 1  2016 White Male   New Engla… $170000… None  Married Grad…\n#&gt; 2  2016 White Male   New Engla… $50000 … None  Never … Lt H…\n#&gt; 3  2016 White Male   New Engla… $75000 … Cath… Married High…\n#&gt; 4  2016 White Female New Engla… $170000… Cath… Married &lt;NA&gt; \n#&gt; 5  2016 White Female New Engla… $170000… None  Married Bach…\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 19 more variables: madeg &lt;fct&gt;, partyid &lt;fct&gt;,\n#&gt; #   polviews &lt;fct&gt;, happy &lt;fct&gt;, partners &lt;fct&gt;,\n#&gt; #   grass &lt;fct&gt;, zodiac &lt;fct&gt;, pres12 &lt;labelled&gt;,\n#&gt; #   wtssall &lt;dbl&gt;, income_rc &lt;fct&gt;, agegrp &lt;fct&gt;,\n#&gt; #   ageq &lt;fct&gt;, siblings &lt;fct&gt;, kids &lt;fct&gt;, religion &lt;fct&gt;,\n#&gt; #   bigregion &lt;fct&gt;, partners_rc &lt;fct&gt;, obama &lt;dbl&gt;, …\n\n\nThe gss2016 data does not contain variables with a running number nor other systematic variable names. However, dplyr helps to select such variables without much effort. Consider toy data with several measurements and running numbers to illustrate how we can select such variables efficiently.\n\n# A new df to illustrate\ndf &lt;- tibble(\n  measurement_1 = 1:3,\n  x1 = 1:3,\n  measurement_2 = 1:3,\n  x2 = 1:3,\n  x3 = 1:3,\n  other_variables = 1\n)\n\nSuppose we measured a variables several times and all start with an identical name (e.g., measurement_). Select all variables which start (or end) with a certain string. Thus, insert the starts_with() function and select all measurement variables.\n\n# Select variables that start with a string\nselect(df, starts_with(\"measurement\"))\n\n#&gt; # A tibble: 3 × 2\n#&gt;   measurement_1 measurement_2\n#&gt;           &lt;int&gt;         &lt;int&gt;\n#&gt; 1             1             1\n#&gt; 2             2             2\n#&gt; 3             3             3\n\n\nOr pick variables with the running number. The num_range functions needs the name (x) and the running number.\n\n# Select based on a running number\nselect(df, num_range(\"x\", 1:3))\n\n#&gt; # A tibble: 3 × 3\n#&gt;      x1    x2    x3\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n#&gt; 1     1     1     1\n#&gt; 2     2     2     2\n#&gt; 3     3     3     3\n\n\nThe package offers more helpers to select variables than I can possibly outline. For example, contains() checks if a variable includes a certain word; matches() let us specify search patterns (regular expression, see Chapter 10); and we can also include other functions to select variables. For example, the is.numeric function checks if an input is numeric and we can combine it with where() to select columns only where the content is numeric.\n\n# Insert a function to select variables\ngss2016 |&gt; select(where(is.numeric))\n\n#&gt; # A tibble: 2,867 × 10\n#&gt;    year    id ballot   age childs sibs  pres12 wtssall obama\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;labe&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lab&gt; &lt;labe&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2016     1 1         47      3 2     3        0.957     0\n#&gt; 2  2016     2 2         61      0 3     1        0.478     1\n#&gt; 3  2016     3 3         72      2 3     2        0.957     0\n#&gt; 4  2016     4 1         43      4 3     2        1.91      0\n#&gt; 5  2016     5 3         55      2 2     1        1.44      1\n#&gt; # ℹ 2,862 more rows\n#&gt; # ℹ 1 more variable: income &lt;dbl&gt;\n\n\nNext, we filter data but since all R outputs are large due to the gss2016 data, let us first create a smaller subset to reduce the size of the output and the length of this document.\n\n# Select a smaller subset for the rest of this tutorial\ngss2016 &lt;- select(PracticeR::gss2016, year:sex, income)"
  },
  {
    "objectID": "chapter_04.html#filter",
    "href": "chapter_04.html#filter",
    "title": "3  Data manipulation with dplyr",
    "section": "3.2 Filter",
    "text": "3.2 Filter\nUse filter() to subset the data. The dplyr filters the data and returns a new data frame depending on the specified conditions. Use one or several relational or logical operators to select observations. For example, suppose you want to analyze persons who have a bachelor’s degree only.\n\n# Apply a filter\ngss2016 |&gt;\n  filter(degree == \"Bachelor\") |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 10\n#&gt;    year    id ballot     age childs sibs  degree race  sex  \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;labell&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lab&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;\n#&gt; 1  2016     1 1           47      3 2     Bache… White Male \n#&gt; 2  2016     3 3           72      2 3     Bache… White Male \n#&gt; 3  2016    37 2           59      2 2     Bache… White Male \n#&gt; 4  2016    38 1           43      2 6     Bache… White Fema…\n#&gt; 5  2016    39 3           58      0 1     Bache… White Fema…\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: income &lt;dbl&gt;\n\n\nCan you adjust the code so that two conditions have to be fulfilled simultaneously. For example, keep only observations from adults (18 years and older) with a bachelor’s degree.\n\n# Combine several conditions\ngss2016 |&gt;\n  filter(degree == \"Bachelor\" & age &gt; 17) |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 10\n#&gt;    year    id ballot     age childs sibs  degree race  sex  \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;labell&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lab&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;\n#&gt; 1  2016     1 1           47      3 2     Bache… White Male \n#&gt; 2  2016     3 3           72      2 3     Bache… White Male \n#&gt; 3  2016    37 2           59      2 2     Bache… White Male \n#&gt; 4  2016    38 1           43      2 6     Bache… White Fema…\n#&gt; 5  2016    39 3           58      0 1     Bache… White Fema…\n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: income &lt;dbl&gt;\n\n\nAs outlined, keep your base R skills in mind when selecting or filtering data. For example, keep all degrees but exclude persons who have a Bachelor.\n\n# All degrees, but not! Bachelors\ngss2016 |&gt;\n  filter(degree != \"Bachelor\") |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 10\n#&gt;    year    id ballot     age childs sibs  degree race  sex  \n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;labell&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;lab&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;\n#&gt; 1  2016     2 2           61      0 3     High … White Male \n#&gt; 2  2016     4 1           43      4 3     High … White Fema…\n#&gt; 3  2016     5 3           55      2 2     Gradu… White Fema…\n#&gt; 4  2016     6 2           53      2 2     Junio… White Fema…\n#&gt; 5  2016     7 1           50      2 2     High … White Male \n#&gt; # ℹ 1 more row\n#&gt; # ℹ 1 more variable: income &lt;dbl&gt;\n\n\nUse the operators() function from the PracticeR package when you have trouble to remember how logical and relational operators are implemented. The function inserts and runs examples via the console.\n\nPracticeR::operators(\"logical\")\n# ── Logical Operators\n# &gt; x &lt;- TRUE\n# &gt; y &lt;- FALSE\n# &gt; #Elementwise logical AND\n# &gt; x & y == TRUE\n# [1] FALSE\n# &gt; #Elementwise logical OR\n# &gt; x | y == TRUE\n# [1] TRUE\n# &gt; #Elementwise OR\n# &gt; xor(x, y)\n# [1] TRUE\n# &gt; #Logical NOT\n# &gt; !x\n# [1] FALSE\n# &gt; #In operator\n# &gt; 1:3 %in% rep(1:2)\n# [1]  TRUE  TRUE FALSE"
  },
  {
    "objectID": "chapter_04.html#mutate",
    "href": "chapter_04.html#mutate",
    "title": "3  Data manipulation with dplyr",
    "section": "3.3 Mutate",
    "text": "3.3 Mutate\nIn Chapter 4 I outline several ways to generate new variables based on observed ones. For example, raw data often contains a person’s year of birth but not their age. With mutate() we can extend the data frame and estimate such a variable. Unfortunately, the gss2016 has an age variable, but the variable does only reveal their age when the survey was conducted. To recap how mutate() works, recreate their birth year and a recent age variable, say for the year 2023.\n\n# Create birth_year and a recent (year: 2023) age variable\ngss2016 |&gt;\n  select(id, year, age) |&gt;\n  mutate(\n    birth_year = year - age,\n    age_2023 = 2023 - birth_year\n  ) |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 5\n#&gt;      id  year   age birth_year age_2023\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1     1  2016    47       1969       54\n#&gt; 2     2  2016    61       1955       68\n#&gt; 3     3  2016    72       1944       79\n#&gt; 4     4  2016    43       1973       50\n#&gt; 5     5  2016    55       1961       62\n#&gt; # ℹ 1 more row\n\n\nKeep in mind that you can use relational and logical operators, as well other functions (e.g., log, rankings, etc.) to generate new variables. For example, generate a logical variable that indicates whether a person was an adult (older than 17) in the year 2016. The if_else() function helps you with this job.\n\n# In theory: if_else(condition, true, false, missing = NULL)\ngss2016 |&gt;\n  select(id, year, age) |&gt;\n  mutate(adult = if_else(age &gt; 17, TRUE, FALSE)) |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 4\n#&gt;      id  year   age adult\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n#&gt; 1     1  2016    47 TRUE \n#&gt; 2     2  2016    61 TRUE \n#&gt; 3     3  2016    72 TRUE \n#&gt; 4     4  2016    43 TRUE \n#&gt; 5     5  2016    55 TRUE \n#&gt; # ℹ 1 more row\n\n\nIn terms of generating new variables, also keep the case_when() function in mind, which provides a very flexible approach. Suppose we need to identify parents with a academic background. Parents educational background has many levels or attributes in the gss2016 data, which makes a first attempt harder to apply (and we learn more about factor variables in Chapter 5). For this reason I created a smaller toy data set and I started to prepare the code. Can you complete it? The variable academic_parents is supposed to identify persons with a high educational background (education) with one or more kids. All other conditions are set to FALSE.\n\n# Data to illustrate\ndf &lt;- data.frame(\n  kids = c(0, 1, 3, 0, NA),\n  educ = c(\"high\", \"low\", \"high\", \"low\", NA)\n)\n\n# In theory: case_when(condition ~ value)\ndf |&gt;\n  mutate(academic_parents = case_when(\n    kids &gt;= 1 & educ == \"high\" ~ \"TRUE\",\n    TRUE ~ \"FALSE\"\n  ))\n\n#&gt;   kids educ academic_parents\n#&gt; 1    0 high            FALSE\n#&gt; 2    1  low            FALSE\n#&gt; 3    3 high             TRUE\n#&gt; 4    0  low            FALSE\n#&gt; 5   NA &lt;NA&gt;            FALSE"
  },
  {
    "objectID": "chapter_04.html#summarize",
    "href": "chapter_04.html#summarize",
    "title": "3  Data manipulation with dplyr",
    "section": "3.4 Summarize",
    "text": "3.4 Summarize\nThe summarize() function collapses several columns into a single row. By the way, the dplyr package understands both, British (e.g., summarise) and American English (e.g. summarize) and it’s up to you to decide which one you prefer.\nLet’s calculate the mean age of the survey participants. As outlined in Practice R, the variable has missing values which is why we need to drop them first. In Chapter 5 we will focus on this problem and we learn more about the consequences of such decisions. I already excluded missing values, can you summarize() the age?\n\n# Exclude missing values but consider the consequences (see Chapter 5)\ngss2016 &lt;- gss2016 |&gt;\n  tidyr::drop_na(age, sex)\n\n# Summarize age\ngss2016 |&gt; summarize(mean_age = mean(age))\n\n#&gt; # A tibble: 1 × 1\n#&gt;   mean_age\n#&gt;      &lt;dbl&gt;\n#&gt; 1     49.2\n\n\nThe dplyr package comes with several help functions to summarize data. For example, to count the number of observation per group (e.g., for sex), split the data by groups (group_by) and apply the n() function.\n\n# County by (sex)\ngss2016 |&gt;\n  group_by(sex) %&gt;%\n  summarize(count = n())\n\n#&gt; # A tibble: 2 × 2\n#&gt;   sex    count\n#&gt;   &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 Male    1272\n#&gt; 2 Female  1585\n\n\nMoreover, compare the groups by calculating the median age instead of the mean; add the standard deviation (sd); and count the number of distinct values (n_distinct) of the degree variable.\n\n# Dplyr has more summary functions\ngss2016 |&gt;\n  group_by(sex) |&gt;\n  summarise(\n    median_age = median(age),\n    sd_age = sd(age),\n    distinct_degree = n_distinct(degree)\n  )\n\n#&gt; # A tibble: 2 × 4\n#&gt;   sex    median_age sd_age distinct_degree\n#&gt;   &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;           &lt;int&gt;\n#&gt; 1 Male           48   17.4               6\n#&gt; 2 Female         50   17.9               6\n\n\nIn the last examples we grouped the data and then collapsed it. The counterpart to group is ungroup() which we may add as a last step to disperse the data again. For example, we can estimate how old men or women are on average and add this information to the original data frame. Use mutate() instead of summarise() to see the logic behind ungroup.\n\n# Mutate ungroups the data again\ngss2016 |&gt;\n  select(id, sex, age) |&gt;\n  group_by(sex) |&gt;\n  mutate(count = round(mean(age), 2))\n\n#&gt; # A tibble: 2,857 × 4\n#&gt; # Groups:   sex [2]\n#&gt;      id sex      age count\n#&gt;   &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1 Male      47  48.3\n#&gt; 2     2 Male      61  48.3\n#&gt; 3     3 Male      72  48.3\n#&gt; 4     4 Female    43  49.8\n#&gt; 5     5 Female    55  49.8\n#&gt; # ℹ 2,852 more rows"
  },
  {
    "objectID": "chapter_04.html#arrange",
    "href": "chapter_04.html#arrange",
    "title": "3  Data manipulation with dplyr",
    "section": "3.5 Arrange",
    "text": "3.5 Arrange\nLast but not least, keep the arrange() function in mind. It is easy to apply and I don’t believe there is much to practice. However, it gives us the chance to repeat how transmute() and the between() function works.\nConsider the steps to build a restricted age sample to examine adults only. Use mutate to create a logical variable (age_filter) that indicates if a person is between 18 and 65. Furthermore, explore the difference between mutate() and transmute() if you can’t remember it.\n\n# Create a restricted analysis sample\n# between: x &gt;= left & x &lt;= right\ngss2016 |&gt;\n  transmute(age,\n    age_filter = between(age, 18, 65)\n  )\n\n#&gt; # A tibble: 2,857 × 2\n#&gt;     age age_filter\n#&gt;   &lt;dbl&gt; &lt;lgl&gt;     \n#&gt; 1    47 TRUE      \n#&gt; 2    61 TRUE      \n#&gt; 3    72 FALSE     \n#&gt; 4    43 TRUE      \n#&gt; 5    55 TRUE      \n#&gt; # ℹ 2,852 more rows\n\n\nNext, we need a filter() to restrict the sample, but how can we know that code worked? We can inspect the entire data frame with View, but we can also use arrange() to inspect if the filter was correctly applied. Sort in ascending and descending (desc) order.\n\n# Filter and arrange the data\ngss2016 |&gt;\n  transmute(age,\n    age_filter = between(age, 18, 65)\n  ) |&gt;\n  filter(age_filter == \"TRUE\") |&gt;\n  arrange(desc(age)) |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 2\n#&gt;     age age_filter\n#&gt;   &lt;dbl&gt; &lt;lgl&gt;     \n#&gt; 1    65 TRUE      \n#&gt; 2    65 TRUE      \n#&gt; 3    65 TRUE      \n#&gt; 4    65 TRUE      \n#&gt; 5    65 TRUE      \n#&gt; # ℹ 1 more row\n\n\nThe dplyr package offers many functions to manipulate data and this tutorial only summarizes the main functions. Consider the cheat sheet and the package website for more information.\n\n# The dplyr website\nPracticeR::show_link(\"dplyr\", browse = FALSE)\n#&gt; [1] \"https://dplyr.tidyverse.org/\"\n\nKeep in mind that data preparation steps may appear simple, but only as long as we are not supposed to prepare data on our own. In the latter case we will often need several attempts to come up with a solution that works. Thus, be patient with yourself when your first attempts will not work. Most of the time we all need more than one shot to come up with a workable solution. In addition, we will use the package one more time to combine data in Chapter 5 and other dplyr functions will appear through the Practice R book. Thus, there will be plenty of opportunities to apply and develop your dplyr skills.\nThere are often different approaches that lead to the same result. As the artwork by Jake Clark illustrates and the Practice R info box about data manipulation approaches underlines, the subset() function from base R does essentially the same as dplyr::filter. Base R provides the most stable solution, while dplyr is more verbose and often easier to learn. Don’t perceive them as two different dialects that forces us to stick to one approach. Instead, embrace them both because you will come across different approaches if you use Google to solve a problem. Fortunately, many roads lead to Rome.\n\n\n\nArtwork by Jake Clark"
  },
  {
    "objectID": "chapter_04.html#summary",
    "href": "chapter_04.html#summary",
    "title": "3  Data manipulation with dplyr",
    "section": "3.6 Summary",
    "text": "3.6 Summary\nKeep the main dplyr functions in mind, among them:\n\nKeep rows that match a condition (filter)\nOrder rows using column values (arrange)\nKeep or drop columns using their names and types (select)\nCreate, modify, and delete columns (mutate, transmute)\nSummarize each group down to one row (summarize)\nChange column order (relocate)\nVectorized if-else (if_else)\nA general vectorized if-else (case_when)\nApply a function (or functions) across multiple columns (across)\nSelect all variables or the last variable (e.g., everything)\n\nAnd the following base functions:\n\nThe names of an object (names)\nSub-setting vectors, matrices and data frames (subset)\nApply a function over a list or vector (lapply, sapply)\nRead R code from a file, a connection or expressions (source)\n\n\n\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley. 2022. forcats: Tools for Working with Categorical Variables (Factors). https://CRAN.R-project.org/package=forcats.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "chapter_05.html#inspect-factors",
    "href": "chapter_05.html#inspect-factors",
    "title": "4  Prepare categorical variables",
    "section": "4.1 Inspect factors",
    "text": "4.1 Inspect factors\nSuppose we need to prepare several categorical variables, such as religion (relig) or marital status (marital), for an analysis. To inspect factors, count them with fct_count().\n\n# Count factor variable\nfct_count(df$marital)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                 n\n#&gt;   &lt;fct&gt;         &lt;int&gt;\n#&gt; 1 Married        1212\n#&gt; 2 Widowed         251\n#&gt; 3 Divorced        495\n#&gt; 4 Separated       102\n#&gt; 5 Never Married   806\n#&gt; 6 &lt;NA&gt;              1\n\n\nOr examine the unique levels of a variable with the fct_unique() function:\n\n# How many unique levels do we observe\nfct_unique(df$marital)\n\n#&gt; [1] Married       Widowed       Divorced      Separated     Never Married\n#&gt; [6] &lt;NA&gt;         \n#&gt; Levels: Married Widowed Divorced Separated Never Married"
  },
  {
    "objectID": "chapter_05.html#change-the-order-of-levels",
    "href": "chapter_05.html#change-the-order-of-levels",
    "title": "4  Prepare categorical variables",
    "section": "4.2 Change the order of levels",
    "text": "4.2 Change the order of levels\nThe variable religion (relig) has 13 different levels. Let’s assume we want to control for the largest religious groups only in the analysis. Use the fct_infreq() function to identify how often each level appears.\n\n# fct_infreq: Reorder factor levels by frequency\nf &lt;- fct_infreq(df$relig)\nfct_count(f)\n\n#&gt; # A tibble: 14 × 2\n#&gt;    f                           n\n#&gt;    &lt;fct&gt;                   &lt;int&gt;\n#&gt;  1 Protestant               1371\n#&gt;  2 Catholic                  649\n#&gt;  3 None                      619\n#&gt;  4 Jewish                     51\n#&gt;  5 Other                      44\n#&gt;  6 Christian                  40\n#&gt;  7 Buddhism                   21\n#&gt;  8 Moslem/Islam               19\n#&gt;  9 Hinduism                   13\n#&gt; 10 Orthodox-Christian          7\n#&gt; 11 Inter-Nondenominational     7\n#&gt; 12 Other Eastern               4\n#&gt; 13 Native American             4\n#&gt; 14 &lt;NA&gt;                       18\n\n\nThe fct_infreq() sorts them in order of their frequency, but note we can also order the levels by first appearance (fct_inorder) or in a numeric order (fct_inseq). As the next console illustrates, R sorts levels alphabetically, which is clearly not always a desirable default behavior. Use the fct_inorder() to sort them by appearance.\n\n# Example factor\nf &lt;- factor(c(\"b\", \"a\", \"c\"))\nlevels(f)\n\n#&gt; [1] \"a\" \"b\" \"c\"\n\n# fct_inorder: Reorder factor levels by first appearance\nfct_inorder(f)\n\n#&gt; [1] b a c\n#&gt; Levels: b a c\n\n\nCan you still remember how to manually relevel? Use the fct_relevel() and sort the level Never Married at the second position. You can provide a vector with level names or use the after option to change the position of the level.\n\n# Relevel manually\n# f &lt;- fct_relevel(df$marital, c(\"Married\", \"Never Married\"))\nf &lt;- fct_relevel(df$marital, \"Never Married\", after = 1)\nfct_count(f)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                 n\n#&gt;   &lt;fct&gt;         &lt;int&gt;\n#&gt; 1 Married        1212\n#&gt; 2 Never Married   806\n#&gt; 3 Widowed         251\n#&gt; 4 Divorced        495\n#&gt; 5 Separated       102\n#&gt; 6 &lt;NA&gt;              1\n\n\nSometimes we need to turn the order around. Reverse the order of the levels with fct_rev().\n\n# fct_rev: Reverse order of factor levels\nf &lt;- fct_rev(df$marital)\nfct_count(f)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                 n\n#&gt;   &lt;fct&gt;         &lt;int&gt;\n#&gt; 1 Never Married   806\n#&gt; 2 Separated       102\n#&gt; 3 Divorced        495\n#&gt; 4 Widowed         251\n#&gt; 5 Married        1212\n#&gt; 6 &lt;NA&gt;              1"
  },
  {
    "objectID": "chapter_05.html#change-the-value-of-levels",
    "href": "chapter_05.html#change-the-value-of-levels",
    "title": "4  Prepare categorical variables",
    "section": "4.3 Change the value of levels",
    "text": "4.3 Change the value of levels\nThe relig variable has many levels and even has a category named other, since there are so many religious groups. The same logic applies the fct_other() function which collapses all levels but the one we actually need. Create a variable that includes the five largest groups only. Use the fct_other() function and tell R which variables to keep.\n\n# Create a variable with the five largest, rest are others\ndf$relig5 &lt;- fct_other(df$relig,\n  keep = c(\"Protestant\", \"Catholic\", \"None\", \"Jewish\")\n)\n\nfct_count(df$relig5)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f              n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant  1371\n#&gt; 2 Catholic     649\n#&gt; 3 Jewish        51\n#&gt; 4 None         619\n#&gt; 5 Other        159\n#&gt; 6 &lt;NA&gt;          18\n\n\nThe fct_other() function includes in the code the used levels. If we are unconcerned about this information, you can use one of the fct_lump() functions. The function picks between different methods to lump together factor levels. Nowadays the authors recommend to use one of the specific fct_lump_* functions (fct_lump_min, fct_lump_prop, fct_lump_lowfreq) as outlined in the help file. In our case, use the fct_lump_n() function to lump together the most frequent (n) ones.\n\n# Lump uncommon factor together levels into \"other\"\nf &lt;- fct_lump_n(df$relig, n = 5, other_level = \"Further groups\")\nfct_count(f)\n\n#&gt; # A tibble: 7 × 2\n#&gt;   f                  n\n#&gt;   &lt;fct&gt;          &lt;int&gt;\n#&gt; 1 Protestant      1371\n#&gt; 2 Catholic         649\n#&gt; 3 Jewish            51\n#&gt; 4 None             619\n#&gt; 5 Other             44\n#&gt; 6 Further groups   115\n#&gt; 7 &lt;NA&gt;              18\n\n\nNext, we are going to prepare the educational background. The variable degree includes several levels, as the console shows.\n\n# Count degrees\nfct_count(df$degree)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                  n\n#&gt;   &lt;fct&gt;          &lt;int&gt;\n#&gt; 1 Lt High School   328\n#&gt; 2 High School     1461\n#&gt; 3 Junior College   216\n#&gt; 4 Bachelor         536\n#&gt; 5 Graduate         318\n#&gt; 6 &lt;NA&gt;               8\n\n\nWe already used the fct_recode() function to change factor levels by hand. The lowest category of degree is called less than high school but the text label is confusing. Recode the variable, insert the new label in back ticks to replace the old label (Lt High School).\n\n# fct_recode: Change factor levels by hand\nf &lt;- fct_recode(df$degree, `Less than high school` = \"Lt High School\")\nfct_count(f)\n\n#&gt; # A tibble: 6 × 2\n#&gt;   f                         n\n#&gt;   &lt;fct&gt;                 &lt;int&gt;\n#&gt; 1 Less than high school   328\n#&gt; 2 High School            1461\n#&gt; 3 Junior College          216\n#&gt; 4 Bachelor                536\n#&gt; 5 Graduate                318\n#&gt; 6 &lt;NA&gt;                      8\n\n\nSuppose we want to control only if participants have a high educational background. Use the fct_collapse() function to create a binary dummy variable. The variable should indicate if a person’s educational background is low (Lt High School; High School, and Junior College) or high (Bachelor and Graduate).\n\n# Collapse factor variable\ndf$edu_dummy &lt;- fct_collapse(df$degree,\n  low = c(\n    \"Lt High School\",\n    \"High School\",\n    \"Junior College\"\n  ),\n  high = c(\"Bachelor\", \"Graduate\")\n)\n\nfct_count(df$edu_dummy)\n\n#&gt; # A tibble: 3 × 2\n#&gt;   f         n\n#&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1 low    2005\n#&gt; 2 high    854\n#&gt; 3 &lt;NA&gt;      8"
  },
  {
    "objectID": "chapter_05.html#add-or-drop-levels",
    "href": "chapter_05.html#add-or-drop-levels",
    "title": "4  Prepare categorical variables",
    "section": "4.4 Add or drop levels",
    "text": "4.4 Add or drop levels\nAs always, the forcats package has more to offer than I can outline. For example, suppose we observed the following religion variable.\n\n# New religion variable\nreligion &lt;- factor(\n  x = c(\"Protestant\", \"Jewish\", NA, NA),\n  levels = c(\"Protestant\", \"Jewish\", \"Catholic\")\n)\n\nreligion\n\n#&gt; [1] Protestant Jewish     &lt;NA&gt;       &lt;NA&gt;      \n#&gt; Levels: Protestant Jewish Catholic\n\n\nDid you notice that the variable has a level for Catholic even though we do not observe it. The fct_expand() can be used to expand levels, while the fct_drop() function helps us to get rid of unused levels.\n\n# Drop unused levels\nfct_drop(religion)\n\n#&gt; [1] Protestant Jewish     &lt;NA&gt;       &lt;NA&gt;      \n#&gt; Levels: Protestant Jewish\n\n\nFurthermore, I included missing values on purpose and the latter may have an impact on our analysis. We can make them explicit and include them as a level with fct_na_value_to_level().\n\n# Make NAs explicit\nfct_na_value_to_level(religion, level = \"Missing\")\n\n#&gt; [1] Protestant Jewish     Missing    Missing   \n#&gt; Levels: Protestant Jewish Catholic Missing"
  },
  {
    "objectID": "chapter_05.html#further-steps",
    "href": "chapter_05.html#further-steps",
    "title": "4  Prepare categorical variables",
    "section": "4.5 Further steps",
    "text": "4.5 Further steps\nChapter 5 discussed many steps to prepare data, but of course this was not an all-encompassing list. I introduced data formats and we learned how to combine data given that many official data sets are split into several files. Unfortunately, transforming and combining data can be tricky and we may introduce mistakes if we neglected to prepare and clean the data properly. Thus, it is up to you to assure that the data can be transformed (combined) and further cleaning steps might be necessary.\nInstead of re-running these steps with the gss2016 data, let us explore how the tidyr package can help with the task (Wickham and Girlich 2022). As other packages, tidyr has a cheat sheet and provides a tiny data set that lets us repeat how the functions work. For example, the table4a data is a wide data set with observations of three countries and two years.\n\n# Example wide table\nhead(table4a)\n\n#&gt; # A tibble: 3 × 3\n#&gt;   country     `1999` `2000`\n#&gt;   &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 Afghanistan    745   2666\n#&gt; 2 Brazil       37737  80488\n#&gt; 3 China       212258 213766\n\n\nUse the pivot_longer() function to transform the data. The long data should have a new variable for the year (via names_to) and you can give the values (values_to) to a variable named cases.\n\n# Make em longer\npivot_longer(table4a,\n  cols = 2:3, names_to = \"year\",\n  values_to = \"cases\"\n)\n\n#&gt; # A tibble: 6 × 3\n#&gt;   country     year   cases\n#&gt;   &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 Afghanistan 1999     745\n#&gt; 2 Afghanistan 2000    2666\n#&gt; 3 Brazil      1999   37737\n#&gt; 4 Brazil      2000   80488\n#&gt; 5 China       1999  212258\n#&gt; 6 China       2000  213766\n\n\nOr consider the table2 data, the variable type has two outcome types (cases and population) which underline why we should transform the data into the wide format.\n\n# Example long table\nhead(table2)\n\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year type           count\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999 cases            745\n#&gt; 2 Afghanistan  1999 population  19987071\n#&gt; 3 Afghanistan  2000 cases           2666\n#&gt; 4 Afghanistan  2000 population  20595360\n#&gt; 5 Brazil       1999 cases          37737\n#&gt; 6 Brazil       1999 population 172006362\n\n\nKeep in mind that we need to provide where the names (names_from) and the values (values_from) are coming from to transform the data.\n\n# Make it wider\npivot_wider(table2,\n  names_from = type,\n  values_from = count\n)\n\n#&gt; # A tibble: 6 × 4\n#&gt;   country      year  cases population\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071\n#&gt; 2 Afghanistan  2000   2666   20595360\n#&gt; 3 Brazil       1999  37737  172006362\n#&gt; 4 Brazil       2000  80488  174504898\n#&gt; 5 China        1999 212258 1272915272\n#&gt; 6 China        2000 213766 1280428583\n\n\n\nI introduced these data sets because tidyr offers such simple examples in the cheat sheet that demonstrates how we can transform data. In addition, the copycat package has the code snippets from the tidyverse cheat sheets included. As the animation shows, it only takes a few seconds to insert these examples via the add-in. Start with such a simple example if you do not transform and combine data on a regular basis. After you made sure that the code works, adjust it for your purpose, but be careful how the data is transformed.\n\nThe same applies if you need to combine data. The dplyr also offers a small data set to practice mutating joins (Wickham et al. 2022). The band_members data includes names from members of two different music bands; and the band_instruments data includes their instruments.\n\n# Small data to recapture the join_* functions\nband_members\n\n#&gt; # A tibble: 3 × 2\n#&gt;   name  band   \n#&gt;   &lt;chr&gt; &lt;chr&gt;  \n#&gt; 1 Mick  Stones \n#&gt; 2 John  Beatles\n#&gt; 3 Paul  Beatles\n\nband_instruments\n\n#&gt; # A tibble: 3 × 2\n#&gt;   name  plays \n#&gt;   &lt;chr&gt; &lt;chr&gt; \n#&gt; 1 John  guitar\n#&gt; 2 Paul  bass  \n#&gt; 3 Keith guitar\n\n\nUse one of the join function (e.g., inner_join, full_join) to combine the data.\n\n# Mutating joins\nband_members |&gt; inner_join(band_instruments, by = \"name\")\n\n#&gt; # A tibble: 2 × 3\n#&gt;   name  band    plays \n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1 John  Beatles guitar\n#&gt; 2 Paul  Beatles bass\n\nband_members |&gt; full_join(band_instruments, by = \"name\")\n\n#&gt; # A tibble: 4 × 3\n#&gt;   name  band    plays \n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n#&gt; 1 Mick  Stones  &lt;NA&gt;  \n#&gt; 2 John  Beatles guitar\n#&gt; 3 Paul  Beatles bass  \n#&gt; 4 Keith &lt;NA&gt;    guitar\n\n# Further joins:\n# band_members |&gt; left_join(band_instruments)\n# band_members |&gt; right_join(band_instruments)\n\n\nFinally, one last word about missing values: make sure you explore the data before you run an analysis, but don’t neglect to inspect missing and implausible values as well. The naniar package has a lot to offer for this task and of course I did not introduce everything it is capable of in Chapter 5. For example, we used the vis_miss() function to visualize missing values, but not the amount of missing values. Give the gg_miss_var() function a try. It returns a lollipop chart to visualize the amount of missing values. To display percentages, set the show_pct option to TRUE.\n\n# Visualize the amount of missing values\nlibrary(naniar)\ngg_miss_var(df, show_pct = TRUE)"
  },
  {
    "objectID": "chapter_05.html#summary",
    "href": "chapter_05.html#summary",
    "title": "4  Prepare categorical variables",
    "section": "4.6 Summary",
    "text": "4.6 Summary\nIn addition to the discussed content, keep the following R functions and packages in mind:\n\nImport data with different packages. For example:\n\nCSV with the readr package (Wickham, Hester, and Bryan 2022)\nExcel with the readxl package (Wickham and Bryan 2022)\nSPSS or Stata with the haven package (Wickham, Miller, and Smith 2022)\n\nConvert objects into numeric (character) vectors (as.numeric, as.character)\nRename columns (dplyr::rename)\nCleans names of an object (janitor::clean_names: Firke 2021)\nCombine data:\n\nPivot data from long to wide (tidyr::pivot_wider)\nPivot data from wide to long (tidyr::pivot_longer)\nMutating joins (dplyr::inner_join, left_join, right_join, full_join)\nFiltering joins (dplyr::semi_join, anti_join)\nSet pperations (base::union, intersect, setdiff, setequal)\n\nMissing (and implausible) values:\n\nThe naniar package and its function to explore missing values (e.g., n_miss, n_complete, vis_miss)\nCheck if something is not available (e.g., base::is.na)\nConvert values to NA (dplyr::na_if)\nDrop rows containing missing values (tidyr::drop_na)\nReplace NAs with specified values (tidyr::replace_na)\n\n\n\n\n\n\nFirke, Sam. 2021. janitor: Simple Tools for Examining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor.\n\n\nTierney, Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021. naniar: Data Structures, Summaries, and Visualisations for Missing Data. https://CRAN.R-project.org/package=naniar.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley. 2022. forcats: Tools for Working with Categorical Variables (Factors). https://CRAN.R-project.org/package=forcats.\n\n\nWickham, Hadley, and Jennifer Bryan. 2022. readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Maximilian Girlich. 2022. tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2022. haven: Import and Export SPSS, Stata and SAS Files. https://CRAN.R-project.org/package=haven."
  },
  {
    "objectID": "chapter_06.html#estimate-a-linear-regression-analysis",
    "href": "chapter_06.html#estimate-a-linear-regression-analysis",
    "title": "5  Analyze data",
    "section": "5.1 Estimate a linear regression analysis",
    "text": "5.1 Estimate a linear regression analysis\nI used data for teaching purposes to introduce a linear regression analysis in Practice R. This made it possible to focus on the code and its implementation; we did not explore the data, there was no need to clean the data, prepare variables, or deal with missing values. Such steps are necessary to analyze data and the process is not linear: We start to explore the data, we prepare variables, and run a first analysis. However, often we need to circle back to improve the model due to different reasons (e.g. to include control variables, check on implausible values, etc.). Thus, the first estimation results are preliminary and may substantially change during the course of the model development.\nSo, we need to explore the variable first. Suppose we examine the gender wage gap: how large is the effect of sex on income? Explore the distribution of each variable. This gives us an overview how many men and women we observe and whether we may transform the outcome variable in a later step. I already adjusted the graphical parameters (par) to put the two graphs next to each other (mfrow creates one row and two columns). Create a bar plot and a histogram to examine the variables.\n\n# Count sex\ncount_sex &lt;- dplyr::count(df, sex)\n\n# Plot two graphs\npar(mfrow = c(1, 2))\nbarplot(n ~ sex, data = count_sex)\nhist(df$income)\n\n\n\n\nWe may run a first analysis after we have explored the data, cleaned, and prepared the variables. Use the lm() function to estimate a linear regression analysis. The function needs the data and a formula (y ~ x1) to estimate the effect of sex on income.\n\n# The lm function\nlm(income ~ sex, data = df)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = income ~ sex, data = df)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)    sexFemale  \n#&gt;     17.7642      -0.7323\n\n\nSince income is not measured on a numeric scale, this coefficient is hard to interpret, but in accordance with theoretical expectations, females have a lower income. The summary() function helps us with the interpretation of the model. It returns the estimated coefficients, R², and further information about the model. In addition, add a second variable with a plus sign (+) and examine whether the educational background (degree_num) mediates the effect.\n\n# The summary function\nsummary(lm(income ~ sex + degree_num, data = df))\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = income ~ sex + degree_num, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -20.8416  -2.7738   0.9904   3.7014  11.2262 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 10.06283    0.39773  25.300  &lt; 2e-16 ***\n#&gt; sexFemale   -0.83192    0.21199  -3.924 8.92e-05 ***\n#&gt; degree_num   0.69287    0.03285  21.090  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.375 on 2590 degrees of freedom\n#&gt;   (274 observations deleted due to missingness)\n#&gt; Multiple R-squared:   0.15,  Adjusted R-squared:  0.1493 \n#&gt; F-statistic: 228.5 on 2 and 2590 DF,  p-value: &lt; 2.2e-16\n\n\nApparently, the wage gap can’t be explained by the educational background of the participants since sex has a significant effect. Use the predict() function to apply the model. I have already saved the model and I created a new data frame with example values. Apply the model and predict how income changes if degree_num increases; or examine how predicted values differ between male and female participants. Predicting values give you a better intuition about the model.\n\n# The model\nmodel &lt;- lm(income ~ sex + degree_num, data = df)\n\n# Generate example data\nnew_data &lt;- data.frame(\n  sex = c(\"Female\", \"Male\"),\n  degree_num = c(10, 10)\n)\n\n# Apply the model with predict(model, data)\npredict(model, new_data)\n\n#&gt;        1        2 \n#&gt; 16.15957 16.99149\n\n\nFinally, keep in mind that the effectsize package helps us to interpret model parameters such as R² (Ben-Shachar et al. 2022). I have saved the summary as sum_model. Can you extract R² (r.squared) from the latter and interpret it with interpret_r2() function. As default, it uses the Cohen’s rules to interpret the effect size.\n\n# Assign summary of the model\nsum_model &lt;- summary(model)\n\n# Interpret R2\neffectsize::interpret_r2(sum_model$r.squared, rules = \"cohen1988\")\n\n#&gt; [1] \"moderate\"\n#&gt; (Rules: cohen1988)"
  },
  {
    "objectID": "chapter_06.html#develop-the-model",
    "href": "chapter_06.html#develop-the-model",
    "title": "5  Analyze data",
    "section": "5.2 Develop the model",
    "text": "5.2 Develop the model\nAs outlined in Chapter 6, we develop models step by step. We start simple with a bivariate model. We include control variables to inspect how our estimation results change; we examine whether interaction effects mediate the effect; and to which extent an effect is linear. This is not an all-encompassing list, but developing a model step by step implies that we need to compare models to see how the estimation results change between steps. For this purpose we need tables and visualization to compare the estimated models.\nWe already started to develop a model as we included a second independent variable, but our approach made it hard to comprehend how the estimations results change if we add (drop) a variable. Use the huxreg() function from the huxtable package to compare models (Hugh-Jones 2022).\n\n# Models\nm1 &lt;- lm(income ~ sex, data = df)\nm2 &lt;- lm(income ~ sex + degree_num, data = df)\n\n# Develop models step by step\nhuxtable::huxreg(m1, m2)\n\n\n\n\n(1)(2)\n\n(Intercept)17.764 ***10.063 ***\n\n(0.169)   (0.398)   \n\nsexFemale-0.732 ** -0.832 ***\n\n(0.230)   (0.212)   \n\ndegree_num        0.693 ***\n\n        (0.033)   \n\nN2596        2593        \n\nR20.004    0.150    \n\nlogLik-8256.549    -8038.689    \n\nAIC16519.099    16085.377    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nIn addition, use dot-and-whisker plots to compare model graphically. The plot_summs() function from the jtools package only needs the model names (Long 2022).\n\n# jtools returns a dot-and-whisker plot\njtools::plot_summs(m1, m2)\n\n\n\n\nNow that we have established the framework to develop models, let us inspect how we can examine non-linear effects, transform variables, and include interaction effects. Finally we need to check how model changes affect the performance of the model.\nWe have already applied to lm() function when we first created a scatter plot. Since we assume a linear relationship, we should start to examine the effect with a scatter plot in the case of a numerical independent variable. As outlined in Chapter 3, we may insert a regression line with abline and the lm() function. For example, consider the scatter plot for the effect of age on income.\n\n# Create a scatter plot\nplot(y = df$income, x = df$age)\nabline(lm(income ~ age, data = df), col = \"red\")\n\n\n\n\nIt seems though that both variables are not or only weakly related. Does this mean that we are supposed to stop here since there is no (large) effect? A linear regression assumes a linear effect, but the effect of age on income might not be linear. For example, create a squared age variable and including it in second model to examine if age has a non-linear effect. By including a squared variable for age, we can estimate if the effect increases (decreases) for older people.\n\n# Make a squared age variable\ndf$age_sqr &lt;- df$age^2\n\n# Compare models\nm1 &lt;- lm(income ~ age, data = df)\nm2 &lt;- lm(income ~ age + age_sqr, data = df)\nhuxtable::huxreg(m1, m2)\n\n\n\n\n(1)(2)\n\n(Intercept)17.066 ***10.421 ***\n\n(0.343)   (0.880)   \n\nage0.006    0.305 ***\n\n(0.007)   (0.037)   \n\nage_sqr        -0.003 ***\n\n        (0.000)   \n\nN2589        2589        \n\nR20.000    0.026    \n\nlogLik-8238.575    -8205.475    \n\nAIC16483.151    16418.951    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nWe may transform the outcome variable to increase the model fit as well. In the case of income, we often observe many people with little or average income while the amount of people with of a very high income is low. In such a case a logarithm of the income may help to increase the model fit. Keep in mind that the interpretation of the coefficient will change if we transform the variables. Regardless of the interpretation, the transformer() function shows what the distribution of a numerical variable would look like (e.g. log) if you transform it.\n\n# Transform a numerical variable\nPracticeR::transformer(df$income)\n\n\n\n\nNext, we examine interaction effects: I estimated a model with an interaction effect between happy and sex. Certainly, I only included it to repeat how this works, but it implies that the effect of happiness on income is moderated by sex. Regardless of my ad-hoc hypothesis, visualize the effect with cat_plot() function from the interactions package (Long 2021); it needs the model, the name of the predictor (pred) and the moderator variable (modx). As the plots shows, there is no significant interaction effect.\n\n# Interaction of two categorical variables\nlibrary(interactions)\nm3 &lt;- lm(income ~ happy * sex, data = df)\n\n# cat_plot for categorical predictors\ncat_plot(m3, pred = happy, modx = sex)\n\n\n\n\nSuppose we believe there is an interaction between sex and education. We may expect that male participants gain much more advantages from education than female participants. Use the interact_plot() function with the predictor variable (pred) and the moderator (modx) variable. The interval option shows the confidence interval and we can see the overlap.\n\n# Interaction model\nm3 &lt;- lm(income ~ sex * degree_num, data = df)\n\n# Interaction between sex*degree_num\ninteract_plot(m3,\n  pred = degree_num, modx = sex,\n  interval = TRUE, plot.points = FALSE\n)\n\n\n\n\nFinally, keep the performance package in mind when developing models (Lüdecke et al. 2022). Check how the performance changes if you insert a non-linear parameter, include interaction terms or if you compare different model specifications. The compare_performance() function returns several performance indicators and it even creates a radar plot if we assign and plot the results.\n\n# Compare performance\nlibrary(performance)\nperformance_models &lt;- compare_performance(m1, m2,\n  metrics = c(\"AIC\", \"BIC\", \"R2_adj\")\n)\n\n# Compare performance\nperformance_models\n\n#&gt; Comparison of Model Performance Indices\n\n#&gt;Name | Model |   AIC (weights) |   BIC (weights) |  R2 (adj.)\n#&gt;-------------------------------------------------------------\n#&gt;m1   |    lm | 16483.2 (&lt;.001) | 16500.7 (&lt;.001) | -8.117e-05\n#&gt;m2   |    lm | 16419.0 (&gt;.999) | 16442.4 (&gt;.999) |      0.025\n\n\n# Plot results\nplot(performance_models)"
  },
  {
    "objectID": "chapter_06.html#improve-the-model",
    "href": "chapter_06.html#improve-the-model",
    "title": "5  Analyze data",
    "section": "5.3 Improve the model",
    "text": "5.3 Improve the model\nThere are more steps to develop and improve the model. Up to this point we developed the model from a theoretical point of view: we checked if variables interact with each other or in case of a non-linear effect. There is still much room for improvement after we worked off theoretical points. At least we should be aware about the assumptions of a linear regression analysis and the packages that can help us to address such concerns. So, what shall we do if we finalized the first model(s)?\n\n# Final model(s)\nm_all &lt;- lm(income ~ sex + degree_num, data = df)\n\nI introduce the performance package because it gives you a quick overview about potential violations. First, the check_model() returns an overview with several plots to check the model assumptions.\n\n# Get a quick overview\ncheck_model(m_all)\n\nSecond, the package has several check_* functions to examine assumptions individually. For example, what about multicollinearity and heteroscedasticity?\n\n# multicollinearity\ncheck_collinearity(m_all)\n\n#&gt; Check for Multicollinearity\n\n#&gt; Low Correlation\n\n#&gt;       Term  VIF  VIF 95% CI Increased SE Tolerance\n#&gt;        sex 1.00 [1.00, Inf]         1.00      1.00\n#&gt; degree_num 1.00 [1.00, Inf]         1.00      1.00\n#&gt;\n#&gt; Tolerance 95% CI\n#&gt;    [0.00, 1.00]\n#&gt;     [0.00, 1.00]\n\n\n# check_heteroscedasticity\ncheck_heteroscedasticity(m_all)\n\n#&gt; Warning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\nThe last function runs a statistical test to check on the assumptions; in the case of heteroscedasticity we can apply the Breusch & Pagan (1979) test (bptest), which runs in the background. The lmtest package gives you access to such statistical tests (Hothorn et al. 2022).\n\n# Breusch & Pagan test (1979)\nlmtest::bptest(m1)\n\n#&gt; \n#&gt;  studentized Breusch-Pagan test\n#&gt; \n#&gt; data:  m1\n#&gt; BP = 3.2195, df = 1, p-value = 0.07277\n\n\nThe error of our model is heteroscedastic and the estimatr package runs a regression with (cluster) robust standard errors to address this point (Blair et al. 2022). Run a regression with the lm_robust() function and adjust the type of standard errors with the se_type option.\n\n# Robust standard errors\nlibrary(estimatr)\nrobust_model &lt;- lm_robust(income ~ age,\n  data = df,\n  se_type = \"stata\"\n)\n\nsummary(robust_model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm_robust(formula = income ~ age, data = df, se_type = \"stata\")\n#&gt; \n#&gt; Standard error type:  HC1 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)  CI Lower CI Upper   DF\n#&gt; (Intercept) 17.066368   0.348788 48.9305   0.0000 16.382436 17.75030 2587\n#&gt; age          0.005891   0.006638  0.8875   0.3749 -0.007125  0.01891 2587\n#&gt; \n#&gt; Multiple R-squared:  0.0003053 , Adjusted R-squared:  -8.117e-05 \n#&gt; F-statistic: 0.7876 on 1 and 2587 DF,  p-value: 0.3749\n\n\nFinally, one last word about the visualization of regression results. The jtools package provides convenient solutions to create dot-and-whisker plots; and the dotwhisker package lets us customize the graph (Solt and Hu 2021). For this purpose I introduce the package, but this does not mean that we have to build a long and complicated code from the ground up each time we need an individual dot-and-whisker plot. In the next chapter we learn more about ggplot2 which will boost your visualization skills and in a later step we will create functions to create plots efficiently (Wickham et al. 2022).\nThe same applies to the dotwhisker package. Once you have built a graph, you can build your own function to create such plots. Don’t let complicated code scare you off, we’ll soon work on strategies how to create plots without the trouble of memorizing complex code. For example, I created a function called visualize_model() which rebuilds the complicated code to create a dot-and-whisker plot from Chapter 6. However, it only needs the models and the names for each predictor to create the plot.\n\n# visualize_model() runs dotwhisker in the background\nvisualize_model(m_all, p1 = \"Sex\", p2 = \"Education\")"
  },
  {
    "objectID": "chapter_06.html#summary",
    "href": "chapter_06.html#summary",
    "title": "5  Analyze data",
    "section": "5.4 Summary",
    "text": "5.4 Summary\nKeep the following R functions and packages in mind:\n\nFitting linear models (lm)\nModel predictions (predict)\nInterpret coefficient of determination (effectsize::interpret_r2)\nReorder levels of factor (relevel)\nCreate a huxtable to display model output (huxtable::huxreg)\nPlot regression summaries (jtools::plot_summs)\nPlot interaction effects in regression models (e.g., interactions::interact_plot)\nThe performance package and its functions to examine the performance of a model.\n\nCompute the model’s R2 ( r2)\nCompare performance of different models (compare_performance)\nVisual check of model assumptions (e.g.,check_model, check_outliers, check_heteroscedasticity)\n\nTransform a numerical input (PracticeR::transformer)\nExport regression summaries to tables (jtools::export_summs)\nOLS with robust standard errors (estimatr::lm_robust)\nCreate fine tuned dot-and-whisker plots API with the dotwhisker package\n\n\n\n\n\nBen-Shachar, Mattan S., Dominique Makowski, Daniel Lüdecke, Indrajeet Patil, and Brenton M. Wiernik. 2022. effectsize: Indices of Effect Size. https://CRAN.R-project.org/package=effectsize.\n\n\nBlair, Graeme, Jasper Cooper, Alexander Coppock, Macartan Humphreys, and Luke Sonnet. 2022. estimatr: Fast Estimators for Design-Based Inference. https://CRAN.R-project.org/package=estimatr.\n\n\nHothorn, Torsten, Achim Zeileis, Richard W. Farebrother, and Clint Cummins. 2022. lmtest: Testing Linear Regression Models. https://CRAN.R-project.org/package=lmtest.\n\n\nHugh-Jones, David. 2022. huxtable: Easily Create and Style Tables for LaTeX, HTML and Other Formats. https://CRAN.R-project.org/package=huxtable/.\n\n\nLong, Jacob A. 2021. interactions: Comprehensive, User-Friendly Toolkit for Probing Interactions. https://CRAN.R-project.org/package=interactions.\n\n\n———. 2022. jtools: Analysis and Presentation of Social Scientific Data. https://CRAN.R-project.org/package=jtools.\n\n\nLüdecke, Daniel, Dominique Makowski, Mattan S. Ben-Shachar, Indrajeet Patil, Philip Waggoner, and Brenton M. Wiernik. 2022. performance: Assessment of Regression Models Performance. https://CRAN.R-project.org/package=performance.\n\n\nSolt, Frederick, and Yue Hu. 2021. dotwhisker: Dot-and-Whisker Plots of Regression Results. https://CRAN.R-project.org/package=dotwhisker.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2022. ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2."
  },
  {
    "objectID": "chapter_07.html#order-the-data",
    "href": "chapter_07.html#order-the-data",
    "title": "6  Visualize data",
    "section": "6.1 Order the data",
    "text": "6.1 Order the data\nSuppose you created a bar graph to examine cars and their manufacturer (mpg$manufacturer). The data is not important, but we need to learn how to order the levels of a categorical variable. As the next console illustrates, the displayed information is difficult to perceive because the bars are all mixed up. Adjust the levels of a factor variable manually or use the fct_infreq() function from the forcats package to order the data by frequency (Wickham 2022).\n\n#Simple bar graph\np1 &lt;- ggplot(data=mpg, aes(x=manufacturer)) + \n  geom_bar()\n\n#Order the data\np2 &lt;- ggplot(data=mpg, aes(x=fct_infreq(manufacturer))) + \n  geom_bar()\n\np1 + p2\n\n\n\n\nIt is our job is to make the graph and its insights accessible. The example underlines that we need to structure and present the data in a way that leverages the message. The last graph also illustrates that there are many group levels making it difficult to depict them all in one graph even if we ordered the data. Moreover, look at the labels, they are not vertically aligned which makes it hard to read. Remember, the forcats package offers many functions to manipulate factor variables. For example, display only the five largest groups with the fct_lump function and use the coord_flip() function to turn around the axes to align the labels vertically.\n\n# Lump levels with fct_lump\nmpg$manufacturer_max &lt;- fct_lump(mpg$manufacturer, n = 5)\n\n# Left: Plot less levels\np1 &lt;- ggplot(data = mpg, aes(x = fct_infreq(manufacturer_max))) +\n  geom_bar()\n\n# Right: Flip axes\np2 &lt;- ggplot(data = mpg, aes(x = fct_infreq(manufacturer_max))) +\n  geom_bar() +\n  coord_flip()\n\np1 + p2\n\n\n\n\nTo order the data is important, regardless of the graph created. For example, suppose you examine car consumption (mpg$hwy) for different classes of cars (mpg$class) with a box plot. Look at the unsorted plot, can you tell me which level has the highest mean? It is complicated to compare groups without a useful order. Try to apply the fct_reorder() function, because it lets us reorder the class variable by its consumption (hwy).\n\n# A basic plot\np1 &lt;- ggplot(mpg, aes(hwy, class)) +\n  geom_boxplot()\n\n# Use fct_reorder to sort class by their consumption\np2 &lt;- ggplot(mpg, aes(hwy, fct_reorder(class, hwy))) +\n  geom_boxplot()\n\np1 + p2\n\n\n\n\nWe therefore are supposed to order the data and communicate in a coherent way, otherwise the audience may get confused. There are however additional pitfalls when it comes to box plots."
  },
  {
    "objectID": "chapter_07.html#boxplot-pitfalls",
    "href": "chapter_07.html#boxplot-pitfalls",
    "title": "6  Visualize data",
    "section": "6.2 Boxplot pitfalls",
    "text": "6.2 Boxplot pitfalls\nI generated fake data with a group and an outcome variable to illustrate the main concerns against box plots.\n\n# Some fake data\nglimpse(data)\n\n#&gt; Rows: 615\n#&gt; Columns: 2\n#&gt; $ group   &lt;chr&gt; \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A…\n#&gt; $ outcome &lt;dbl&gt; 13.06984, 10.62587, 12.96371, 11.07371, 12.21470, 12.69473, 11…\n\n\nSay you estimated a box plot to examine the differences between the groups. At first glance there seems to be a large differences between groups as the first box plot reveals, but are we comparing on fair grounds? See what happens if you add a geom_jitter(). It displays observations with points, but compared to a geom_point it adds a small amount of random variation to reduce over plotting.\n\n#A Basic geom_boxplot\np1 &lt;- ggplot(data, aes(x = group, y = outcome)) +\n  geom_boxplot()\n\n#Add a geom_jitter(color, size, alpha)\np2 &lt;- ggplot(data, aes(x = group, y = outcome)) +\n  geom_boxplot() +\n  geom_jitter(color = \"#d62828\", \n              size = 0.5, \n              alpha = 0.6)\n\np1 + p2\n\n\n\n\nWe are comparing three different groups, but the amount of observations are unevenly distributed between the groups and we hardly observe any from group C. This becomes visible when using geom_jitter() to add observations, compared to geom_boxplot() which does not display the data. A box plot disguises such problems which is obviously a serious concern.\nThe geom_jitter already improved the graph, what else can we do to fulfill the guiding principles of visualization. For example, include the sample size in the graph to make our reader conscious about the problem. The next steps are a bit trickier to apply: Estimate the sample size per group and assign the results. Use the dplyr::n() function to count observations, but you will need to group the data first (Wickham, François, et al. 2022).\n\n# Estimate sample_size (n) per group\nsample_size &lt;- data |&gt;\n  dplyr::group_by(group) |&gt;\n  dplyr::summarize(num = dplyr::n())\n\nsample_size\n\n#&gt; # A tibble: 3 × 2\n#&gt;   group   num\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 A       100\n#&gt; 2 B       500\n#&gt; 3 C        15\n\n\nTo include the sample size in the graph, we need to combine the group label and the sample size. We can paste text strings together with the paste (and paste0) function, as the next console illustrates. It returns text strings which we can include in the graph.\n\n# Concatenate Strings with paste (and paste0)\npaste(sample_size$group, \"has N =\", sample_size$num, \" observations.\")\n\n#&gt; [1] \"A has N = 100  observations.\" \"B has N = 500  observations.\"\n#&gt; [3] \"C has N = 15  observations.\"\n\n\nFirst, combine both data sets with a left_join(). Second, create a new variable to add the text label. Use the paste function to paste the text label, but also add a new line (\\n) to separate the group name and the text to display the sample size (num).\n\n# Join data and mutate with text labels for group_N\ndata &lt;- data |&gt;\n  dplyr::left_join(sample_size) |&gt;\n  dplyr::mutate(group_N = paste0(group, \"\\n\", \"N=\", num))\n\nhead(data)\n\n#&gt;   group  outcome num  group_N\n#&gt; 1     A 13.06984 100 A\\nN=100\n#&gt; 2     A 10.62587 100 A\\nN=100\n#&gt; 3     A 12.96371 100 A\\nN=100\n#&gt; 4     A 11.07371 100 A\\nN=100\n#&gt; 5     A 12.21470 100 A\\nN=100\n#&gt; 6     A 12.69473 100 A\\nN=100\n\n\nNow we can use the new variable (group_N) as x and include the sample size. It goes without saying that there are more ways to improve a box plot (and to include text). For example, we can use a geom_violin() to examine the distribution, as the second plot on the right side shows.\n\n#Use the new variable group_N as x\np1 &lt;- ggplot(data, aes(x = group_N, y = outcome)) +\n  geom_boxplot()+\n  geom_jitter(color = \"#d62828\", \n              size = 0.5, \n              alpha = 0.6)\n\n#A violin plot and stat_summary\np2 &lt;- ggplot(data, aes(x = group, y = outcome)) +\n  geom_violin(width=0.6, alpha=0.8)+\n  stat_summary(fun = \"median\", color = \"red\", \n               size = 1.5, geom = \"point\")+\n  stat_summary(fun.data = return_stats, \n               geom = \"text\", \n               size = 2, fontface = \"bold\",\n               hjust = 0.5, vjust = 0.9) \n\np1 + p2\n\n\n\n\nAs the right plot shows, I used the stat_summary() function twice to include further statistics. First, I used the function to display the median of each group. Second, I used a function (return_stats) that returns the statistics and finally the stat_summary() function which includes them as text in the plot. The latter approach is more flexible but also more complicated than the first approach. The next console shows how the function works and we will learn more about the geom_text at the end of this tutorial.\n\n\nCode\n# The return_stats function\nreturn_stats &lt;- function(y) {\n  return(data.frame(\n    value = max(y) * 1.2,\n    label = paste(\n      \"N =\", length(y), \"\\n\",\n      \"Mean =\", round(mean(y), 2), \"\\n\",\n      \"Median =\", round(median(y), 2), \"\\n\"\n    )\n  ))\n}\n\nreturn_stats(data$outcome)\n\n\n#&gt;      value                                        label\n#&gt; 1 31.58253 N = 615 \\n Mean = 13.01 \\n Median = 12.89 \\n\n\n\nRegardless of the approach, keep in mind that a box plot does not show the data nor does it display the distribution. Compared to that, the geom_jitter() displays the data and the violin plot reveals the underlying distribution.\nTo calculate the sample size or other statistics seems a bit awkward if you are not used to customized plots. Fortunately, there are further ggplot2 extension package that help us with this task. For example, the see package has a geom_violindot() function, which combines a violin with a dot plot. The latter makes it convenient to inspect the sample size and the distribution (Lüdecke et al. 2022). Add the geom, fill the dots black (via fill_dots); and find a reasonable size for the dots via size_dots option.\n\n# The see package adds a geom_violindot\nlibrary(see)\nggplot(data, aes(x = group, y = outcome, fill = group)) +\n  geom_violindot(fill_dots = \"black\", size_dots = 5) +\n  scale_fill_material_d(palette = \"contrast\")\n\n\n\n\nOr consider the ggstatsplot package: As the result from the ggbetweenstats() function shows, the package automatically adds statistical details to the graph. In our case, it combines box and violin plots to compare the outcome between the subjects (Patil 2023).\n\n# The ggstatsplot package\nlibrary(ggstatsplot)\nggbetweenstats(data, group, outcome) +\n  theme_minimal(base_size = 10)"
  },
  {
    "objectID": "chapter_07.html#the-spaghetti-plot",
    "href": "chapter_07.html#the-spaghetti-plot",
    "title": "6  Visualize data",
    "section": "6.3 The spaghetti plot",
    "text": "6.3 The spaghetti plot\nAnother classic visualization pitfall is the spaghetti plot. Essentially it is a line graph with too many lines and colors which is why we cannot see what is going on. We can create a spaghetti plot with the babynames package and the corresponding data (Wickham 2021). The package contains names of newborn babies in the US and includes proportion for a long period (1880-2017). Suppose we examine how the most popular male names have been developed over time. I have already prepared the data to identify the most popular male names (Top 10: name_pop).\n\n# The Top 10 male names\nname_pop\n\n#&gt;  [1] \"James\"       \"Michael\"     \"Robert\"      \"John\"        \"David\"      \n#&gt;  [6] \"William\"     \"Christopher\" \"Richard\"     \"Mark\"        \"Jason\"\n\n\nTo visualize how often these names appear, we need to apply a filter to get only male babynames and to filter the data for the Top 10 names.\n\n# Get male baby names for the Top 10 names\nbabynames_df &lt;- babynames %&gt;%\n  filter(sex == \"M\" & name %in% name_pop)\n\nNext, visualize the data with a line plot (geom_line). Use year as x, n as y, and name as group and color aesthetic.\n\n# Plot\nbabynames_df %&gt;%\n  ggplot(aes(x = year, y = n, group = name, color = name)) +\n  geom_line() +\n  scale_color_viridis(discrete = TRUE) +\n  ggtitle(\"A spaghetti chart example\")\n\n\n\n\nWhat a confusing graph: single lines look like spaghettis and we can’t see how often each name was used over the time. How can we improve the spaghetti plot? You are already familiar with a simple, but powerful solution. Apply a facet_wrap() and split the graph in subplots.\n\n# Split with facet_wrap\nggplot(babynames_df, aes(x = year, y = n, group = name)) +\n  geom_line() +\n  facet_wrap(name ~ ., nrow = 2)\n\n\n\n\nThere is still room for further improvement: We could - for example - to draw all lines in gray and highlight for each facet the corresponding line in a different color. First, we need to create a copy of the name variable (facet_names), which we will use to facet the graph.\n\n# Copy the names column\nbabynames_df$facet_names &lt;- babynames_df$name\n\nNext, I prepared the geom_line() to create a spaghetti plot one more time with gray lines only, as the first plot on the left side shows. However, see what happens if you add the facet_wrap() function and the facet_names variable to split the graph.\n\np1 &lt;- ggplot(babynames_df, aes(x=year, y=n)) +\n  geom_line(data = babynames_df %&gt;% select(-facet_names), \n            aes(group=name), \n            color=\"grey\", \n            linewidth=0.5, \n            alpha=0.5)\n\np2 &lt;- ggplot(babynames_df, aes(x=year, y=n)) +\n  geom_line(data = babynames_df %&gt;% select(-facet_names), \n            aes(group=name), \n            color=\"grey\", \n            linewidth=0.5, \n            alpha=0.5)+\n  theme_minimal(base_size = 8)+\n  facet_wrap(facet_names ~ ., nrow = 2)\n  \np1 + p2\n\n\n\n\nAs the second plot show, the new variable gives us the chance to create subplot for each name, but all lines are still included if we use the copy. Next, use a second geom_line() for the overlay. Insert the name as a color aesthetic, which will make a comparison easier. Moreover, give the overlaying line a distinct color and adjust its size with linewidth.\n\n#add another geom_line as overlay\nfinal_plot &lt;- ggplot(babynames_df, aes(x=year, y=n)) +\n  geom_line(data = babynames_df %&gt;% select(-facet_names), \n            aes(group=name), \n            color=\"grey\", \n            linewidth=0.5, \n            alpha=0.5) +\n  theme_minimal(base_size = 10)+\n  facet_wrap(facet_names ~ ., nrow = 2)+\n  geom_line(aes(color=name), color=\"darkred\", linewidth=0.75)\n\nfinal_plot\n\n\n\n\nWe focused on ggplot2, because we need a print version to visualize data in applied empirical research. However, we could also make the last plot interactive to untangle the spaghetti plot. For example, Highcharts is a JavaScript software library to create interactive charts and I used the highcharter package to create a responsive HTML version of the spaghetti plot (Kunst 2022). The next console shows the code for an improved version of the graph with the highcharter package.\n\n\n\n\n\nThe highcharter package\n\n\n\n\nLearning a new package and creating interactive graphs might be too far reaching in the beginning, just keep in mind that such possibilities exits. And in this case it is not even necessary to learn a new package to make the graph interactive, because the plotly package can create an interactive version for many standard graphs that are made with ggplot2 (Sievert et al. 2022). Plotly is a JavaScript library to visualize data and can convert a ggplot2 object into a plotly chart.\n\n\n\n\n\nThe plotly package\n\n\n\n\nConsider reading Interactive web-based data visualization with R, plotly, and shiny by Carson Sievert if you want to improve your interactive visualization skills\n\n# Interactive web-based data visualization with R, plotly, and shiny\nPracticeR::show_link(\"plotly\")\n\nInstead of learning more about interactive visualization techniques, the last pitfall is not a flaw, it is a principle and an important advice."
  },
  {
    "objectID": "chapter_07.html#clutter",
    "href": "chapter_07.html#clutter",
    "title": "6  Visualize data",
    "section": "6.4 Clutter",
    "text": "6.4 Clutter\nEdward Tufte underlines: “Clutter and confusion are failures of design, not attributes of information”. He highlightes that we are supposed to cut the clutter and get rid of everything that is not necessary to visualize the data.\nConsider the next two graphs. I made two bar graphs with a toy data frame and a binary outcome to keep it as simple as possible. I took my quite some time to create a graph that outlines the idea. As the plot on the left side shows, I created a theme that is supposed to look like the old Excel theme with a lot of clutter: The background is gray, I colored the bars even though the color and the legend do not transport any information, and I picked thick, black grid lines for a finishing touch. To compare this ugly beast, the right side shows the ggplot2 default version. Unfold the code if you want to create a ugly, cluttered graph on your own.\n\n\n\n\n\nThe reinvention of the old Excel theme seems a bit drastic, but even the default ggplot2 theme has some clutter that we could get rid of. This might not be necessary, but it highlights that there is always room to improve a graph, especially when it comes to clutter. For example, we could use a different theme to get rid of the gray background, there is no need to color each bar since they do not represent information, and we could integrate a label for each bar to communicate clearly.\nSo, fill the bars white and make the border of the bars black. In addition, use a theme without background colors and provide a descriptive title.\n\n# De-color de bars\nggplot(df_clutter, aes(x = outcome, y = count)) +\n  geom_col(color = \"black\", fill = \"white\") +\n  theme_minimal(base_size = 12) +\n  labs(title = \"Members by Sex\")\n\n\n\n\nNext, the geom_text() helps us to integrate text labels. Essentially, the function displays texts as a geometrical object which is why the main logic is not different compared to other geoms. I added a simple data frame (df_text) to illustrate how the geom works. It contains coordinates for x and y and an example text to visualize.\n\ndf_text &lt;- tibble::tribble(\n  ~x, ~y, ~text, ~group,\n  -1, -1, \"bottom left\", \"B\",\n  -1, 1, \"top right\", \"A\",\n  1, 1, \"top left\", \"A\",\n  1, -1, \"bottom right\", \"B\",\n  0, 0, \"center\", \"C\"\n)\n\nAs the next console highlights, the function depicts the text in accordance with the x and y coordinate, as the plot on the right side shows. The geom understands supplementary aesthetics and options (e.g., size, fontface) to display text. To give you an idea how it works, add the color aesthetics for each group and adjust the alignment of the text with the vjust (vertical adjustment) and the hjust (horizontal adjustment) option. If you set them to inward, the text will be aligned towards the center, but there are more alignment options available (e.g., left, right, center) should you prefer those.\n\n# geom_text example\np1 &lt;- ggplot(df_text, aes(x, y)) +\n  geom_text(aes(label = text),\n    size = 3\n  )\n\n# insert color aesthetic and adjust options (e.g., size, fontface)\np2 &lt;- ggplot(df_text, aes(x, y, color = group)) +\n  geom_text(aes(label = text),\n    vjust = \"inward\",\n    hjust = \"inward\",\n    size = 3,\n    fontface = \"bold\"\n  ) +\n  scale_color_brewer(palette = \"Set1\")\n\np1 + p2\n\n\n\n\nSince the data does not contain text to improve the bar graph, we may use the paste() function to create a label. It contains the group level, a new line (\\n), and the percentages.\n\n# Paste a label\npaste0(df_clutter$outcome, \"\\n\", df_clutter$percent, \"%\")\n\n#&gt; [1] \"Men\\n64.8%\"   \"Women\\n35.2%\"\n\n\nInclude the latter as a label and adjust the position via the y parameter Use the count and adjust it by increasing (decreasing) it manually. In addition, pick a text color and a reasonable text size.\n\n#Include text labels inside the bars\nggplot(df_clutter, aes(x=outcome, y=count)) +\n  geom_col(color = \"black\", fill = \"white\")+\n  geom_text(aes(label = paste0(outcome, \"\\n\", percent, \"%\"), \n                y = count - 100),\n            color=\"black\",\n            size = 3.5)+\n  theme_minimal(base_size = 12)+\n  labs(title= \"Members by Sex\")"
  },
  {
    "objectID": "chapter_07.html#summary",
    "href": "chapter_07.html#summary",
    "title": "6  Visualize data",
    "section": "6.5 Summary",
    "text": "6.5 Summary\nI highlighted several books to improve your ggplot2 and data visualizations skills, but at the end of the day your skills will improve faster, if you start to visualize data on your own and accept that trial and error are not necessarily a wrong approach. To this end, the ggplot2 cheat sheet (from the package website) will support you as well.\nIn addition, keep the following functions and packages from Chapter 7 in mind:\n\nCreate a new ggplot (ggplot), aesthetic mappings (aes), and add a geom_* (e.g., geom_bar, geom_point, geom_smooth)\nAdd a layer with +, start each new function on a new line, don’t forget to delete the plus sign if you delete the last line of code\nThere are several predefined theme functions (e.g., theme_bw, theme_light).\nModify axis, legend, and plot labels (e.g., with labs)\nLay out panels in a grid (e.g., facet_grid)\nDiscard (or adjust) the legend (e.g., theme(legend.position = \"none\"))\nAdjust the coordinate system (e.g., coord_cartesian)\nFurther packages:\n\nThemes: ggthemes (Arnold 2021)\nFont types: showtext (Qiu 2022)\nColor: The RColorBrewer (Neuwirth 2022) and the viridis package (Garnier 2021)\nMany color palettes: paletteer (Hvitfeldt 2021)\nCombine graphs: patchwork (Pedersen 2022b)\nZoom in: ggforce (Pedersen 2022a)\n\n\n\n\n\n\nArnold, Jeffrey B. 2021. ggthemes: Extra Themes, Scales and Geoms for ggplot2. https://CRAN.R-project.org/package=ggthemes.\n\n\nCairo, Alberto. 2016. The Truthful Art: Data, Charts, and Maps for Communication. New Riders.\n\n\nGarnier, Simon. 2021. viridis: Colorblind-Friendly Color Maps for R. https://CRAN.R-project.org/package=viridis.\n\n\nHvitfeldt, Emil. 2021. paletteer: Comprehensive Collection of Color Palettes. https://CRAN.R-project.org/package=paletteer.\n\n\nKunst, Joshua. 2022. highcharter: A Wrapper for the Highcharts Library. https://CRAN.R-project.org/package=highcharter.\n\n\nLüdecke, Daniel, Dominique Makowski, Indrajeet Patil, Mattan S. Ben-Shachar, Brenton M. Wiernik, and Philip Waggoner. 2022. see: Model Visualisation Toolbox for easystats and ggplot2. https://CRAN.R-project.org/package=see.\n\n\nNeuwirth, Erich. 2022. RColorBrewer: ColorBrewer Palettes. https://CRAN.R-project.org/package=RColorBrewer.\n\n\nPatil, Indrajeet. 2023. ggstatsplot: ggplot2 Based Plots with Statistical Details. https://CRAN.R-project.org/package=ggstatsplot.\n\n\nPedersen, Thomas Lin. 2022a. ggforce: Accelerating ggplot2. https://CRAN.R-project.org/package=ggforce.\n\n\n———. 2022b. patchwork: The Composer of Plots. https://CRAN.R-project.org/package=patchwork.\n\n\nQiu, Yixuan. 2022. showtext: Using Fonts More Easily in R Graphs. https://CRAN.R-project.org/package=showtext.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik Ram, Marianne Corvellec, and Pedro Despouy. 2022. plotly: Create Interactive Web Graphics via plotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley. 2021. babynames: US Baby Names 1880-2017. https://github.com/hadley/babynames.\n\n\n———. 2022. forcats: Tools for Working with Categorical Variables (Factors). https://CRAN.R-project.org/package=forcats.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2022. ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "chapter_08.html#the-gt-package",
    "href": "chapter_08.html#the-gt-package",
    "title": "7  Create tables",
    "section": "7.1 The gt package",
    "text": "7.1 The gt package\nThe R community has developed many cool packages to create tables. They rely on different approaches, have a different aim, or are specialized for different output formats. For example, the gt package creates elegant tables for PDF and HTML files and it outlines its approach to create tables graphically (Iannone et al. 2022). The next Figure shows the parts to create a gt table. \n\n\n\nThe gt package: Artwork by Iannone et al. (2022)\n\n\nApproaches to create customized tables can quickly become complex, since even a simple table includes many parts (e.g., header, labels, body, etc.) that need to be defined, formatted, and generated for a certain output. Irrespective of the package, the first step to create a table are often similar and not complicated. We thus need to prepare the output and give it to the package. As the next console shows, I estimated the mean of several variables for each species of the penguins data which we will use as an example input for the table. The corresponding gt() function returns the input as a simple, but elegant table.\n\n# Create table output\npenguins_table &lt;- penguins |&gt;\n  group_by(species) |&gt;\n  drop_na() |&gt;\n  summarise(across(bill_length_mm:flipper_length_mm, mean))\n\n# Create a gt table\nlibrary(gt)\ngt_tbl &lt;- gt(penguins_table)\ngt_tbl\n\n\n\n\n\n  \n    \n      species\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n    \n  \n  \n    Adelie\n38.82397\n18.34726\n190.1027\n    Chinstrap\n48.83382\n18.42059\n195.8235\n    Gentoo\n47.56807\n14.99664\n217.2353\n  \n  \n  \n\n\n\n\nThe package has functions and options to improve the default result. For example, fmt_number() rounds numerical columns; we can format the table header (tab_header) and the column labels (cols_label) with the md() function which interprets the input as Markdown. By the way, the html() does essentially the same for HTML code. Never mind if are not yet familiar with HTML, Chapter 11 gives you a hands on and the next console shows the discussed code and table.\n\n# Improve the table\ngt_tbl |&gt;\n  fmt_number(\n    columns = c(bill_length_mm, bill_depth_mm, flipper_length_mm),\n    decimals = 2\n  ) %&gt;%\n  tab_header(\n    title = md(\"**The Palmerpenguins**\")\n  ) |&gt;\n  cols_label(\n    species = \"Species\",\n    bill_length_mm = md(\"Bill Length (mm)\"),\n    bill_depth_mm = md(\"Bill Depth (mm)\"),\n    flipper_length_mm = md(\"Flipper Length (mm)\")\n  )\n\n\n\n\n\n  \n    \n      The Palmerpenguins\n    \n    \n    \n      Species\n      Bill Length (mm)\n      Bill Depth (mm)\n      Flipper Length (mm)\n    \n  \n  \n    Adelie\n38.82\n18.35\n190.10\n    Chinstrap\n48.83\n18.42\n195.82\n    Gentoo\n47.57\n15.00\n217.24\n  \n  \n  \n\n\n\n\nLike this, there are many cool packages to create tables, but depending on our aim, it may become quite complicated. Let me underline this point with the kableExtra package."
  },
  {
    "objectID": "chapter_08.html#the-kableextra-package",
    "href": "chapter_08.html#the-kableextra-package",
    "title": "7  Create tables",
    "section": "7.2 The kableExtra package",
    "text": "7.2 The kableExtra package\nYou can create awesome HTML and LaTeX tables with knitr::kable() and the kableExtra package. As we have seen before, the first step is not complicated, we need an input and the kbl() function returns a basic table.\n\n# https://haozhu233.github.io/kableExtra/awesome_table_in_html.html\n# booktabs = TRUE\npenguins_table %&gt;%\n  kbl()\n\n\n\n\nspecies\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\n\n\n\n\nAdelie\n38.82397\n18.34726\n190.1027\n\n\nChinstrap\n48.83382\n18.42059\n195.8235\n\n\nGentoo\n47.56807\n14.99664\n217.2353\n\n\n\n\n\n\n\nThe package provides many features to adjust the table. For example, there are predefined rules (based on CSS, see Chapter 11) to style the appearance of a HTML table. See what happens if you add kable_styling(). It returns the table in minimal style.\n\n# Styles for HTML tables\npenguins_table %&gt;%\n  kbl(booktabs = T) %&gt;%\n  kable_styling()\n\nIn a similar vein, there many options to style an HTML table. The bootstrap_options returns striped cells in white and light gray, we can adjust the width of the table (e.g., full_width); and define the position of the table.\n\n# Further options of an HTML table\nkbl(penguins_table) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\nUnfortunately, all flexible approaches to create tables become complex if we want to customize a table in more detail. The next console shows a complicated illustration. I adjusted the header, I used colors to highlight values, and I inserted an inline histogram of depict flipper_length_mm. Please ignore the code details and inspect the package vignette for more information. I will not outline how it works, but it underlines how complex the code can become.\n\n# Customize the table in LATEX\npeng_split &lt;- split(penguins$flipper_length_mm, penguins$species)\npenguins_table$flipper_length_mm2 &lt;- \"\"\npenguins_table$species &lt;- \"\"\n\npenguins_table %&gt;%\n  kbl(booktabs = TRUE, col.names = c(\n    \"Species\",\n    \"Bill length\",\n    \"Bill Depth\",\n    \"Flipper Length\",\n    \"Histogram\"\n  )) |&gt;\n  kable_paper(full_width = FALSE) |&gt;\n  kable_styling(font_size = 10) |&gt;\n  row_spec(0, bold = T, font_size = 12) |&gt;\n  column_spec(1,\n    image = spec_image(c(\n      \"images/ch_08/p1.png\",\n      \"images/ch_08/p2.png\",\n      \"images/ch_08/p3.png\"\n    ), 200, 100)\n  ) |&gt;\n  column_spec(2,\n    bold = T,\n    color = spec_color(penguins_table$bill_length_mm[1:3])\n  ) |&gt;\n  column_spec(5,\n    bold = T,\n    image = spec_hist(peng_split, width = 200, height = 100)\n  )\n\n\n\n\nSpecies\nBill length\nBill Depth\nFlipper Length\nHistogram\n\n\n\n\n\n38.82397\n18.34726\n190.1027\n\n\n\n\n48.83382\n18.42059\n195.8235\n\n\n\n\n47.56807\n14.99664\n217.2353\n\n\n\n\n\n\n\n\nIs it worth to create such customized tables? It depends on your goal and the possibilities to recycle the code. Overall, all those different packages rely on different approaches to generate tables. There is not one packages for all purposes and it depends on your taste and needs or which approach you prefer. For this reason this tutorial tried to raise awareness that several excellent packages to create tables exist. I did not even discuss them all, but I have another one for the road.\nConsider the modelsummary package because it provides many features to create tables for models (Arel-Bundock 2023). Furthermore, the datasummary_skim() creates a nice summary table. It even let you determine the output style and change its overall appearance. Pick a output style, for example, flextable, gt, or kableExtra.\n\n# output style: gt, kableExtra, flextable, huxtable\nlibrary(modelsummary)\ndatasummary_skim(penguins, output = \"gt\", histogram = FALSE)\n\n\n\n\n\n  \n    \n       \n      Unique\n      Missing Pct.\n      Mean\n      SD\n      Min\n      Median\n      Max\n    \n  \n  \n    bill_length_mm\n165\n1\n43.9\n5.5\n32.1\n44.5\n59.6\n    bill_depth_mm\n81\n1\n17.2\n2.0\n13.1\n17.3\n21.5\n    flipper_length_mm\n56\n1\n200.9\n14.1\n172.0\n197.0\n231.0\n    body_mass_g\n95\n1\n4201.8\n802.0\n2700.0\n4050.0\n6300.0\n    year\n3\n0\n2008.0\n0.8\n2007.0\n2008.0\n2009.0\n  \n  \n  \n\n\n\n\nTo report research findings, customized tables are definitely worth the trouble, but we can reduce our effort to create tables. Let us switch back to the huxtable package and improve our skills to create tables for research findings."
  },
  {
    "objectID": "chapter_08.html#the-huxtable-package",
    "href": "chapter_08.html#the-huxtable-package",
    "title": "7  Create tables",
    "section": "7.3 The huxtable package",
    "text": "7.3 The huxtable package\nLet us revise what we learned in Chapter 8. First, we created a table with the huxreg function and in a second step I introduced some options to improve the table. I already estimated three example linear regression models (m1, etc.). Can you create a regression table with the huxtable package?\n\n# The models\nm1 &lt;- lm(body_mass_g ~ bill_length_mm,\n  data = penguins\n)\nm2 &lt;- lm(body_mass_g ~ bill_length_mm + flipper_length_mm,\n  data = penguins\n)\nm3 &lt;- lm(body_mass_g ~ bill_length_mm + flipper_length_mm + sex,\n  data = penguins\n)\n\n# The minimal code\nlibrary(huxtable)\nhuxreg(m1, m2, m3)\n\n\n\n\n(1)(2)(3)\n\n(Intercept)362.307    -5736.897 ***-5433.534 ***\n\n(283.345)   (307.959)   (286.558)   \n\nbill_length_mm87.415 ***6.047    -5.201    \n\n(6.402)   (5.180)   (4.860)   \n\nflipper_length_mm        48.145 ***48.209 ***\n\n        (2.011)   (1.841)   \n\nsexmale                358.631 ***\n\n                (41.572)   \n\nN342        342        333        \n\nR20.354    0.760    0.807    \n\nlogLik-2696.987    -2527.741    -2426.664    \n\nAIC5399.975    5063.482    4863.327    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nIn the second step, I outlined that we can omit coefficients(omit_coefs), adjust the reported statistics, and add a note to inform the reader about the model. These options are not a comprehensive list, but they illustrated some of the typical steps to create a table for a publication. Thus, omit the model’s intercept ((Intercept)), pick some statistics (e.g., nobs for N; r.squared), and add a note. In addition, format the returned numbers of the table with number_format.\n\n# Show my models via huxreg()\nhuxreg(m1, m2, m3,\n  omit_coefs = \"(Intercept)\",\n  statistics = c(`N` = \"nobs\", `R²` = \"r.squared\"),\n  number_format = 2,\n  note = \"Note: Some important notes.\"\n)\n\n\n\n\n(1)(2)(3)\n\nbill_length_mm87.42 ***6.05    -5.20    \n\n(6.40)   (5.18)   (4.86)   \n\nflipper_length_mm       48.14 ***48.21 ***\n\n       (2.01)   (1.84)   \n\nsexmale              358.63 ***\n\n              (41.57)   \n\nN342       342       333       \n\nR²0.35    0.76    0.81    \n\nNote: Some important notes.\n\n\n\n\nWe can recycle a lot of code the next time we need to report a similar table, but there are still a lot of steps involved to create such a table. And who can remember all those options? So, we can define what the table should look like, without the need to rebuild a table from scratch every time: We improve our coding skills by learning how to create our own table functions. We already defined the most important options to create the table. The next time we create a similar table, we need to update the estimated models, text labels, or the note.\nCreate a new function: Give the function a name (e.g., my_huxreg) and insert the code from the last step into the body of the function. As a first step, the function should only update the included models. Instead of the function parameters, put three points (...) inside the function() and the huxreg() function instead of the model names. Such a dot-dot-dot argument allows us to send uncounted numbers of arguments (here models) to the huxreg() function. Moreover, create a list with model names (modelfits) and test the approach by running the my_huxreg() function with the estimated models.\n\n# Create your own huxreg function\nmy_huxreg &lt;- function(...) {\n  huxreg(...,\n    omit_coefs = \"(Intercept)\",\n    statistics = c(`N` = \"nobs\", `R²` = \"r.squared\"),\n    number_format = 2,\n    note = \"Important note\"\n  )\n}\n\n# Create a list of models\nmodelfits &lt;- list(\n  \"Model A\" = m1,\n  \"Model B\" = m2,\n  \"Model C\" = m3\n)\n\nmy_huxreg(modelfits)\n\n\n\n\nModel AModel BModel C\n\nbill_length_mm87.42 ***6.05    -5.20    \n\n(6.40)   (5.18)   (4.86)   \n\nflipper_length_mm       48.14 ***48.21 ***\n\n       (2.01)   (1.84)   \n\nsexmale              358.63 ***\n\n              (41.57)   \n\nN342       342       333       \n\nR²0.35    0.76    0.81    \n\nImportant note\n\n\n\n\nWe only passed the models via the function, but we can integrate further function parameters to improve the approach. For example, each time we create a new table, text labels for the variables names (coefs_names) are needed; we may omit different variables (drop) from the models; and - depending on the outcome and the reported models - we should adjust the message of the note. Instead of providing these options inside the function, include them as parameters and insert their objects names in the my_huxreg function.\n\n# Include option parameters\nmy_huxreg &lt;- function(..., coefs_names, drop, message) {\n  huxreg(...,\n    coefs = coefs_names,\n    omit_coefs = drop,\n    statistics = c(`N` = \"nobs\", `R²` = \"r.squared\"),\n    number_format = 2,\n    note = message\n  ) |&gt;\n    set_bold(row = 1, col = everywhere) |&gt;\n    set_align(1, everywhere, \"center\")\n}\n\nMoreover, the huxtable is not made for regression tables only, but for tables in general. For this reason the package has much more to offer than the discussed options. Consider the last two lines of code of the solution: I added them to illustrate this point. The set_bold function prints the first row of all columns in bold; and I align numbers (set_align) in the center.\nRegardless of the discussed steps, we can now recycle the code by creating a function. We only need to hand over the estimated models and the new information about the models. I already started to create text labels for the coefficients (coefs). Adjust which variables you will drop (droped_coefs); the message option, and insert those objects into the my_huxreg function.\n\n# Option input\ncoefs &lt;- c(\n  \"Bill length\" = \"bill_length_mm\",\n  \"Flipper length\" = \"flipper_length_mm\",\n  \"Male\" = \"sexmale\"\n)\n\ndroped_coefs &lt;- c(\"(Intercept)\")\nmessage &lt;- \"Note: Some important notes that can change.\"\n\n# Create table (my_huxreg is based on the solution of the last console)\nmytable &lt;- my_huxreg(modelfits,\n  coefs_names = coefs,\n  drop = droped_coefs,\n  message = message\n)\nmytable\n\n\n\n\nModel AModel BModel C\n\nBill length87.42 ***6.05    -5.20    \n\n(6.40)   (5.18)   (4.86)   \n\nFlipper length       48.14 ***48.21 ***\n\n       (2.01)   (1.84)   \n\nMale              358.63 ***\n\n              (41.57)   \n\nN342       342       333       \n\nR²0.35    0.76    0.81    \n\nNote: Some important notes that can change.\n\n\n\n\nWe will learn more about automation and text reporting in Chapter 10, but keep in mind that such steps to create your own function are often worth considering, as it makes the code less clunky and reproducible. If you create a document, save your function in a separate R script, and include it in your document via the souce() function in the setup R chunk. It runs the code if you render the document.\nFinally, let me briefly introduce Quarto (.qmd), a publishing system to create many different document types. In a similar sense as rmarkdown, it uses knitr and Pandoc to create documents with R. As the illustration from Allison Horst underlines, Quarto is a flexible system since it is not tied to R. As outlined on the homepage: “Quarto was developed to be multilingual, beginning with R, Python, Javascript, and Julia, with the idea that it will work even for languages that don’t yet exist”.\n\n\n\nArtwork “Hello, Quarto” by Allison Horst\n\n\nI introduced rmarkdown because it is the classic approach and both procedures are very identical in terms of creating documents. The main difference stems from the YAML header because Quarto standardize the YAML code between different documents types. For example, consider the next console, it compare the YAML header of a default rmarkdown document with a default Quarto document. The latter has a format field instead of the output field, but will create an HTML document with both ways. Certainly there are more differences, but the main steps – code is evaluated via code-chunks, you need to format text via Markdown, etc. – are almost identical.\n#rmarkdown YAML\n---\ntitle: \"Untitled\"\noutput: html_document\n---\n#Quarto YAML\ntitle: \"Untitled\"\nformat: html\nThus, also consider Quarto if you start to create documents on a regular basis, because it provides many templates and an excellent documentation. You can create documents from RStudio after you installed Quarto. Click on the Quarto logo to visit the website."
  },
  {
    "objectID": "chapter_08.html#summary",
    "href": "chapter_08.html#summary",
    "title": "7  Create tables",
    "section": "7.4 Summary",
    "text": "7.4 Summary\nKeep the following R packages, functions, and key insights from Chapter 8 in mind:\n\nCreate many different documents with rmarkdown and adjust the document in the meta section (YAML header)\nPandoc runs in the background, converts the file and uses, for example, Latex in case of a PDF file\nAdjust code via chunk-options (e.g., eval, echo, warning, message)\nFormat text with Markdown and RStudio’s visual markdown editing mode\nStart using a citation manager (e.g., Zotero)\nCreate table with, for example, the flextable, the modelsummary, and the stargazer package\nCreate a huxtable to display model output (huxtable::huxreg)\nRead R code from a file, a connection or expressions (source)\n\n\n\n\n\nAllaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2022. rmarkdown: Dynamic Documents for R. https://CRAN.R-project.org/package=rmarkdown.\n\n\nArel-Bundock, Vincent. 2023. modelsummary: Summary Tables and Plots for Statistical Models and Data: Beautiful, Customizable, and Publication-Ready. https://CRAN.R-project.org/package=modelsummary.\n\n\nGohel, David, and Panagiotis Skintzos. 2022. flextable: Functions for Tabular Reporting. https://CRAN.R-project.org/package=flextable.\n\n\nHlavac, Marek. 2022. stargazer: Well-Formatted Regression and Summary Statistics Tables. https://CRAN.R-project.org/package=stargazer.\n\n\nHugh-Jones, David. 2022. huxtable: Easily Create and Style Tables for LaTeX, HTML and Other Formats. https://CRAN.R-project.org/package=huxtable/.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, and JooYoung Seo. 2022. gt: Easily Create Presentation-Ready Display Tables. https://CRAN.R-project.org/package=gt.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nXie, Yihui, Joe Cheng, and Xianying Tan. 2022. DT: A Wrapper of the JavaScript Library DataTables. https://CRAN.R-project.org/package=DT.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex Table with kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  },
  {
    "objectID": "chapter_10.html#automate-graphs",
    "href": "chapter_10.html#automate-graphs",
    "title": "8  Automate work",
    "section": "8.1 Automate graphs",
    "text": "8.1 Automate graphs\nSuppose someone asked you to create a report with many descriptive graphs. If the report contains many graphs - say a histogram for all numerical variables - the chance is high that we start to repeat ourselves in terms of code. You may create a customized plot with ggplot2 (Wickham, Chang, et al. 2022), but for each variable we still need to copy the code and then change the plot slightly. Such a copy and paste approach makes the code messy and we repeatedly need to adjust each graph manually if we find an error. \nFor this reason, I introduced the advantages of dynamic reports, but we can also make functions that help us to create graphs more efficiently. With functions, we minimize the urge to repeat ourselves. They make our work less error prone because if the function includes a mistake, the error would appear each time we call the function, making it easier to spot them. Therefore, our work becomes more flexible, because we have to change the code only in one place and repeat it over and over for an entire document.\nSuppose you need to visualize all numerical variables from the penguins data with a histogram (Horst, Hill, and Gorman 2022). We will use the next code as an example to build functions. It is not important what the plots actually looks like, as we can still adjust all kind of graphical appearances and include such steps in the created function. Let’s keep it simple to illustrate how the approach works. As a bare minimum let’s pick a numerical variable (e.g., bill_length_mm) and give the plot a title.\n\n# Pick a variable and give a title\nggplot(penguins) +\n  geom_histogram(aes(x = bill_length_mm)) +\n  ggtitle(\"Bill length\")\n\n\n\n\nI already created the body of a function to build such a histogram (hist_fun) and you need to add the code to create the graph. First, insert the code from the last console. Next, we need to adjust the input variable. There are different ways to use ggplot2 in functions. Adjust the code and fill in .data[[x]] instead of x, it will hand over the column vector from the function call. As always, give it a try before you consider the solution and check if the function is working.\n\n# A function to create histograms\nhist_fun &lt;- function(data, x) {\n  ggplot(data) +\n    geom_histogram(aes(x = .data[[x]])) +\n    ggtitle(paste(\"Var:\", x))\n}\n\n# Did it work?\nhist_fun(penguins, x = \"bill_length_mm\")\n\n\n\n\nFunctions reduce our workload, but the approach is quite repetitive, especially if we display each numerical variable with a histogram. Why don’t we create one plot with a histogram for each numerical variable? We used the DataExplorer package for this task in Chapter 3, but with your own function you will be able to create a plot in the exact same way as you want them.\nFirst we need to identify which variables of a data frame are numerical. The select_if() function from dplyr lets us pick variables under a specified condition (Wickham, François, et al. 2022). As the next console shows, it returns variables which are double (numerical, factor) if we insert the is.double (is.numeric; is.factor) function.\n\n# dplyr::select_if\ndplyr::select_if(penguins, is.double) |&gt;\n  head()\n\n#&gt; # A tibble: 6 × 2\n#&gt;   bill_length_mm bill_depth_mm\n#&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1           39.1          18.7\n#&gt; 2           39.5          17.4\n#&gt; 3           40.3          18  \n#&gt; 4           NA            NA  \n#&gt; 5           36.7          19.3\n#&gt; 6           39.3          20.6\n\n\nHowever, we need a vector with the corresponding variable names to create the plot. Insert the select_if function into the names() function to get the variable names.\n\n# Only numerical input\nnames(dplyr::select_if(penguins, is.double))\n\n#&gt; [1] \"bill_length_mm\" \"bill_depth_mm\"\n\n\nNow that we have a vector with variable names and a function to create histograms, enables us to use purrr (Henry and Wickham 2022). The map function returns a list with the histogram for each input variable. First, assign the results of the last console as numerical_variables. Next, we apply the hist_fun() for each input of numerical_variables.\n\n# Iterate with purrr\nnumerical_variables &lt;- names(dplyr::select_if(penguins, is.double))\nplots_list &lt;- purrr::map(numerical_variables, ~ hist_fun(penguins, x = .x))\n\nFinally, use the plot_grid function from the cowplot package to combine them all in one graph (Wilke 2020). The function only needs a plotlist in order to combine all the plots from the created list (plots_list) in one graphical output.\n\n# Insert your plotlist\ncowplot::plot_grid(plotlist = plots_list)\n\n\n\n\nNow it’s up to you to combine these steps. Create a function (all_hist) that takes all numerical variables from a data frame, then create a histogram for each variable with purrr and combine all into a single graph with cowplot. Finally, check if the function works.\n\n# Create a function that returns several histograms\nall_hist &lt;- function(data) {\n  numerical_variables &lt;- names(dplyr::select_if(data, is.double))\n  plots_list &lt;- purrr::map(numerical_variables, ~ hist_fun(data, x = .x))\n  plot &lt;- cowplot::plot_grid(plotlist = plots_list)\n  return(plot)\n}\n\n# Did it work?\nall_hist(penguins)\n\n\n\n\nLet us create an error message and adjust the options to illustrate how to improve the approach. So far our function works only with numerical variables, but what happens if the data does not contain one? The first two variables of the penguins data are categorical which gives us the opportunity to inspect which error our function returns if there is no numerical input.\n\n# What happens if there is an error?\nall_hist(penguins[1:2])\n\n#&gt; Error in grobs[[i]]: subscript out of bounds\n\n\nThe error message is pretty obscure, but we can improve it: It should warn us in a reasonable manner and abort the function. Consider the numerical_variables vector. If there are no numerical variables, it has a length of zero and the function is supposed to abort.\n\n# names_num is zero if the data has no numerical input\nnumerical_variables &lt;- names(dplyr::select_if(penguins[1:2], is.double))\nnumerical_variables\n\n#&gt; character(0)\n\n\nThe cli package provides helpers for developing command line interfaces and we can use the cli_abort function from it (Csárdi 2022). It aborts the function call and returns a warning message as the next console illustrates.\n\n# CLI provides helpers for developing Command Line Interfaces\ncli::cli_abort(\"What is the problem?\")\n\n#&gt; Error:\n#&gt; ! What is the problem?\n\n\nInsert the cli_abort() function together with an if condition in the all_hist() function. Only if the names_num vector has a length of zero, the cli_abort function should abort the function call and returns a warning.\n\n# Add if and cli::cli_abort\nall_hist &lt;- function(data) {\n  numerical_variables &lt;- names(dplyr::select_if(data, is.double))\n  if (length(numerical_variables) == 0) {\n    cli::cli_abort(\"Input must be a double-precision vector.\")\n  }\n  plots_list &lt;- purrr::map(numerical_variables, ~ hist_fun(data, x = .x))\n  plot &lt;- cowplot::plot_grid(plotlist = plots_list)\n  return(plot)\n}\n# Do we get an error?\nall_hist(penguins[1:2])\n\n#&gt; Error in `all_hist()`:\n#&gt; ! Input must be a double-precision vector.\n\n\nIt goes without saying that we can further improve the function by adding and adjust the options that generates the plot.\nFor example, add the ncol option in the plot_grid() function. It lets us determine the number of columns used to plot the graphs. Don’t forget to insert the option also in the function() and give a default value that suits your purpose.\n\n# Adjust the plot_grid function\nall_hist &lt;- function(data, ncol = 3) {\n  numerical_variables &lt;- names(dplyr::select_if(data, is.double))\n  if (length(numerical_variables) == 0) {\n    cli::cli_abort(\"Input must be a double-precision vector.\")\n  }\n  plots_list &lt;- purrr::map(numerical_variables, ~ hist_fun(data, x = .x))\n  cowplot::plot_grid(plotlist = plots_list, ncol = ncol)\n}\n\n# The all_hist with ncol\nall_hist(iris, ncol = 4)\n\n\n\n\nFinally, one last thought about the themes. If we adjust the theme() inside the function, the same styling rules are applied. However, we can also create our own theme function which increases the flexibility, since we can also apply the theme also to other graphs.\nCreating a theme is not complicated. We best start by using a predefined theme and only adjust it where the theme does not fit for our purpose. As the next console shows, the my_theme() function relies on a ggthemes theme (Arnold 2021); to give you an idea how it works I only adjusted the text size of the title and the caption. After we created the theme, we can integrate it in the function or call it after we created the graph, as the next console shows.\n\n# Create a customized theme\nmy_theme &lt;- function() {\n  ggthemes::theme_gdocs() +\n    theme(plot.title = element_text(size = 16)) +\n    theme(plot.caption = element_text(size = 10))\n}\n\n# Apply it where needed\nplot &lt;- all_hist(iris, ncol = 2)\nplot + my_theme()"
  },
  {
    "objectID": "chapter_10.html#automate-the-boring-stuff",
    "href": "chapter_10.html#automate-the-boring-stuff",
    "title": "8  Automate work",
    "section": "8.2 Automate the boring stuff",
    "text": "8.2 Automate the boring stuff\nStudents in the social sciences learn R to apply statistics, but R helps us also to automate repetitive tasks. This last section does not necessarily have applied empirical research in mind, but it tries to raise awareness about how we can get the boring stuff done (with R and different packages).\n\n8.2.1 The officer package\nTill now we focused on PDF reports, but the officeverse package encompasses several packages and functions to work with Microsoft Office files. For example, the officer package will help you to create and change all sorts of MS Office documents. \nSuppose that a data set gets an update and we are supposed to do the same with the corresponding Word reports. There is one Word document for a long list of countries and we certainly do not want to make the update manually. For the sake of simplicity, suppose we only need to add a new page, insert a new headline, and provide an updated plot for each country. Therefore, we first need a new plot that we are supposed to add:\n\n# New plot\nplot &lt;- ggplot(penguins) +\n  geom_histogram(aes(x = bill_length_mm)) +\n  ggtitle(\"Bill length\")\n\nThe next console shows how such a minimal but effective update may look like based on a simple workaround. First, we read the document with read_docx; next we add a new page (body_add_break), a new header (body_add_par), and the plot (body_add_gg). Finally, we are able to export the new document with the print() function and the target option.\n\nlibrary(officer)\n# Read and update my_doc\ndoc_updated &lt;- read_docx(path = \"my_doc.docx\") |&gt;\n  body_add_break(pos = \"after\") |&gt;\n  body_add_par(\"Updated results\", style = \"heading 1\") |&gt;\n  body_add_gg(value = plot, style = \"normal\")\n\n# Save updated doc\nprint(doc_updated, target = \"doc_updated.docx\")\n\nOf course, this was a simple workaround for illustration purposes. Consider the package website for more information about the officeverse.\n\n\n8.2.2 The pdftools package\nSay you have a bunch of PDF files and you need to combine them in a single file. Or the other way around, you have a large PDF file but for some reasons you need to split them. Certainly there are different software solutions available, but your time is too precious to add each page manually or apply another repetitive task to the file(s). The pdftools and the qpdf package has corresponding functions to combine, split, and perform further functions when working with PDF files (Ooms 2022a, 2022b). \n\n# Join several pdf files into one\nqpdf::pdf_combine()\n\n# Split a single pdf into separate files, one for each page\nqpdf::pdf_split()\n\nIn the case of image files, consider the magick package (Ooms 2021).\n\n\n8.2.3 The magick package \nSuppose you have many images that are saved a PDF file and you need to convert them into png files. As before, you can open all files in a graphic software and export each of them manually. Or you can use the magick package to read the files and convert them into a certain format, as the next console highlights. The package provides many features to read, adjust, and convert image files. Consider the package documentation because it outlines more features that I can introduce.\n\n# Convert Images\nimg &lt;- image_read_pdf(\"figure.pdf\")\n\n# Write as PNG\nimage_write(img, \"output.png\")\n\nChapter 10 introduced packages and features to automate work. Certainly, we cannot automate all kinds of work with R, but keep in mind that there are often solutions are available to get recurring tasks done, before you start to repeat yourself several times. I did not introduce the magick package only because of it lets us convert images. I did so because it has many features to work with images and sometimes you will be surprised about the numerous possibilities of R and its landscape.\nSuppose you want to analyze texts, but they are only available as an image files. I made a screen shot of an info box from the Practice R book. The image shows the first lines of the cronR info box.\n\nThe magick package helps us to extract this text from the image files. As the next console shows, we need to read the image first before we can extract the text.\nThe image_ocr() function (optical character recognition) scans the file and extract the data. The functions relies on tesseract, which is an open OCR engine that supports over 100 languages. To make the output a bit easier to read in the console, I used the stringr package, which I will introduce in Chapter 11 in detail.\n\n# Extract text via OCR\nlibrary(tesseract)\nlibrary(stringr)\ntxt &lt;- image_ocr(img)\ntext &lt;- str_split(txt, \"\\n\")\ntext &lt;- as_vector(text)\nhead(text)\n\n\nInstead of repeating yourself, use your time wiser and learn something new about R and its environment. How about D3 (Data-Driven Documents), which is a JavaScript library to create interactive visualizations for the web. The r2d3 package let you integrate D3 into R (Strayer, Luraschi, and Allaire 2022). The next console illustrates that the package runs a JavaScript file (voronoi.js) and returns an example made by Mike Bostock.\n\nlibrary(r2d3)\n# voronoi.js is based on: https://bl.ocks.org/mbostock/4060366\nr2d3(d3_version = 4, script = \"d3/voronoi.js\")\n\nIf you are not in the right mood to learn something new, how about playing an old school video game? The Rcade package lives on GitHub only, but thanks to Romain Lesur you can play Tetris, Mario, or Pacman directly from R.\n\n# devtools::install_github('RLesur/Rcade')\n# library(Rcade)\nRcade::games$Pacman\n\nThus, be curious and don’t miss the opportunity to automate work that does not need your full attention, because it will also improve your skills. In a similar sense, consider to write your own R package if you have invested a lot of time and effort in your work. Depending on your goal, this might not be necessary but all the functions would be available if you combine them in a package. Moreover, I couldn’t resist to highlight the possibility one more time, especially regarding the American Chopper meme.\n\n\n\nMeme based on the American Chopper\n\n\nDon’t let fancy packages such as ggplot2 discourage you when considering to create your own package for the first time: you and your ideas are worth the time and effort. Keep that in mind if you start fooling around with the idea."
  },
  {
    "objectID": "chapter_10.html#summary",
    "href": "chapter_10.html#summary",
    "title": "8  Automate work",
    "section": "8.3 Summary",
    "text": "8.3 Summary\nKeep the following R functions and packages from Chapter 10 in mind:\n\nKeep distinct/unique rows (dplyr::distinct)\nConcatenate strings (paste)\nFormat and interpolate a string (glue: Hester and Bryan 2022)\nRender R Markdown (rmarkdown::render)\nFind your files (here:: Müller 2020)\nControl flow (e.g., if, for loop)\nPlay a short sound (beepr: Bååth 2018)\nAutomatic reporting of R objects (report:: Makowski et al. 2022)\nSend an email (blastula: Iannone and Cheng 2020)\nInterpret input text as Markdown-formatted text (blastula::md)\nList the Files in a directory/folder (list.files)\nApply a function to each element of a vector (purrr::map)\n\n\n\n\n\nAllaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2022. rmarkdown: Dynamic Documents for R. https://CRAN.R-project.org/package=rmarkdown.\n\n\nArnold, Jeffrey B. 2021. ggthemes: Extra Themes, Scales and Geoms for ggplot2. https://CRAN.R-project.org/package=ggthemes.\n\n\nBååth, Rasmus. 2018. Beepr: Easily Play Notification Sounds on any Platform. https://CRAN.R-project.org/package=beepr.\n\n\nCsárdi, Gábor. 2022. cli: Helpers for Developing Command Line Interfaces. https://CRAN.R-project.org/package=cli.\n\n\nHenry, Lionel, and Hadley Wickham. 2022. purrr: Functional Programming Tools. https://CRAN.R-project.org/package=purrr.\n\n\nHester, Jim, and Jennifer Bryan. 2022. glue: Interpreted String Literals. https://CRAN.R-project.org/package=glue.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nIannone, Richard, and Joe Cheng. 2020. blastula: Easily Send HTML Email Messages. https://CRAN.R-project.org/package=blastula.\n\n\nMakowski, Dominique, Daniel Lüdecke, Mattan S. Ben-Shachar, Indrajeet Patil, and Brenton M. Wiernik. 2022. report: Automated Reporting of Results and Statistical Models. https://CRAN.R-project.org/package=report.\n\n\nMüller, Kirill. 2020. here: A Simpler Way to Find Your Files. https://CRAN.R-project.org/package=here.\n\n\nOoms, Jeroen. 2021. magick: Advanced Graphics and Image-Processing in R. https://CRAN.R-project.org/package=magick.\n\n\n———. 2022a. pdftools: Text Extraction, Rendering and Converting of PDF Documents. https://CRAN.R-project.org/package=pdftools.\n\n\n———. 2022b. qpdf: Split, Combine and Compress PDF Files. https://CRAN.R-project.org/package=qpdf.\n\n\nStrayer, Nick, Javier Luraschi, and JJ Allaire. 2022. R2d3: Interface to D3 Visualizations. https://CRAN.R-project.org/package=r2d3.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2022. ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWilke, Claus O. 2020. cowplot: Streamlined Plot Theme and Plot Annotations for ggplot2. https://CRAN.R-project.org/package=cowplot."
  },
  {
    "objectID": "chapter_11.html#detect-matches",
    "href": "chapter_11.html#detect-matches",
    "title": "9  11 Collect data",
    "section": "9.1 Detect matches",
    "text": "9.1 Detect matches\nSuppose we want to create an online survey which is why we scraped emails of our participants such as in the fictive email addresses from the Stranger Things data. Unfortunately, the strings contain some minor mistakes that need to be fixed:\n\n# Email examples\nemails &lt;- sf_data$email\nemails\n\n#&gt; [1] \"eleven@HawkinsLab.com\"    \"Dustin.Henderson@gmx.com\"\n#&gt; [3] \"byers-castle@gmx.com\"     \"Erica-Sinclair1@aol.com\" \n#&gt; [5] \"MBrenner@HawkinsLab.com2\" \"jim.hopper@hawkinspd.com\"\n#&gt; [7] \"Joyce-B@gmx.com\"          \"Mike@TheWheelers.com\"    \n#&gt; [9] \"1nancy-wheeler92@gmx.com\"\n\n\nNotice, some email addresses start (end) with a number instead of letters. Those signs are not a part of the email address but refer to footnotes on the webpage where we scraped the data. Suppose we do not know how virulent this problem is, can you detect which one does not start (str_starts) or end (str_ends) with a letter?\n\n# Does the string start with ...?\nstr_starts(emails, \"[:alpha:]\")\n\n#&gt; [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n\n\n\n# Does the string end with ...?\nstr_ends(emails, \"[:alpha:]\")\n\n#&gt; [1]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nSome of the email addresses are private, while others are from a company (e.g., HawkinsLab.com). If you need to know how many, use the str_count() function and build the sum. How many email addresses are from HawkinsLab.com?\n\n# Count them\nsum(str_count(emails, \"HawkinsLab.com\"))\n\n#&gt; [1] 2\n\n\nUse the str_detect() function to detect all strings from the HawkinsLab.\n\n# Detect strings\nstr_detect(emails, \"@HawkinsLab.com\")\n\n#&gt; [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n\n\nThe str_which() is also handy, it returns at which position we observe the search pattern.\n\n# And at which position?\nstr_which(emails, \"@HawkinsLab.com\")\n\n#&gt; [1] 1 5\n\n\nSuppose we need to extract the user names because we want to include them in the email invitation for the survey. In order to extract the names, locate the position of a string. Use the str_locate() to locate where the @ sign appears, because it splits the string into the user and the provider name.\n\n# Locate a start and an end point (here @)\nstr_locate(emails, \"@\")\n\n#&gt;       start end\n#&gt;  [1,]     7   7\n#&gt;  [2,]    17  17\n#&gt;  [3,]    13  13\n#&gt;  [4,]    16  16\n#&gt;  [5,]     9   9\n#&gt;  [6,]    11  11\n#&gt;  [7,]     8   8\n#&gt;  [8,]     5   5\n#&gt;  [9,]    17  17\n\n\nIn the next step we will use the position of the @ sign to mutate the strings and to extract their user names."
  },
  {
    "objectID": "chapter_11.html#mutate-strings",
    "href": "chapter_11.html#mutate-strings",
    "title": "9  11 Collect data",
    "section": "9.2 Mutate strings",
    "text": "9.2 Mutate strings\nLet us first clean the email addresses. Remove strings that do not start or end with a letter but with a number, which is clearly an error. Very similar to the str_replace() function, the str_remove() searches the string, but it removes a match instead of performing a replacement. Can you still remember how to remove the digits from the beginning (^) and the end ($) of a string? Replace the emails vector and check if it worked.\n\n# Remove strings\nemails &lt;- str_remove(emails, \"^[:digit:]\")\nemails &lt;- str_remove(emails, \"[:digit:]$\")\n\n# Did it work?\nemails\n\n#&gt; [1] \"eleven@HawkinsLab.com\"    \"Dustin.Henderson@gmx.com\"\n#&gt; [3] \"byers-castle@gmx.com\"     \"Erica-Sinclair1@aol.com\" \n#&gt; [5] \"MBrenner@HawkinsLab.com\"  \"jim.hopper@hawkinspd.com\"\n#&gt; [7] \"Joyce-B@gmx.com\"          \"Mike@TheWheelers.com\"    \n#&gt; [9] \"nancy-wheeler92@gmx.com\"\n\n\nWe could use the str_extract() function and our regex knowledge to extract the user names, but regex are hard to build even in the case of a supposedly simple strings. The email addresses make this point clear: Each user name consist of one or several words; some have a separator between the first and the last name, some contains digits (or not), and the user name ends before the @ sign. There is a much simpler solution to extract the user names, but nevertheless keep the str_view_all() function in mind if you are building a regex because it displays the strings in the viewer pane and highlights matched characters.\nInstead of building a regex, we can use the str_sub() function to create a vector with the user names only. The function needs the strings, a start, and an endpoint to create the subset. For this purpose we already located the positions of the @ sign with the str_locate() function. Thus, all user names start at the first position until the @ sign appears in the string. I copied the code to locate the @ sign and saved the results as x. Subset x to get a vector with the end position of the user name, then subset the emails.\n\n# Get and set substrings using their positions\nx &lt;- str_locate(emails, \"@\")\nend &lt;- x[, 1]\nnames &lt;- str_sub(emails, 1, end - 1)\nnames\n\n#&gt; [1] \"eleven\"           \"Dustin.Henderson\" \"byers-castle\"     \"Erica-Sinclair1\" \n#&gt; [5] \"MBrenner\"         \"jim.hopper\"       \"Joyce-B\"          \"Mike\"            \n#&gt; [9] \"nancy-wheeler92\"\n\n\nFurther steps to manipulate the strings might be easier to apply if all the user would have used the same style regarding their user names. Use the str_replace() function and replace the dashes with points.\n\n# Replace\nstr_replace(names, \"-\", \".\")\n\n#&gt; [1] \"eleven\"           \"Dustin.Henderson\" \"byers.castle\"     \"Erica.Sinclair1\" \n#&gt; [5] \"MBrenner\"         \"jim.hopper\"       \"Joyce.B\"          \"Mike\"            \n#&gt; [9] \"nancy.wheeler92\"\n\n\nDepending on the purpose, it might also be useful to create a uniform formatting of the strings. Use one of the str_to_*() functions to make them lower, upper, or title case.\n\n# str_to_* (lower, upper, title)\nstr_to_lower(names)\n\n#&gt; [1] \"eleven\"           \"dustin.henderson\" \"byers-castle\"     \"erica-sinclair1\" \n#&gt; [5] \"mbrenner\"         \"jim.hopper\"       \"joyce-b\"          \"mike\"            \n#&gt; [9] \"nancy-wheeler92\""
  },
  {
    "objectID": "chapter_11.html#subset-strings",
    "href": "chapter_11.html#subset-strings",
    "title": "9  11 Collect data",
    "section": "9.3 Subset strings",
    "text": "9.3 Subset strings\nWe used the str_sub() to split strings by their position, but the str_subset() function lets us create a subset for a search pattern. For example, consider all participants with an specific email account (e.g., gmx):\n\n# Find matching elements\nstr_subset(emails, pattern = \"gmx\")\n\n#&gt; [1] \"Dustin.Henderson@gmx.com\" \"byers-castle@gmx.com\"    \n#&gt; [3] \"Joyce-B@gmx.com\"          \"nancy-wheeler92@gmx.com\"\n\n\nFurthermore, most of the time we use the str_detect() function to detect a pattern. For example, the functions shows us which input has a specific pattern and we can detect if an string has no @ sign at all.\n\nstrings &lt;- c(\n  \"Dustin Henderson\",\n  \"hop@gmx.com jim.hopper@hawkinspd.com\",\n  \"Erica-Sinclair@aol.com\",\n  \"nancy-wheeler92@gmx.com\"\n)\n\nis_email &lt;- \"@\"\n\n# Detect a pattern\nstr_detect(strings, is_email)\n\n#&gt; [1] FALSE  TRUE  TRUE  TRUE\n\n\nWe used the function to illustrate the first few things about regular expressions. However, we do not need to filter the data and first detect the email addresses if we want to extract this information. Consider how the str_extract() and the str_extract_all function work. The function needs strings and a pattern (such as is_email). It shows us which string does (not) include the given pattern.\n\n# Extract the complete match\nstr_extract(strings, is_email)\n\n#&gt; [1] NA  \"@\" \"@\" \"@\"\n\nstr_extract_all(strings, is_email)\n\n#&gt; [[1]]\n#&gt; character(0)\n#&gt; \n#&gt; [[2]]\n#&gt; [1] \"@\" \"@\"\n#&gt; \n#&gt; [[3]]\n#&gt; [1] \"@\"\n#&gt; \n#&gt; [[4]]\n#&gt; [1] \"@\"\n\n\nFinally, the str_match() (and str_match_all) does essentially the same as str_extract(), but returns matches as matrix.\n\n# Extract components (capturing groups) from a match\nstr_match(strings, is_email)\n\n#&gt;      [,1]\n#&gt; [1,] NA  \n#&gt; [2,] \"@\" \n#&gt; [3,] \"@\" \n#&gt; [4,] \"@\""
  },
  {
    "objectID": "chapter_11.html#join-and-splits",
    "href": "chapter_11.html#join-and-splits",
    "title": "9  11 Collect data",
    "section": "9.4 Join and splits",
    "text": "9.4 Join and splits\nThe stringr package has join and split functions. Suppose we scraped the first and the last name of a person separately, but for the survey invitation we need to combine them. Use str_c() for this job and assign them as names. Combine the firstname with the lastname from the sf_data. Use a blank space as a separator (sep).\n\n# Use str_c to combine strings\nnames &lt;- str_c(sf_data$firstname, sf_data$lastname, sep = \" \")\nnames\n\n#&gt; [1] \"Millie Bobby Brown\" \"Gaten Matarazzo\"    \"Noah Schnapp\"      \n#&gt; [4] \"Priah Ferguson\"     \"Matthew Modine\"     \"David Harbour\"     \n#&gt; [7] \"Winona Ryder\"       \"Finn Wolfhard\"      \"Natalia Dyer\"\n\n\nUse the str_split_fixed() in the opposite scenario. Split the names vector from the last task: Use the blank space as a pattern and each name consist of two text chunks we want to split (n).\n\n# Split strings\nstr_split_fixed(names, pattern = \" \", n = 2)\n\n#&gt;       [,1]      [,2]         \n#&gt;  [1,] \"Millie\"  \"Bobby Brown\"\n#&gt;  [2,] \"Gaten\"   \"Matarazzo\"  \n#&gt;  [3,] \"Noah\"    \"Schnapp\"    \n#&gt;  [4,] \"Priah\"   \"Ferguson\"   \n#&gt;  [5,] \"Matthew\" \"Modine\"     \n#&gt;  [6,] \"David\"   \"Harbour\"    \n#&gt;  [7,] \"Winona\"  \"Ryder\"      \n#&gt;  [8,] \"Finn\"    \"Wolfhard\"   \n#&gt;  [9,] \"Natalia\" \"Dyer\"\n\n\nWe used the str_sub() function to extract the user names, but we could also use the str_split() function to split the strings before and after the @ sign. Say we want to extract unique provider names this time. The str_split() function returns a list as the next console shows. Use the pipe and the map_chr() functions from purrr to get the first or second element of each list (Henry and Wickham 2022). Furthermore, apply the stri_unique() function from stringi to examine unique provider names only (Gagolewski et al. 2022).\n\n# Split email, get provider names, but only unique ones\nstr_split(emails, pattern = \"@\") |&gt;\n  purrr::map_chr(2) |&gt;\n  stringi::stri_unique()\n\n#&gt; [1] \"HawkinsLab.com\"  \"gmx.com\"         \"aol.com\"         \"hawkinspd.com\"  \n#&gt; [5] \"TheWheelers.com\"\n\n\nThe glue package offers some useful features to work with strings, especially if we create texts and documents. Suppose we want to create a sentence that describe how old a person like Jim Hopper is. I already calculated his age (hopper_age); use the paste function to create a sentences that describes how old he is.\n\n# Traditional approach\nhopper_age &lt;- lubridate::year(Sys.time()) - sf_data$year[6]\npaste(\"Jim Hopper is\", hopper_age, \"years old.\")\n\n#&gt; [1] \"Jim Hopper is 49 years old.\"\n\n\nDid you realize that we need a lot of quotation marks and that we need to be careful not to introduce any error. The str_glue() tries to improve this case. We can refer to objects with curved braces without further ado.\n\n# Glue strings\nstr_glue(\"Hop is {hopper_age} years.\")\n\n#&gt; Hop is 49 years.\n\n\nOne step further goes the str_glue_data() function. It returns strings for each observation of a data set. For example, build a sentence that outlines the firstname, lastname and the birth year of the Stranger Things actors.\n\n# Glue strings from data\nstr_glue_data(sf_data, \"- {firstname} {lastname} is born in {year}.\")\n\n#&gt; - Millie Bobby Brown is born in 2004.\n#&gt; - Gaten Matarazzo is born in 2002.\n#&gt; - Noah Schnapp is born in 2004.\n#&gt; - Priah Ferguson is born in 2006.\n#&gt; - Matthew Modine is born in 1959.\n#&gt; - David Harbour is born in 1975.\n#&gt; - Winona Ryder is born in 1971.\n#&gt; - Finn Wolfhard is born in 2002.\n#&gt; - Natalia Dyer is born in 1995.\n\n\nFinally, the package offers functions to order strings and manage their length."
  },
  {
    "objectID": "chapter_11.html#length-and-order",
    "href": "chapter_11.html#length-and-order",
    "title": "9  11 Collect data",
    "section": "9.5 Length and order",
    "text": "9.5 Length and order\nDo not forget that stringr comes with example strings (fruit, sentences) that lets you test the functions before you run them in the wild, but of course we can also build our own fruits. So, do you remember how we can estimate the length of strings?\n\n# Length of a string\nfruits &lt;- c(\"banana\", \"apricot\", \"apple\", \"pear     \")\nstr_length(fruits)\n\n#&gt; [1] 6 7 5 9\n\n\nUnfortunately, the fruits vector includes an mistake. There is a lot of white space around the last fruit. Do you know how to get rid of such noise.\n\n# Trim your strings\nfruits &lt;- str_trim(fruits)\nfruits\n\n#&gt; [1] \"banana\"  \"apricot\" \"apple\"   \"pear\"\n\n\nFinally, order (str_order) and sort (str_sort) the fruits.\n\n# Order strings\nstr_order(fruits)\n\n#&gt; [1] 3 2 1 4\n\n\n\n# Sort strings\nstr_sort(fruits, decreasing = F)\n\n#&gt; [1] \"apple\"   \"apricot\" \"banana\"  \"pear\""
  },
  {
    "objectID": "chapter_11.html#summary",
    "href": "chapter_11.html#summary",
    "title": "9  11 Collect data",
    "section": "9.6 Summary",
    "text": "9.6 Summary\nKeep also the following functions and packages from Chapter 11 in mind:\n\nPDF utilities (e.g., pdf_text, Ooms 2022)\nCoerce a list to a vector (purrr::as_vector)\nThe Names of an object (names)\nSubset rows using their positions (dplyr::slice_*, Wickham et al. 2022)\nBind multiple data frames by row (dplyr::bind_rows)\nThe rvest package and its functions for web scraping (e.g., read_html, html_table, Wickham 2022b)\nThe httr package and its functions for receive information from a website (GET, content, Wickham 2022a)\nCreate an API with the plumber package (Schloerke and Allen 2022)\n\n\n\n\n\nGagolewski, Marek, Bartek Tartanus, others; Unicode, Inc., et al. 2022. stringi: Fast and Portable Character String Processing Facilities. https://CRAN.R-project.org/package=stringi.\n\n\nHenry, Lionel, and Hadley Wickham. 2022. purrr: Functional Programming Tools. https://CRAN.R-project.org/package=purrr.\n\n\nOoms, Jeroen. 2022. pdftools: Text Extraction, Rendering and Converting of PDF Documents. https://CRAN.R-project.org/package=pdftools.\n\n\nSchloerke, Barret, and Jeff Allen. 2022. plumber: An API Generator for R. https://CRAN.R-project.org/package=plumber.\n\n\nTreischl, Edgar J. 2023. Practice R: An Interactive Textbook. De Gruyter Oldenbourg.\n\n\nWickham, Hadley. 2022a. httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr.\n\n\n———. 2022b. rvest: Easily Harvest (Scrape) Web Pages. https://CRAN.R-project.org/package=rvest.\n\n\n———. 2022c. stringr: Simple, Consistent Wrappers for Common String Operations. https://CRAN.R-project.org/package=stringr.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin\nUshey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and\nRichard Iannone. 2022. rmarkdown: Dynamic\nDocuments for R. https://CRAN.R-project.org/package=rmarkdown.\n\n\nArel-Bundock, Vincent. 2023. modelsummary:\nSummary Tables and Plots for Statistical Models and Data: Beautiful,\nCustomizable, and Publication-Ready. https://CRAN.R-project.org/package=modelsummary.\n\n\nArnold, Jeffrey B. 2021. ggthemes: Extra\nThemes, Scales and Geoms for ggplot2. https://CRAN.R-project.org/package=ggthemes.\n\n\nBååth, Rasmus. 2018. Beepr: Easily Play\nNotification Sounds on any Platform. https://CRAN.R-project.org/package=beepr.\n\n\nBen-Shachar, Mattan S., Dominique Makowski, Daniel Lüdecke, Indrajeet\nPatil, and Brenton M. Wiernik. 2022. effectsize: Indices of Effect Size. https://CRAN.R-project.org/package=effectsize.\n\n\nBlair, Graeme, Jasper Cooper, Alexander Coppock, Macartan Humphreys, and\nLuke Sonnet. 2022. estimatr: Fast Estimators\nfor Design-Based Inference. https://CRAN.R-project.org/package=estimatr.\n\n\nCairo, Alberto. 2016. The Truthful Art:\nData, Charts, and Maps for\nCommunication. New Riders.\n\n\nComtois, Dominic. 2022. summarytools: Tools to\nQuickly and Neatly Summarize Data. https://CRAN.R-project.org/package=summarytools.\n\n\nCsárdi, Gábor. 2022. cli: Helpers for\nDeveloping Command Line Interfaces. https://CRAN.R-project.org/package=cli.\n\n\nCui, Boxuan. 2020. DataExplorer: Automate Data\nExploration and Treatment. https://CRAN.R-project.org/package=DataExplorer.\n\n\nFirke, Sam. 2021. janitor: Simple Tools for\nExamining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor.\n\n\nGagolewski, Marek, Bartek Tartanus, others; Unicode, Inc., et al. 2022.\nstringi: Fast and Portable Character String\nProcessing Facilities. https://CRAN.R-project.org/package=stringi.\n\n\nGarnier, Simon. 2021. viridis:\nColorblind-Friendly Color Maps for R. https://CRAN.R-project.org/package=viridis.\n\n\nGohel, David, and Panagiotis Skintzos. 2022. flextable: Functions for Tabular Reporting.\nhttps://CRAN.R-project.org/package=flextable.\n\n\nHenry, Lionel, and Hadley Wickham. 2022. purrr:\nFunctional Programming Tools. https://CRAN.R-project.org/package=purrr.\n\n\nHester, Jim, and Jennifer Bryan. 2022. glue:\nInterpreted String Literals. https://CRAN.R-project.org/package=glue.\n\n\nHlavac, Marek. 2022. stargazer: Well-Formatted\nRegression and Summary Statistics Tables. https://CRAN.R-project.org/package=stargazer.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2022. palmerpenguins: Palmer Archipelago (Antarctica) Penguin\nData. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nHothorn, Torsten, Achim Zeileis, Richard W. Farebrother, and Clint\nCummins. 2022. lmtest: Testing Linear\nRegression Models. https://CRAN.R-project.org/package=lmtest.\n\n\nHugh-Jones, David. 2022. huxtable: Easily\nCreate and Style Tables for LaTeX, HTML and Other Formats.\nhttps://CRAN.R-project.org/package=huxtable/.\n\n\nHvitfeldt, Emil. 2021. paletteer: Comprehensive\nCollection of Color Palettes. https://CRAN.R-project.org/package=paletteer.\n\n\nIannone, Richard, and Joe Cheng. 2020. blastula: Easily Send HTML Email Messages. https://CRAN.R-project.org/package=blastula.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, and\nJooYoung Seo. 2022. gt: Easily Create\nPresentation-Ready Display Tables. https://CRAN.R-project.org/package=gt.\n\n\nKunst, Joshua. 2022. highcharter: A Wrapper for\nthe Highcharts Library. https://CRAN.R-project.org/package=highcharter.\n\n\nLong, Jacob A. 2021. interactions:\nComprehensive, User-Friendly Toolkit for Probing\nInteractions. https://CRAN.R-project.org/package=interactions.\n\n\n———. 2022. jtools: Analysis and Presentation of\nSocial Scientific Data. https://CRAN.R-project.org/package=jtools.\n\n\nLüdecke, Daniel, Dominique Makowski, Mattan S. Ben-Shachar, Indrajeet\nPatil, Philip Waggoner, and Brenton M. Wiernik. 2022. performance: Assessment of Regression Models\nPerformance. https://CRAN.R-project.org/package=performance.\n\n\nLüdecke, Daniel, Dominique Makowski, Indrajeet Patil, Mattan S.\nBen-Shachar, Brenton M. Wiernik, and Philip Waggoner. 2022. see: Model Visualisation Toolbox for easystats and\nggplot2. https://CRAN.R-project.org/package=see.\n\n\nMakowski, Dominique, Daniel Lüdecke, Mattan S. Ben-Shachar, Indrajeet\nPatil, and Brenton M. Wiernik. 2022. report:\nAutomated Reporting of Results and Statistical Models. https://CRAN.R-project.org/package=report.\n\n\nMakowski, Dominique, Brenton M. Wiernik, Indrajeet Patil, Daniel\nLüdecke, and Mattan S. Ben-Shachar. 2022. Correlation:\nMethods for Correlation Analysis. https://CRAN.R-project.org/package=correlation.\n\n\nMüller, Kirill. 2020. here: A Simpler Way to\nFind Your Files. https://CRAN.R-project.org/package=here.\n\n\nMüller, Kirill, and Hadley Wickham. 2022a. pillar: Coloured Formatting for Columns. https://CRAN.R-project.org/package=pillar.\n\n\n———. 2022b. tibble: Simple Data\nFrames. https://CRAN.R-project.org/package=tibble.\n\n\nNeuwirth, Erich. 2022. RColorBrewer: ColorBrewer\nPalettes. https://CRAN.R-project.org/package=RColorBrewer.\n\n\nOoms, Jeroen. 2021. magick: Advanced Graphics\nand Image-Processing in R. https://CRAN.R-project.org/package=magick.\n\n\n———. 2022a. pdftools: Text Extraction,\nRendering and Converting of PDF Documents. https://CRAN.R-project.org/package=pdftools.\n\n\n———. 2022b. qpdf: Split, Combine and Compress\nPDF Files. https://CRAN.R-project.org/package=qpdf.\n\n\nPatil, Indrajeet. 2023. ggstatsplot: ggplot2\nBased Plots with Statistical Details. https://CRAN.R-project.org/package=ggstatsplot.\n\n\nPedersen, Thomas Lin. 2022a. ggforce:\nAccelerating ggplot2. https://CRAN.R-project.org/package=ggforce.\n\n\n———. 2022b. patchwork: The Composer of\nPlots. https://CRAN.R-project.org/package=patchwork.\n\n\nQiu, Yixuan. 2022. showtext: Using Fonts More\nEasily in R Graphs. https://CRAN.R-project.org/package=showtext.\n\n\nSchloerke, Barret, and Jeff Allen. 2022. plumber: An API Generator for R. https://CRAN.R-project.org/package=plumber.\n\n\nSchloerke, Barret, Di Cook, Joseph Larmarange, Francois Briatte, Moritz\nMarbach, Edwin Thoen, Amos Elberg, and Jason Crowley. 2021. GGally: Extension to ggplot2. https://CRAN.R-project.org/package=GGally.\n\n\nSievert, Carson, Chris Parmer, Toby Hocking, Scott Chamberlain, Karthik\nRam, Marianne Corvellec, and Pedro Despouy. 2022. plotly: Create Interactive Web Graphics via\nplotly.js. https://CRAN.R-project.org/package=plotly.\n\n\nSolt, Frederick, and Yue Hu. 2021. dotwhisker:\nDot-and-Whisker Plots of Regression Results. https://CRAN.R-project.org/package=dotwhisker.\n\n\nStrayer, Nick, Javier Luraschi, and JJ Allaire. 2022. R2d3:\nInterface to D3 Visualizations. https://CRAN.R-project.org/package=r2d3.\n\n\nTierney, Nicholas, Di Cook, Miles McBain, and Colin Fay. 2021. naniar: Data Structures, Summaries, and Visualisations\nfor Missing Data. https://CRAN.R-project.org/package=naniar.\n\n\nTreischl, Edgar J. 2023. Practice R: An\nInteractive Textbook. De Gruyter Oldenbourg.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia,\nHao Zhu, and Shannon Ellis. 2022. skimr:\nCompact and Flexible Summaries of Data. https://CRAN.R-project.org/package=skimr.\n\n\nWickham, Hadley. 2021. babynames: US Baby Names\n1880-2017. https://github.com/hadley/babynames.\n\n\n———. 2022a. forcats: Tools for Working with\nCategorical Variables (Factors). https://CRAN.R-project.org/package=forcats.\n\n\n———. 2022b. httr: Tools for Working with URLs\nand HTTP. https://CRAN.R-project.org/package=httr.\n\n\n———. 2022c. rvest: Easily Harvest (Scrape) Web\nPages. https://CRAN.R-project.org/package=rvest.\n\n\n———. 2022d. stringr: Simple, Consistent\nWrappers for Common String Operations. https://CRAN.R-project.org/package=stringr.\n\n\nWickham, Hadley, and Jennifer Bryan. 2022. readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen,\nKohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey\nDunnington. 2022. ggplot2: Create Elegant Data\nVisualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2022.\ndplyr: A Grammar of Data\nManipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Maximilian Girlich. 2022. tidyr: Tidy Messy Data. https://CRAN.R-project.org/package=tidyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2022. haven: Import and Export SPSS, Stata and SAS\nFiles. https://CRAN.R-project.org/package=haven.\n\n\nWilke, Claus O. 2020. cowplot: Streamlined Plot\nTheme and Plot Annotations for ggplot2. https://CRAN.R-project.org/package=cowplot.\n\n\nXie, Yihui, Joe Cheng, and Xianying Tan. 2022. DT: A Wrapper of the JavaScript Library\nDataTables. https://CRAN.R-project.org/package=DT.\n\n\nZhu, Hao. 2021. kableExtra: Construct Complex\nTable with kable and Pipe Syntax. https://CRAN.R-project.org/package=kableExtra."
  }
]